Проект «Обучение модели классификации текстов»

ОПИСАНИЕ:
Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.
Задача проекта – создать модель, которая будет определять токсичность комментариев.
ИСПОЛЬЗУЕМЫЕ БИБЛИОТЕКИ, ИНСТРУМЕНТЫ И НАВЫКИ
Pyton, Pandas, BERT, nltk, tf-idf
ВЫВОД:
Цель проекта - обучить модель классифицировать комментарии на позитивные и негативные.
Что было сделано:
1.	Мы проверили данные на сбалансированность классов, оказалось, что они не сбалансированы, этот момент мы учли в параметрах модели, укаазыв class_weight 'balanced'.
2.	Очистили данные от лишних символов, привели их к стандартной кодировке кодировку Unicode U, проведем лемматизацию с помощью лексической базы Wordnet для английского языка.
3.	Разбили данные на выборки, удалили стоп-слова и провели векторизацию.
4.	Обучили с помощью подбора параметров и кросс-валидации 3 модели - LogisticRegression, DecisionTreeClassifier, CatBoostClassifier. Но по условию задачи требуемой метрике F1 >0.75 подошла только модель LogisticRegression, ее F1 составила 0.769057.
Можно было бы еще потренироваться подобрать параметры для модели CatBoostClassifier, ее метрика относительно близка к требуемой, но на её обучение уходит слишком много времени. А модель Логистической регрессии сработала быстро и точно, поэтому остановились на ней.
5.	Проверил метрику выбранной модели на тестовой выборке, ее F1 составила 0.775675, что хорошо значит модель не переобучилась и наша тестовая выборка была репрезентативной.
6.	Построили матрицу ошибок и график полноты-точности, тут тоже модель показала хороший результат - большой процент точности предсказаний и мало ошибок.
Поэтому полученную модель Логистической регрессии рекомендуем использовать для определения токсичных комментариев в интернет-магазине «Викишоп».

