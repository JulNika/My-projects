{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea2bacf",
   "metadata": {},
   "source": [
    "# Проект \"Прогнозирование заказов такси на следующий час\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ed3a6",
   "metadata": {},
   "source": [
    "***Описание проекта***\n",
    "\n",
    "Компания «Чётенькое такси» собрала исторические данные о заказах такси в аэропортах. Чтобы привлекать больше водителей в период пиковой нагрузки, нужно спрогнозировать количество заказов такси на следующий час. \n",
    "\n",
    "Нобходимо постройте модель для прогнозирования заказов такси на следующий час.\n",
    "Значение метрики RMSE на тестовой выборке должно быть не больше 48.\n",
    "\n",
    "***Этапы выполения работы:***\n",
    "\n",
    "1. Загрузить данные и выполните их ресемплирование по одному часу.\n",
    "\n",
    "2. Анализ данных.\n",
    "\n",
    "3. Обучение разных моделей с различными гиперпараметрами (размер тестовуой выборки - 10% от исходных данных).\n",
    "\n",
    "4. Проверкае данные на тестовой выборке и сделайте выводы.\n",
    "\n",
    "***Описание данных***\n",
    "\n",
    "Данные лежат в файле /datasets/taxi.csv. \n",
    "Количество заказов находится в столбце 'num_orders' (от англ. number of orders, «число заказов»)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4398f",
   "metadata": {},
   "source": [
    "## 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec624a",
   "metadata": {},
   "source": [
    "***Тут будут все импорты***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aeae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729941e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error,make_scorer,mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, cross_val_score\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a99503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 0:00:00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01 0:10:00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 0:20:00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01 0:30:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01 0:40:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26491</th>\n",
       "      <td>2018-08-31 23:10:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26492</th>\n",
       "      <td>2018-08-31 23:20:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26493</th>\n",
       "      <td>2018-08-31 23:30:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26494</th>\n",
       "      <td>2018-08-31 23:40:00</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26495</th>\n",
       "      <td>2018-08-31 23:50:00</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  num_orders\n",
       "0       2018-03-01 0:00:00           9\n",
       "1       2018-03-01 0:10:00          14\n",
       "2       2018-03-01 0:20:00          28\n",
       "3       2018-03-01 0:30:00          20\n",
       "4       2018-03-01 0:40:00          32\n",
       "...                    ...         ...\n",
       "26491  2018-08-31 23:10:00          32\n",
       "26492  2018-08-31 23:20:00          24\n",
       "26493  2018-08-31 23:30:00          27\n",
       "26494  2018-08-31 23:40:00          39\n",
       "26495  2018-08-31 23:50:00          53\n",
       "\n",
       "[26496 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загрузка данных\n",
    "from io import BytesIO\n",
    "import requests\n",
    "spreadsheet_id = '1He-SoMnBAnPYHWyaJE6c8BWys1VdmNCxodUK24oe0J4'\n",
    "file_name = 'https://docs.google.com/spreadsheets/d/{}/export?format=csv'.format(spreadsheet_id)\n",
    "r = requests.get(file_name)\n",
    "data = pd.read_csv(BytesIO(r.content))\n",
    "data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5132498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26496 entries, 0 to 26495\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   datetime    26496 non-null  object\n",
      " 1   num_orders  26496 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 414.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#информция по данным и просмотр пропусков\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d7ed3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 26496 entries, 2018-03-01 00:00:00 to 2018-08-31 23:50:00\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   num_orders  26496 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 414.0 KB\n"
     ]
    }
   ],
   "source": [
    "#ресемплирование по одному часу\n",
    "\n",
    "data = pd.read_csv(BytesIO(r.content), index_col=[0], parse_dates=[0])\n",
    "data= data.sort_index()\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb98a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:10:00</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:20:00</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:30:00</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:40:00</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     num_orders\n",
       "datetime                       \n",
       "2018-03-01 00:00:00           9\n",
       "2018-03-01 00:10:00          14\n",
       "2018-03-01 00:20:00          28\n",
       "2018-03-01 00:30:00          20\n",
       "2018-03-01 00:40:00          32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d611a83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:10:00</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:20:00</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:30:00</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:40:00</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:50:00</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     num_orders\n",
       "datetime                       \n",
       "2018-08-31 23:10:00          32\n",
       "2018-08-31 23:20:00          24\n",
       "2018-08-31 23:30:00          27\n",
       "2018-08-31 23:40:00          39\n",
       "2018-08-31 23:50:00          53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95efcfa",
   "metadata": {},
   "source": [
    "***Вывод:***\n",
    "Пропусков в данных нет. Данные представлены за период 01.03.2018 - 31.08.2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ac976",
   "metadata": {},
   "source": [
    "## 2. Анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ecafc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,  14,  28,  20,  32,  21,   7,   5,  17,  12,  19,  25,  22,\n",
       "         8,   6,   4,  10,  13,   2,   3,   0,   1,  11,  15,  16,  23,\n",
       "        18,  33,  24,  26,  30,  38,  34,  42,  31,  27,  36,  29,  35,\n",
       "        56,  37,  40,  39,  45,  49,  58,  68,  43,  53,  44,  41,  52,\n",
       "        46,  57,  47,  64,  61,  50,  48,  55,  62,  54,  71,  78, 119,\n",
       "        99,  51,  60,  87,  90,  94,  82,  80,  91,  76,  66,  65,  98,\n",
       "        81,  95,  67])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_orders'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeeaa13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#проверим в хронологическом ли порядке расположены даты и время\n",
    "print(data.index.is_monotonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed0be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выполним ресемплирование данных по 1 часу\n",
    "data = data.resample('1H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bae4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выполним ресемплирование данных по 1 неделе и 1 месяцу \n",
    "\n",
    "data1 = data.resample('1W').mean()\n",
    "data2 = data.resample('1D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b3db55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#построим график\n",
    "figsize = (18,10)\n",
    "data.plot(figsize=figsize)\n",
    "\n",
    "plt.xlabel('Дата заказов в разбивке по часу')\n",
    "plt.ylabel('Количество заказов')\n",
    "plt.title('График количества заказов такси по часам ', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300b2464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#построим график\n",
    "figsize = (18,10)\n",
    "data1.plot(figsize=figsize)\n",
    "\n",
    "plt.xlabel('Дата заказов в разбивке по неделям')\n",
    "plt.ylabel('Среднее количество заказов в неделю')\n",
    "plt.title('График среднего количества заказов такси по неделям', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc03abc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>56.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-02</th>\n",
       "      <td>62.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-03</th>\n",
       "      <td>53.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-04</th>\n",
       "      <td>47.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>52.458333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_orders\n",
       "datetime              \n",
       "2018-03-01   56.833333\n",
       "2018-03-02   62.750000\n",
       "2018-03-03   53.750000\n",
       "2018-03-04   47.541667\n",
       "2018-03-05   52.458333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afebe03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#построим график\n",
    "figsize = (18,10)\n",
    "data2.plot(figsize=figsize)\n",
    "\n",
    "plt.xlabel('Дата заказов в разбивке по дням')\n",
    "plt.ylabel('Срднее количество заказов в день')\n",
    "plt.title('График среднего количества заказов такси в день', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038018c3",
   "metadata": {},
   "source": [
    "Если сделать ресемплирвоание данных по днмя и неделям и найти среднее их колчество, то видна явная тенденция роста числа заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82c207d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAI4CAYAAAA/PH0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACieUlEQVR4nOydd5hdVfWw3zW9Z9J7hZCQBBKSEELvSCjSm4CgKGKvnz+aigKCIqKIUhQEpXcihE6oCWmQkE56b5Nkep/Z3x+nzLn93pnbZma9z5PcOXWvc84+Z+219tprizEGRVEURUk3MlItgKIoiqIEQxWUoiiKkpaoglIURVHSElVQiqIoSlqiCkpRFEVJS1RBKYqiKGmJKihF6SKIyAkisjXVcihKvFAFpShxRkSqPf9aRaTOs3x5quVTlM5CVqoFUJSuhjGmyPlbRDYC3zLGvOO/n4hkGWOakymbonQm1IJSlCThuOBE5P9EZCfwbxHJEJHrRWSdiOwVkWdFpJe9/wgRMSJylYhsFpEyEbnJc758EXlURPaLyArg8FRdm6IkArWgFCW5DAB6AcOxGog/BM4Fjgf2APcCfwcu8xxzDDAGOAiYLyIvGmNWAr8BDrD/FQKvJ+cSFCU5qAWlKMmlFfiNMabBGFMHXAfcZIzZaoxpAG4BLhQRb+Pxt8aYOmPMEmAJMNFefzFwuzFmnzFmC5ZyU5Qug1pQipJc9hhj6j3Lw4GXRKTVs64F6O9Z3un5uxZw+rgGAVs82zbFU1BFSTVqQSlKcvGfPmALMMMYU+r5l2eM2RbFuXYAQz3Lw+ImpaKkAaqgFCW1PADcLiLDAUSkr4icE+WxzwI3iEhPERmC1Z+lKF0GVVCKklr+CswE3hKRKuBT4Igoj/0tlltvA/AW8N+ESKgoKUJ0wkJFURQlHVELSlEURUlLVEEpiqIoaYkqKEVRFCUtUQWlKIqipCWdYqBunz59zIgRI1IthqIoipIAFi1aVGaM6eu/vlMoqBEjRrBw4cJUi6EoiqIkABEJmgVFXXyKoihKWqIKSlEURUlLVEEpiqIoaYkqKEVRFCVp3PP2l1zy4Nyo9lUFpSiKoiSNv767hnkb9vHRmj0R91UFpSiKoiSdKx+ez+a9tWH3UQWlKIqipISfPPN52O2qoBRFUZSU8Nnm8rDbVUEpiqIoSWHF9kqf5XEDS8LurwpKURRFSQrLt1f4LK/YUcnbK3aF3F8VlKIoihJ3NpTV8Kc3V+OdFHfj3pqA/bIyJOQ5VEEpiqIoced7T3zGfbPXsnlfW6Te32evC9jvhDEBOWJdVEEpiqIocWflDqu/qaG5NWDbP78+1f1bJLQF1SmymSuKoiidk4amNgWVm5VBblYGp47rz+3nTeDjNWVhj1UFpSiKosSVitom9++G5hb37/ycTL46cRAAlx8xnMuPGB72POriUxRFUeLKZ5v3u387Lj5jDNX1zRTlRm8XqYJSFEVRQjJ71W6emr85pmP21jS6f9c3WRZUQ3Mrza2GwhgUlLr4FEVRlJB849EFAFw2bVjUx5TXtimoRtuCqm5oBqA4Ty0oRVEUpYN4xzC1tpqQ++2oqHOj9gAe+nC9+3eTfVx1vaWgYnHxqQWlKIqiBGXmku3u382thpwQg2qPvOM9ADbeeSYAu6sa3G0trb4WlPZBKYqiKB3mt/9b4f7d3Bo4nikU/UtyGTugGICmFsuCqmqHBRUXBSUij4jIbhFZ5ll3i4hsE5HF9r8zPNtuEJG1IrJaRL4SDxkURVGU+LLPE+zQ1Bzaxefg9Dc1txgGl+YD0GK7+HZX1QNQlII+qEeB04Osv8cYM8n+NwtARMYBlwLj7WP+ISKZcZJDURRFiRPTRvZy/26KwoKqqrfGP9U2tlCSnw1Ac4t13IYyKw9fz4KcqMuPi4IyxnwI7Ity93OAp40xDcaYDcBaYFo85FAURVHihzeRa3NLcAvKUUDQ5hJsaG6hMNeyO5ptCyrTTmk0oEde1OUnug/qByLyhe0C7GmvGwxs8eyz1V6nKIqipBEVdW0ZIZpagltQ3lx7M5dsp6XV0GogP9tWULZiq21qITtTyM6MXu0kUkHdDxwATAJ2AHfHcrCIXCsiC0Vk4Z49exIgnqIoihKKiromVu2sYkCJZfGEUlB1TS0+y85++TlWX5PjGqxpaHaVVrQkTEEZY3YZY1qMMa3AP2lz420Dhnp2HWKv8z/+IWPMVGPM1L59Q6djVxRFUeJPWXUDLa2GCYN7AG2uOn/qGtsU1LBeBTQ6CspWRi22BfWfuZuotCP5oiVhCkpEBnoWzwOcCL+ZwKUikisiI4HRwPxEyaEoiqLEjqN4etjBDqEsqJpGS+n0K86lvLaRpmZHQVnqpSnMAN9IxGWgrog8BZwA9BGRrcBvgBNEZBJggI3AdwCMMctF5FlgBdAMfN8Y0xLktIqiKEqKcFx3bQoquKKptRXZoNJ8Fm8pd4/LycokK0NoaW11s1B865iRMckQFwVljLksyOqHw+x/O3B7PMpWFEVROs6GshpmLd3B9044ABFxLSgnd15zCAuqtsHab7CtoPZWW2OnsjOFzAyhucVww4tLARhoj42KFs0koSiK0sXZV9PIqBteY+nWipD7XPPYAu56czVvLt8FtLn0CnIy7eVQFpTl4htoh487aY5ysjLIzsygudXwzEIrcLt3YfRjoEAVlKIoSpfn9WU7aDVw73trQu6zfo81kPa6xxcBbUERzvQY9U3Be2IcF58zMPfO11cCkJ2ZQXVDMw9/vMHdt5cqKEVRFMXLsm2W5RTOgpk4tNRn2ek3Ki2wFE9VQ/AIPGd9ie0KXGcrumDjnRxrLFpUQSmKonRxnppvudgaQ/QjARzYtwiwwsONMa4F5QRJ/O3d4NbXnsp6ROCK6b7Tt2dn+mY+/8bRI5g8rCexoNNtKIqidGG88zhV1oUeh1Rp59Gra2qhrLrRTfLqDNRds7saYwxipywqr23kqflbqGpopjAniyw/i8k/596vzxrnHhstakEpiqJ0YbyuuRa/hK97qxvYUVEHQEVtW1qjvTUNroLKzcrkpjMOBvAZaHvDi0v5wxur+GD1Hjfvnpf+JW0597645bSYlROoBaUoitKlqfTk0/NmgzDGMOW2dwBrosGKuiZyszJoaG6lpqHZVVAZGdDT7rsqr210XX5OtF51Q3PQKTT6FOVw8MAShvcqoCQvu12yqwWlKIrShahvauFXLy+jrNpSINvK69xtLR4Ftae6bdbbLftqqahrcudwqm5oocWe7j0rI8NVSuUeK2vT3lrAcg06kxDeeu4EDh5YwprbZ5CVmcHrPz6WB66c0u5rUQWlKIrShXj1ix3899NN3P3WlwDsrLAmCuxbnOtjQe3xTMv+yuJtloLqaSmo2oZmd9+MjLa8ejvsc20oq3EVYH1TK1/Y46uunD6c1398bEwZy8OhCkpRFKUL8egca9yRM5eTM5PtwB55PgET3j4nEaGuqcUdbFtZ3+Tum5WR4UbkOWOcvvHv5KRPVQWlKIrShXBcb0Nsa2h3ZQN52ZabzmtB7fcoqHvtEPKTxvYDYOv+Op+JBqcMt8LDN+6tZUdFHRvtMhwe/cbhCbkWVVCKoigJor6phT+9uZr9NY1JK/Og/sUANNpZxavqm+mRn012ZoZPH9T+2jaZnEkHT58wkB752VTWNbkRf5mZ4hNC/quXlweUecKYfvG/EFRBKYqiJIyP1pRx3+y1/OWdL5NWZkOzlXqoxk5B1NTSSlZGhpW41evi80T3eSnJz6KyvhlnTK932neAd1buSoDUwVEFpSiKkiCcqSd2VtYnrcwaO7v4F1vLAWs+puxMIVPEZxzUiu2ViMCfLproc3xJnq8FlWGPX3LGQjncMGMsAGMHFCfkOkDHQSmKoiSMGnuQbG1j8qa8q7bLnLNuL2BNk5GVmUGLMeyqbIvce23pDgAunDKEIT3z3Wk1SvKyqaxvCrCghvcu8CnniunD+c7xByT0WtSCUhRFSRCOG63Gk83hk7Vl/O5/KxJWZq2nLGMMTS2G7MwM3l6xi4q6JhZt2h8wt9P0Ub0ZP8ia2r04L4vKuuY2C8pWUKWe1EXnThrkZjlPJKqgFEVREoQzsNU7wPWqR+bzyCcbqKoP3gfUEVpbDTWNLeRmWZ/2+qZWmltbyc4UTh3XH4AL7p9DfXPopLF52Zk0trTSYoxP/5MzFgrghyePjrvswVAFpSiKkiCcBKzry2rc+ZScQIV9CYjsq21qm34dLAuuucVSND/2KJXPN+8HYPygkoBzZGdm0NjcSnOrca0ngKG92mbDHd6rIOC4RKAKSlEUJUF48+Dd995aADLtj36ZJ9VQvHBcid4Bt012H9SEwT24bNpQAK582Bpo++1jRwWcIydLaGxppbnFkOMJLy8tyGHjnWey8c4zAzKXJwpVUIqiKAnCm/3bGXfkuM0uuH9u3MtrU1AeC8qO4oM25egQrB8pJzODppZWmlpaA+Z0SjaqoBRFURJERV0T00b2AqwBs9A2KDYcxhh+978VLNq0z2f9ve+u4ZQ/f+CTssiLE8E3qNS2oOqarCi+jAz7vL779y3ODTiH4+JrbG4lJyu1KkIVlKIoSjtZsHFf2CwRVXVN9CvOZfygEmoamt2p1wE3rDsYDc2tPPLJhgAr66EP17N2dzUrd1YGPc5xG47qWwhYLr7GljYL6ga/sUxBFVSWZUHtrmqgMCe1I5FUQSmKorSD/TWNXPTAXG5+eVnIfSrrmyjJz6YwN4vqhmb22sps4pAeVDc0h7SEavxCxR0cC8mb6NWLk6H8wL7F7n5eC6rIz6XnTKPhxXLxGeau28ukYaUhry0ZqIJSFKXbcNlDn3LTS0tpaonsZovEwx9bWcM/syPi/DHGUFnXTHFeFkW2gnIUz+j+xRjjO9utF+/AXqcfy6vMqkMcd++7ViBGmwVlTZuR5elLeudnx7t/F+YEzoTruPXqmlqYPKxn0HKShSooRVG6DXPX7+WJeZuZfOvbMR1X29jM0/M3+yRbvW+2pQzyg3zkwRr71NjSSt+iXApzs6hpaKa63ukjsoMYQlhCXlfgswu2ALBpX1sG8VAKypmcsDA3i8KcTCrqmthX00hPzyDbA/sVuX8Hm4bdGxgRzMJKJqqgFEXpdlTVB//Ah+KWmcu5/sWlfPfxRQHbenk+/l627reUxZCeBbYF1eIqFscaOu6u2UGP/cFTn7t/3z7LmoPJm33c6wJcurWC9XuqueRBq7/qnEmDACjJz6asuoEKux/My7rfn8Ha22cELXuunSIJVEEpiqIkBWegbLTsqWpwFcnCTZYb760Vu2huacUYg2N8hLJmtldYCmpQaR5FuZmWBWXve+WRw939grkbC4JYZd7s49V2QthP1+/l7Ps+5qS7P2DeBivir3ehpYxK8rKZt95a16/EV0FlZkjIsUxfP3KE+7cqKEVRlCTgtZq8KXw+WrMnQEk0Nrdy+O3v8P+e/wJomwTQOU9NY4sbsu21bLzstjOY9y/JozA3i7qmFirqmsjNyqB/SR4XThkCwI7ywEznjqyONdTc0urjDnQsqCVbygOOzc+xPus98rPdLOrBovVCccSoXu7f/oot2aiCUhSlW+CkHepfkusGDazcUcmVD8/n9tdWBt33hc+20tJqfPqedlbWu31JJXlZ7Kps8Alg+Pvstdz15io3Yq9XYQ7FeZYlsqOizo2ku3iqldVh3Z5qn7KNscLCLz18KIcNLbXlaabcowgdS+wPb6wKuE7H0irJb4vYGzewR4S700aBJ7S8Zwj3ZbJQBaUoSqdj/Z5qn/DraHDSDg3vVUh9Uyt1jS3uGKaP15b57Ovth/G3kHZW1rNlv2VROVF4f7GnTH996Q7uenM1f5+9jn01jZTkZZGdmcFgOyhi3vp9ZNuutWF2PrvtFXUYYzjgxln8+5MN7Kiop6nFMH5QiZtBvLy2kT+9ZU162Lc415UpWJS645ZzrKZzJg1igJ36KFbysoMHgCQLVVCKkkD+8MYqXvxsa6rF6FIs21bBSXd/wCOfbIzpuL3V1kd9RB9LMeyvbXStjd1+Ewr+0BOk8Pwi6/k5eezKa63xT9CWmeGt5TsBeMqOuAPYUFZD7yJLSTjKaG9No+t261loKZKbXlpmT29h+O3/VrB6VxUAYweWuMqmvK7JtZr2VDXwyuLt7pgnsIIeVvzuK1x3/AF894QDATiwnzUWKh4h9alCFZSiJJD731/Hz55dkmoxuhRbbevlsTkb23XcoUNKAUtB7bf7dSrrm0NaZHe+brnRjj+or3VcTVtf0HPXHQlY45oAPvxyj7vtozVlbsqhYb0Ds3/nZrVZJ1/716fu3y/YCnFIz3xKbAXlWH+ODADPLWpThpkZQkFOFtfPGOu6EJ1wcu8khdFy3mGDGdmnMObj4k1cFJSIPCIiu0VkmWddLxF5W0TW2L897fUiIveKyFoR+UJEJsdDBkVJN7wt10TM/dMRYnWPpRdW/9Fmz7igYPz46c99LKGy6kYypG0Qa3ltk4/77sM1lpsvVFTeyD7WB7+irokTx/RldL8iDh/RiwEleeytbgiaFWK0bcV4Mzh8/H8nBuy3fHtb6qJXv7Bmuu1blEsPux9pT1UDInDYsFJXKX6w2lKGb/7kuODy9rausz3P+p5LJjH7FyfEfFy8iZcF9Shwut+664F3jTGjgXftZYAZwGj737XA/XGSQVHSCu/H71dh0uEkm+cWbmH8b95kuz2oM5V8sbXcZ3bXf3+ygb/bA2BDURNCgfjzyuLt/G/Jdne5rLqBXoW5rtusqr6Zu95c7W53ghDW20ELh4/wzaLQrziXkrwsKuqaqGtqcQMIdlbWM2fdXibfZg3+vfqoEe4xpQWBYdp9itoi404fPyCk/FmZGa4FtaGsBmNgQEke4wZaczjN27CPotwsDupfFPT4ob3yufGMsfzlksNClpHuxEVBGWM+BPb5rT4HeMz++zHgXM/6/xiLT4FSERkYDzkUJZ3wTki3oawmhZL48s+P1lPb2MJLn29LqRzPL9rKV+/7hL/PXueu++3/VnDXm6tD5qgD3/FAOyqCK9lHP9ng/v2B7XYrq26kT1EOJXZEnb+l5DwvJ+HqDWcczG/OHudu75GfTY+CbMprG6lrbHEzSPQqdAIZLLm8Id1nHTooQDZv4MG1xwfOx+TFUabvrdoNQEFuFoW5WW6Z1Q3NQbNBgJUl4trjDgjqXuwsJLIPqr8xZof9906gv/33YGCLZ7+t9jofRORaEVkoIgv37Nnjv1lR0h6nUx5gWO/U+/P9mbl4e+SdEsjv/rccgMVbrEGwXqVUXhfaJerd9t+5m4Luc8v/Vrh/f/fxRRhjKK+1Uv447rbq+ib6FOVwxiEDyMwQVzH980NLufUpzOWK6W0DajMyhKLcbF5evJ2axhYKcy1Fs+jmU3zKvva4Ufzs1IO4//LJPmmFXv7+0dx5/iE++/YubAvjnmSHlHtx+qlW7bQCJwps5eZMv+5YU12VpARJGMsJGpMj1BjzkDFmqjFmat++fSMfoChpxl6PBRXOIkg2NXYWgngOwmxqafUZK/TK4m2ssaPRQnHOJKtdOtxW3m+v3OVue+CDdUGPAXxck8Em3Gv2i1qrbWzhiXmbWbhpP3PX73WPqW5opr6plYE98ulblOtGxTl9h4N75pOdmcGDV05h7g0nAda4KYC1u6vd8UIiwtThljtw451nkp2ZwY9OHs2MQ3wdQ5OGlnLptGE+6/oVt4V//+zUg9xp2b3zMB1zYB/37wJbKTa3WjJeakcWdlUSqaB2Oa47+3e3vX4b4L2rQ+x1itKl2Ge3yAeX5secZidRNLW0um4xb8bsjvDfuRsZfdPrHHDjLMBSxj9+ejGn//Ujn/1+8dwSfvbsYnfZ6Ut6dM5GjDH82+OWCzfH0tb9tYwfZFkOGUHcW04Y9wWTh7jrnCkxehfmkJOVQW5WBuW1Vuh2SV42/Upy2WlHu2VlWgrHmX32K+MHuDPUOpkdwDcT+OPfOoLFvz41pMyhyM/JdM/TtziX755wAADfs38Bpnr6wgr85mcKN6dUVyCRCmomcJX991XAK571X7ej+aYDFR5XoKJ0GfbWWFFj/UtyqUsTBbVtf507uDPaYINI/OqV5T7LjqvMa1FV1Dbx/KKtvPjZNrfvxzsd+px1e93w7wP7FYVN5rp1fx0H9isiNysjaJohJ0nreYcF9Bzwg5OsMULFeVnsqLAUWUl+Fv2K89yxUOW1TUGDGwB+cdoY9+8WT3RcXnamO6g2Vn53zgQAhvcuIC87k7W3z3AtKcAd2OvIDW2h4/VNnXeMUzTEK8z8KWAuMEZEtorINcCdwKkisgY4xV4GmAWsB9YC/wS+Fw8ZFCVRVDc0c/dbq91xNNGy157moCAnK20sqPVlVoTa8N4F1DT6Top3yp8/4F47I4JDdUMze6tjG0ezvSIwt9zireXu38599IbeP/ThemoamuldmMPAHnkhgx9aWw27KusZVJpPz4Ic19Kav2EfI65/jU17a9jmZhHPZ+XvfIOLLz/C6lMqq27ktaVWu7hHfjb9S3LZVm5ldKioawqpbHoXta0vzY9PGqALpgxh451nutZRVmaGT+DDgJI2N+AI2x361YmWJTcqDcYqJZJ4RfFdZowZaIzJNsYMMcY8bIzZa4w52Rgz2hhzijFmn72vMcZ83xhzgDHmEGPMwnjIoCiJYtYXO/jbe2vD9ot4ufLheYy4/jWenLeZ3kU55GVnpk1Ld7fd8h7Vp5Dahjal+cXWCtburubPb3/prlu1s5IJv3mTKbe9EzIbQWOztT7HbuU3NLewI0j4+lWPzA+QobqhmWNHW/0rU4b3pLaxhYLcTAb2yAuq5ABW7KikqcXQqyCH0oJsd6Dt8/ag1bP+9rFrQQ0szSM/J5OHrpwCwAlj+vr07TjkZGUwdkAxVfXN7KysZ39tIz1DWFD52ZmU5GUxdkCxa40lmvMnD+bpa6ez/vdnuG7Hey87jKW3nMYRo3onRYZUoZkkFCUCTuv/8U83R7X/R2va8roJQl52RtItqPqmFqrqmwIGaTqus4Gl+T4W1BceC8fBmym7PMTEek5otjP4taKuiSfnt92n2sZAV90rdvTg8u2VbNtfR4E9sV5NQzOFOZa7ray6wZW9oq6J0//yISOuf4373rPGSA3uaVlQ5bWNbN1fy7MLt7rXd887X1JakO1GwJ02fgCrbj2df319qivDr89qCx/PzsxwB+Gu2llFfVNrSAtKRPjilq/wxk+OS1qeOhFh+qjeZGT49rc5CWi7MqqgFCUClZ6w5t1VwVv2odhb02BbUG0Kak9VQ8xus1gZ+6s3OOSWtxh5wyx2eqwRRyn1KcqlvqnVjXjz9iM5fUfefqDyEFNKONkcDrJT/VTXN/so6B0V9e61Xzx1iHsux823vqyGHvnZVNQ1UdvYYs0Em5uFMW39K1f8a54bZv2GnfPuK+MH0Kswh/21jUEH9vqHTuRlZ/rMf+RVLqeN689we6zQM/MtSyyW6SmUxKEKSunWNLe0Mnv17rDpYLzK5Z0Vu0PuB4GJOVtaDfnZmdQ3t62/+MG5TLntnXZKHJ61u6sZcf1rPuvW7G4L965tbHHdVAC1QSy7f320HoDtnnmK9oWIqnPWH9DXskD8gxu27a9zpyGfPqo3h4/oSVVDM/e8bfV19S3OdRVUTWMzBTmZ7mR9+2obeXflLpZ6pj93yMwQSguyKa9t4qn5bcMqHVfjxCBjirw4Y5h+dNKBiIg7BbujAGdMCJ3hQUkeqqCUbs3XH5nPN/69wJ2NNBh1TS3uB/3T9XtD7gdw2O/e9lmecchA8rIzqLNDuqvqm9ysEo3N8e2Xqm9q4ZQ/fxCw3qs0ahqaKczNdDvknf6gnKwMpo20JqpbbLv2vOONQk3K51hWQ3paH3hnGopvHzsSsDJoOOOhhvcuYHjvQlbvrGJfjVXuXy6ZRI/8bHZXNfD55nJK8rPd8Ui/n7WSax4L7KL+uj0bbc+CHJ+xZmceOpBVt57O/50+ljvPPzTEXbI469BB3H7eBL5v9yNldkP3WWdAFZTSrZljz/sTykIAqGtsYeLQUrIzxf0QB6OxudUNoT5xTF+ev+5Ibj1nguXia27BGONOHQ7xC/N22BkisMDbf1Tb2EJBTpbbZ7RiRyUVdU00NrdyxMheDOqR5w5kXbhpHxMGW+ON9nkyeHutTSdIwbkvzsyzhw4pJT87k3V7qvnDG1a+u2G9Cim2c9nNthOdHnVAb3rkZ7v9XeW1je5Eft4sC698/2h+cdpBQNskevM3tjUq/u/0sdx76WFkZAjfPeGAiPMfZWYIlx8x3CejuJJ+qIJSFGBXZei+pbqmVvKyM8nJzKDBY/X4uwW9CuKhr09l6oheZGYIedmZGAMNza0+/VmhsmaDlbEg3PZgzFzim7rod+eMB3ytn5oGy4126BBrhtUt+2pd5dCzIIcS291W3dBMWXUjpx48wOcc6/dUM/KGWVz58DzAUig5WRlun82mvZZ12Lc4l1F9C9myr9ZN99O3ONcnZBqsAAAn3xzAr84a5+aO+4+dxmji0FImDi3ltPEDGNargDMPtTI0OIoMrGko/K2gWLnnkomAb+YGJbWoglK6Ld6BpOHmzKlvsvptcrMzXbdcY3Mrh9zylk/o+XZ77M7j1xzhM7jS6ZBvaPJVUDVBItzACtWe8dePmPCbN2O6nv9+6puX7uKpQ8nJyuCZBVvcYAgnEMFx8d315mq33+XEsf0oyMnkozV73FDxEX0KKMjJdMcbfb65HLAiFRuaW9yQbCe/nRNN16col54FOW5i17EDrCCKa44Z6crXz1ZqTjaIotwsxg4IzC33wBXWjDwH9S/mw1+e6AZkXDhliJvZIVRG71g477AhLLr5FP511dTIOytJQRWUkjLmrtsbMJNpMJxBmN4xOvHAO1A03HxNdY0t5GZl2BaU1Zf07spdVDc089CH6939/vG+paz6++W4y8u2XrP65haf7AnBXHyV9U2MufkNd9k/r1w4Jg4pZUBJHhvuOIP1vz+DPFuhbt5Xy4O2nPtrG93+NIcn51lh4QNK8vhsczn1Ta18bltVzoDYfbWNNDa3+vRLPbtgC59tLmd0v2KK/M7ZpyjHzvzdxP6aRjczQ1ZmBkcfaI3d+ZUd6j3LHjDrtRhH2FbUHy881E0zFIw/XngoC246xSdCryP0LspN+TTnShuqoJQOUdfYwt9nr43pQwqWO+qyf37Kpf/8NOK+Ty+wPqDPLdwSdPuXu6oYcf1rzA8T6BCM/bWh3W3GGO54fSWLt5TT0NxiufiyMlwLypmW++CBxe4xufYgUCeizcHJPF3X2OITrl3dEBhBt2ZXtc9yuL4xf3ZV1jNmQDEiEjBm5m/vWVFzZdUN7nxEf7zQN5AgPyfTDbdetNHqKxtUmk/f4ly27a/j/Ps/4W5PI6GuqYVt++s4eGCxe40OPfKzGVCSx46KejburWVoz7YpH5zksE7anrsuslxrg0vbFNGj35jG7887xMeNF4zcrEwNCe/CqIJSOsQVD8/jrjdXuy30aPmRPdPp+j01ET/CjvvImVbbH2cG0osfnBuTDE44NQSGR7+2dAcPfrCec//+CQ3NreTaCUadPqh1e6y+lgZPhohMEUb3KwpQDk6LvL65xWfmVK8Fta+mkbG/ep273lzlc+zuqjbXo5PmJxQ7K+sD+ngcF5jVD2bYW91IH/uD7v34//48axqI28618sI9YzcG+hfncuiQHizbVsGybZXeU/PkvM3UNbVQWpDjk5qnODcLEWFwaT51TS2UVTe4bjmAG884mJvOOJijDrD6ek6fMICfnDKaP1880d1nRJ9CvnaEb+ZvpfvR7RVU5576OvU4EV/emUmjYbRnnpxTg4RGe3GSelaEmCPI28keC0/Yrq1RfQoDzj3Xju4b1COP+ibLgsrNbrOg1u62LB2v5bWzsp7+JYHRY46Lr6K2yY0aBN/xVSfd/T71Ta18ut6yAq89zprIzhnQ2tDcwqgbZ3HE799l9urAsVhfbC1nT1VDgDXxl0smcdm0oVTVN7N1fx3NrcZnRtcvb5vBs985ksvsaRv872VWZgaDS/Op8WQ+d6ysjXbEntOA+ObRVv9Srq2QD/A84wM9fURFuVl8+7hRPmmHfnLKQV0+bY8SO91aQZ39t4+5LAoXU3vZXVnPx55R9V0Rb0aEUNkGguF1g+2taWTE9a/xjX/PDxgb1NzSytsrrHmCKiKMxcmJ0A9R39Tio1BKC6wkoevLali0ab87/gfawqUN0GqwLahMGppbaW017rTgjuW1sayGxVvKg6Y0ciyoXbY1NMWeO8ibn88/lZAz1ue6xz8DfF1963b7ugE37a3hq/d9AoD/7BMiQt/iPFpaDcf+cTZg9Q85OOOfHAvI29/z8vePBnyzKpx56EBe+9GxXO6xbpx+qSttmZ2ABW8i04NCWL+KEo5uraCWbqvg0/X73OkB4s0FD8zhiofnhZ3bJp257701/CmCZbS7qsFVDM48POv3VPPb/y33iZLz543lOxnkN1Zl9uo9HPzrN3zWlXlmpQ1lQW2x0+00trS6QQzBOP8fc3wi44rzsjj6gLaQ4gV2H1ZVfRMfr7UaFo711rMwx3bxtbCtvM51+znBFc5Edl/1zBfkUGhHzDkDUM+wJ7LzKjN/y8dr5YCvAvO60yrrmzj+rvfd5W8dGziFuH9QhP+5vfQtzuW64w/gwilD3BlevW7DMf2LKcrN8nE9OmWO6F3ALWeP4+6LA/uU/J+1okRDt1VQXtdesFQqHaW+qYUt+6yW5V1vxeb+SgXbyutYsNE3yOBPb33JfUHynHmpqm9yXT7OBHg/e3YJ//5ko/vRDkZ2ptCzMDAhZ0ur8WkwOMlGB5fmB50jyBjDy56py/33GXH9a27qnxW2PO+tsiyy2gYre/b7vzgBgCZ7ltI/vhH4vM48ZKDbB+VYV4cM7kF1QzO1jc189wnL0jludODsz05aHSdi0Qmvrvco07rGFgb1yKMoN4uFN5/iE0nW1NLqO9jWYwX+4tkl7t+Hj+gZ1N3pP8mdf5ShP9fPGMufLmrrDxriCXBwBsA67jzAzfwtIlx99EjXCsvIEPoW5zK8d4GPUlWUaOm2Cqqyru0lb26Jfz+Ud7yLMz9NMtiyrzas5RKKo+98j4semOtae94s1HUhZl5tammlvqnV/Wg50zc4x37/yc+CHldZ30RTi2HGhAHcf/nkgNa112pzlF6fohyaW02AC9Bxkzn9Gd777r0Gr/X1zUet9DlW7rcsRtiuqDeWWeOBnJDoN35yLGcdOpC5N5xkW1CZNDS1uoNWh/UuoNW0ZeeGtiwHXhwF4QSSOHMKObK3thpqG5s5f/IQlt5ymmvh3H6eFbCwt7rRd7Ct53lkZbZ9+E8d1z+gbIBzDxvEUQe09e/0C9JPFo5BpW37O5bekZ7zhQvx/uD/ncCbPzkupvIUxaHbKqit5W2Tz4VyHXUE73gXpxM50SzcuI9j/zib38xcFtNx3snhfvzMYgDX+oPQediq7WvsV2wrKFshOMrfsTT8cTIXTBxayoxDBjLnhpNZestpboLOPR73kRPp5ny0/ZVlpe1iO9Ye/e+1oPZ63IPLt/tayWXVDdQ3tbqJScGaE8na1kifohzGDijhvq9Ndi2C3GzLxeeUOcR2YXmVYo8g8wj5B06U5GVb1pjt4ttWbs1yO7A0z8fScFL9lFU38OGXe9z1dR7FW1XfzMShpcy/8WS+HcS9B5aC9M7QWhxjfczKzODSw4e6sjtsvPNMNt55ZthjC3KydFyR0m66tIJqaG7hb++uCTonzZItbR+sygQoKO/Az8owg0DjiTND6LsrfaO8FmzcF9aqWm+HTHvxyhxKQTnKYEAPS3k41o63Qz9Y0IAzMNObcbo4L5v7r5jC0Qf2ptxrBdnHO1ZHbZPvs3SenZMLziu3V44PPB94gFU7rHFMTv/QVUcOJy87A2MMuyvrXaXrxXHxOQp4sF3mRju9z72XHRZwDFh5374yvs26Kc7LoiAnky/tsVSP2xkgBvkNSO1tK+V9NY3srmrgwH5FPhF19U0tfLSmjG376+hXkhfWjXb4iF4cd1BfLps2rF3utl+fPY57LpnI5GGlMR+rKO2lSyuom15axt1vf8nDH20I2OYdT1KeEAVlfcTyszOD9p0kAqecxuZWVyE9s2AzFz0wlwc/DD0brJMRevygEjbYU4J7lfb+muD3x1EGjoVQ29jC/ppGGj2Ddp1+H2MMFbXWBHqrdlaRlSE+rXGHHvnZPtGAjtvQsaBqQ1hQjrLwsaBq2iwxJ2v3WXYeNyfyrMDuHxraq4D6Jkv57KqqD9pPk5+dSU1DMxV1TeRkZrgyLdlSQV52Bmfb5w7GCE9EW3FeNkcf2IeVtpJ0Ji866kDfMGunb6e8rol9NY0M7JFHQU6m2+By+viiCfLJyBD+881p3HH+IRH3DUZBThbnHTZE+5KUpNKlFdTzi6y8YMFsh7LqBnoV5lCSlxXRglq7uyrmxJ2O1TG0V76PNfXOil28sWxHTOeKukxb0eytaXRb9U5mguowStJRCMN6FVDT4EwL0ba/14J6e8UunrZnTHX2aVNQzay3p5K45Wwrjc3tr60E4NmFW5j4O2sCvc83l3PKwcH7S0rysn2nh2gM7+KrcC0oqyPf+yzfWr7L/dvpBxzWy9rPmRbCUZJOv8zE373Fsm2VQcczDe1VQGV9M5v21lCSn0WJHZCwYkclpfk5YT/eYzxh1sV5WYzsU8juqnqaW1ppbjEU5GQGZNZ2zl9Ra/VB9SrMoSAn031Gj83ZCLQNslWUrkaXVlDHjrb6JYK5t6yUL1a+sHB9UHuqGjjlzx8y4Tdvui6ZaHD6UUb1KXI/uE0trXzrPwvdsS3xptrOVA3wpT0DaYsdrRjOzehYSINK890+n6oQLr5v/2ch17+4lNrGZldpOx/zmoYWXlm8DYBj7Hu/yJ5ewj8LwaBSX3eWQ3Felo+CchSSk/0gwIKy3W1DglhQzjMY3rvAnTTPiTh0ZoJ1ot78p9HIzwnsNxljJzxdsHEfJfnZHDK4h7ttZ4Scgt6gguzMDHoW5NBqLHkr6pqCRt856yrqmthX3UjPghxW7qzigy/30NraFr3o1HNF6Wp0aQXlfKD2BHGBWB3huQEuJX8+XtvWd/GhXz9GOMqqG935g5yPpjeaL1RkHFjusDnrymiNMRqvtrGFiUNKEWnLFed8wHdWhHYD7a9tpDgvix752TQ0W9OAe4M8grn4xv36TddNWpqfTU5WBrVNze4UCcN7F3LMgX3cfqZWv4wdg0PMq9TcaqhranEHzbZZUDk+yw6O4h3QI48M8VXEe6obOO6gvpRVNXgUlOVqcwI4HCVwoCfrAQQfT+QoqLLqRkryssnLzmTt7TM4YUxf7vLLa+fPwB75nD95MFdMtwa4Oo2dFz7byvOLtrrjrbzkZmWSn53JnqoGqhqa6V2Y40YxfumZJXegjjFSuiidSkEZY/jGv+cz4vrXImbBbmxuZZVtRZRVBX6c91Y30Lsol9L8nLAW1BOfbnb/3hPkPKEoq26gd2EuJfnZ1DW1WGNZvKHn5aFDz296eRlf++c8nvUkR/377LUceOOssEqrpqGZ3kU5FOVkuYrJ+WCHyuFWUdfExr019CzIcdMW1TS0sL28jtKCbIrzslwLyt/NefPLVrRgkd3p7/QXDeqRR3ZmBqUF1kR0c9aW2fnYivjBiQcyaWgpF04ZElSeFXauutteXQFYfVAZ0ha+HeDis8cH9ci3pnzwj+LrU5TjE5btDB51FGA/u6+pJC+bL2+bwapbT+e9nx/vM8jUoW9Rrtsv5LjfsjIzePQb07goQlJTgD9fPInbzrXccecdNhiAP7xh5d47eWy/oMeUFmS7KYVKC7LdPqRfPv8FYCV8jVcmb0VJNzpVzV64ab87E6cz0j8U3g7y0BZUDhvKavhsc3lIi2ag/aHqW5wbUzReWXUDfYpz3IzNVfXNrlsJQs9+Cm3TH1z/4lJ3uuy73lxNc6txgw6CUd3QTFFuFjlZbdNCOH0ywZTrjoo6jvj9O7y/eg+lBdkU2m6t6sZmlmwtZ+yAYkryst18cC9/vi1oucV5WZTXNrF0WwWFOZnMsDMlOFbYj57+nH01Vh/KL74yhpe/f3TI/Hl3XWgNEHWCCmobWyjMyXJdl7WNLSzatJ/VduOjsr6JvGwrDVFzq3Eznxtj2FvTQO/CHH55+hj3/P4ZG7ypfXKyMsjLzmSUXzZyBxFxU/Y0hslYEQ2Hj+iFCDTZY/BCRQD2yM9u6y/Lz+b4g6yBwE5IvKYQUroynUpBefsfbrVb2KFwxsAU5mQGfJydnGx9inLdvGhO6LM/ZVUNTBnekxJ7qupoeX/1Hkryst1O+Kr6Jn7xXNuo/1CRV/7TVmz0G0sUqh/MGEN5XRMl+dk+Wbcd6yfYfEdH3vGeO1i0oanVtaBqG5rZXdnA8F6FbCuv452Vu2lpNa7F9I/LJ7vnmDayl9u5v3hLOTX2hHiOTGC53xwFFYlhvQsY1aeQuqa2Qb8FuZnuYNcvd1Vxwf1z+MpfPgQsF6aj7CYOKaW+qdWat6iinvqmVgaV5vPd4w8gQ+CyacM6PCbH6c/M7qDVkpEhOF7PIT3z3Xvmz4Aeee4wgJK87AAF6wR9KEpXpFMpqAbPmJrR/cK3HD+yk7SOGVDMnqoGn9RGzviY3oU53HmB5TLZVRXcotldVU+/4lyK8rKDzt8TjDm2dTdn3V4fC8qbBcG/s99hq91P9R07m/X+2sagsvtTUddEY3Mr/UvyyM3OdPuSNpZZCq6mscVH+XkH5wJMH9XLHVBcbYdS9yjI5sQxVov935+0hep7xy9dd7wlp9dF5QwEddxR9U2trNtTQ2mQLAvBsCa6a3TlLsjJctMFeScIbGppZXdVvev+O9MTQv6bVyxlevSBfRAR1t9xpivPPy6fzNkTB3HjGWOjkseLY8HcfOa4mI/1x8l199x1R4bcZ9zAthlmxw8u8VGMIkSl9BWls9KpFJQTKTVxaGlEd5vj2z94YAkNza0+U3o7ec1KC7IpsN1H3qwDDmt3V7FuTw39S/IozMkMOgOqP7OW7uBr/5oHWP0dxbYF5ZTpTHntP3i4vqmFitomltkZD6aO6AVYlqDXigoVEu9cX/+SXDdLweZ9tTS2tDJ+kPWRc/qQlm2r4Mg73nOPPXviIH522hi3Fb+vppGG5lZ65GdziZ1B4O63rInqXv3hMQwuzef+yydz+vgBHHOg9cH2RpI55xnSs4Cpw3u6U1MEG7QbjD5Fue7zqKxrsge2BloYH68t44utFYwfZEXTOR/rE/70Pu/Yg5VH9wt0151xyED+dtlhXHvcAVHJ4+V7Jx7Iez8/3g2Y6Aj3XzGZP14QfsbYg20FdfDAkoDBw7/8SuwKVlE6E8nJwRMntu6vIycrg/GDSkK65MA3rHz6qN48MW8zu6vq3Zxx5XXWx69HvvVB61OUG9TldsqfLTfSyQf3Y1t5HftqLEXx7spd3PvuGl747lEBHdTfe6IthPydnx3vfpx3+iUK9e/zuu7xRby/ui1KcOyAYnKzMthf28j7nvl/QrkZnSCI/iV5rotvjV325GE9Wb69ksq6ZkoLcnzS/vzxgkO5cMoQMjLEtVKckPCS/DaXUl1TCz3ys5lgh1bPOGSg29cEcPjIXu7f3um/va6rI6Oc76coN4tVO6toaG5hX02jm0Vi7IBiN/AF4Bv/XgDAJDu7gb818fUjh8d9YGlmhoTso4qVgT3yufjw8MEVzjVNtV3RAK98/2j21TRy3EGBiWkVpSvRqSyobeV1DC7Np09RLuW1Ta4iuumlpe6cQdA2R9Gt54x3Q3C903t7I7/ACmH2j3L73hOL7G25HHNgHwpzMl233I0vLWXJ1go+ChKo4QwoffLbR5Cfk+lmKnDO37Mgh+xMcVP4AHy8psxHOYE1KLRnQQ77axpZsqWcQT3yGNor3yf824uroIrz7HmLWtxAjHG2BVVZ38T28jr+74Wl7nFnTxzkzgDb15bdGcvUIz+bEb3bMiBM8Xwk/fGGaXtVgmMpnjy2X8jIPX8c9+PLn29j6bYKsmz5/McqORxmu8q84db3Xz6Z350zIary0pkjR/Xm9+cdwo1nHOyumzi0lBPH9iMzQ7M6KF2bTqOgnp6/mc827ad/Sa47v011QzNNLa08MW8z3/7PQndfZ66avsV5bj4z78R6jhXiZK0eM6CYT9fvY976ttlOZy21MlvP/MHRiAiFuVmui8+xKm5+yTcp65x1Vjj1FdOHudNZO/06jgIpyssiPzvTx4K64uF5Puf566WTXPn21zZSWd9Mr6IceuSHHlTsnL9fSS652RnUN7W6gQZO2p6q+mYetbMPgJXs0zsgtZ9tfTljlkrystz7B5YlGQpvFgRv5mzHNXfjmQdHbc3cffEkAFeROh/iuy+axFcnDmL+TSfz26+Od/cfa7vbhnuU6VfGD4iqrHQnI0P42hHDgg4cVpSuTqdw8VXWN3H9i9bHavKwnp7AgyaffqHG5lZysjLcsPJ+JbmuS807wdp+PwtqqB0JdclDn/Luz4/nqkfmu/s6GQ8Kc7PcQaJDSgtYtq3SnTkUrIi1r/3TUjSl+W2uJic82lEghblZVNqK4qYzD/bpUzp74iBaWw0zJlius16FOeyvbSJThKLcLHZVNvDeNt9EsFX1TWRnZth9ZbnkZbcN7nSUoJPpYV9NI++tso4PNYHcYcNK3WnHnftz+RHDeHP5Lr42bVjQYxxuPWe8NaDUo9TuuuhQvtxZ7TODbiT8xyAdMdJSeD0Kst1w7CunD6ehuYVvHD3Sx8360S9PpLy2ybUKFUXpvHQKBZWblYkTwrC9os4NPKiqb/bpeN9b08DAHvluWHnfolwKc60giN2eIIkNZdVuRmmw0hE5nHz3B+7fN5/Z5lYpzMlyQ5jfXGFZV94M2V4F+MOTD/Q5LjND3Jx4RblZHNS/iC93VbNuT7UbDPDvqw/nRL/BmlZqm0pyMjMY2qvAdTE2NLeQm5XJR2v2cOXDbcr0JPv4otwsqhuse5OblcGoPkWIwOIt+1m7u5r/O32sG33nz8g+hQEK6tZzJvDbr46PaAFdeeSIgHX9ivOCZgaPxLBeBe64scuCKMaMDAka5DC0VwFDewWsVhSlE9IpXHy5WRl8cv1JjOpTyD0XT3ItqMq6Ju6Ytcrdz1FMm+xEqY4rbkCPPNbbWbrrGltYu7uagweWuB/ckw/uF9Dh/N9rpvmku3ECCL7cVeWOX7FyqVkW0Do7IOHJbx3h4+7KsKdacJKoFuVmccf5Vlqclz7fxuV2xJ+TI85L/xJrDMzemkaKc7PciLpddtqieet9Z8A9eKDl6irKsxRUXVOLZVHlZDKkZ747DceIMDOcevucHAWVkSFJz1bwxLeOAKzoNXVvKUr3JOFfHRHZKCJLRWSxiCy01/USkbdFZI39G7r33WZwaT7v/eIERvQpdD+cVfXNzPdMU76nqoHH5mzk77OtqSWcQZmj+xWxvbyO91fv5uBfv8Fnm8vd0GuwBl3+++rD3eXjDurLsX5TdztKcY2dA+2rEwcBbSmLZtkZyoNFeJ1wUJtlVFqQ7SqSBz9oG9Pj7T9xmD6ql3tdPQqy3UGZThDBtvI6nwn3HJmLcrOorm+mtrHF3T6mf4mrJEf2DSzLwQnZhrZ0PqlgaK8CHrxyCs+HGSOkKErXJlkuvhONMd6Qt+uBd40xd4rI9fby/0V7Mic7Q2V9EzlZGRw3ug/vrNxNWXUDv5m5HPDtqB9QksecdXuZt6FNmR19gG8G6MwMYdaPjmV9WTUnjgkMBhjWy/qoL9hoZec+5sA+zFyyndP/8hHTRvRyFWWweYS8iVH7FuWSkSEU52ZRZfefPXTllKARWSd5XH69C3Pc8TJOYtGNe2uYNLSUJ7893U1zBJYF1dxqKK9tJN9W0hOH9OCdlVak45gw6XGmjmhrK3Q0W0JH6SqBDoqitI9UfYHOAR6z/34MODeWg52W/d7qRhqbWxlp522rbmhhcGk+4weV8OS3p7v79++RR1V9Mw98YFlW3zpmZNCItHGDSjjr0EFB084c0M8qw8mTd+LYfu7YFEc59SvODeo6m+CxSpzO+5d/cDQA91wykdNCfIi9brWqhmY3jHp7RR3GGDaW1biuQe+08s5+a3ZXu1akE+zxrWNGhu1LysvO9LEuFUVRUkUyLCgDvCUiBnjQGPMQ0N8Y44y03QkEzF4nItcC1wIMG+bbSe642xz3mjthXkMzu6vqOWui78ymzgfb6Tu6+azY09T0K84jO1NoajFk2ClmRvcvZqE93xHA3BtODnpsj4JsNt55ps+6A/oWseJ3XwmaIcHL9TPGcufrq/jqREtxluRlsb28jrnr97K/tiloyqdDh5QC1pQSztilr0wYwModlfzgpAMD9vfn6Wun09wS21QfiqIo8SYZCuoYY8w2EekHvC0iq7wbjTHGVl74rX8IeAhg6tSpPtsd19Mn9kBZJxfb3W9b6XgG+s2G6p0d9ZXvH93+CzmwD7NX76F3US6ZGeJOvQDWrKaxDpyMpJwArjv+AK47vi1arbK+mcc/3czj9jQgY4Ok3BnVp5A+RTmUVTdSalubRblZUSvm4iBTsSuKoiSbhLv4jDHb7N/dwEvANGCXiAwEsH93hz5DaJxUPv7Tc/sve8fVeBOdxso+e/zUcDtY4fzJQziwXxFv/fQ4vnZE+DFC8cKbsWFUn0KmjQyMqRYRN9ghVPYFRVGUdCehCkpECkWk2PkbOA1YBswErrJ3uwp4JdZzf/3I4e7fg0rz3EzVYGVE8OLk4Ovo1NgH2NFvTh/Ngf2KeOdnxyd1Th5vVNtDX58aMvz7882W6zHeuegURVGSRaJdfP2Bl+yPZBbwpDHmDRFZADwrItcAm4CLYz3x4SN6udOLD+tVwMg+hdxgZ5sY4JclITcrk9m/OCFgLp1YufuiicyYMJDDR0SMik8YpQU5PHDFFOasKwuYptzLNceM4p53vnSTuyqKonQ2EqqgjDHrgYlB1u8FgkcURIkT+JCXneFaEdNG9mL+hn1u0lMvTqRfRxARTh0XEM+RdE6fMIDTJ4QPwf7xKaO5+PAhDCiJPYuDoihKOtApUh0FY/ygHhwyuAdXHTXCXffUt6dTXd9MTlanSJCRcMLNM6QoipLudFoFlZ+Tyf9+eIzPuswMoUeBRqApiqJ0BdTUUBRFUdISVVCKoihKWqIKSlEURUlLxJj0T2kjIlXA6gi79QAq2nH6ZB/XnmP7AGUdKDOZssbrOOeaE11eR45N5HGhrj8dZY3Xsd2xnjvEUt9TLWsijhtjjAkcUGqMSft/wMIo9nmonedO6nHtOda5/s4ga7yOi+aZd/ZrjOaZdwZZ43Vsd6znkZ53OsqaiONCXX9XcvH9r5Mcl4oyu4Os3eEaU1Gmyppex6WizFRcI9B5XHwLjTFTUy1HquiO198dr9lLd7z+7njNDt352iH09XcWC+qhVAuQYrrj9XfHa/bSHa+/O16zQ3e+dghx/Z3CglIURVG6H53FglIURVG6GaqgFEVRlLQkLRSUiBgRedyznCUie0Tk1VTKlUxE5Fz7PoxNtSyJRp+3hYhUp1qGVBHp2kXkfRHpUkED3ekdjxdpoaCAGmCCiDjpt08FtsVyAhHptIlvbS4DPrZ/o0ZEMhMjTkLp8PNWlE5Iu97x7ky6KCiAWcCZ9t+XAU85G0RkmojMFZHPRWSOiIyx118tIjNF5D3g3eSLHB9EpAg4BrgGuNRed4KIfCgir4nIahF5QEQy7G3VInK3iCwBjgx95rSmPc/7QxGZ5NnvYxEJmG+sM2E/51c9y/eJyNX23xtF5Lci8pmILO1qLe9w197VCPOOh3r2Z4jIKhFZJCL3djfvgkM6KaingUtFJA84FJjn2bYKONYYcxjwa+D3nm2TgQuNMccnTdL4cw7whjHmS2CviEyx108DfgiMAw4AzrfXFwLzjDETjTEfJ13a+NCe5/0wcDWAiBwE5BljliRN4tRQZoyZDNwP/CLVwijtJtQ7HoD9TjwIzDDGTAH6JknGtCNtFJQx5gtgBFZrepbf5h7AcyKyDLgHGO/Z9rYxZl9ShEwcl2F9sLF/HRfAfGPMemNMC5aF4UyA1QK8kFwR40s7n/dzwFkikg18E3g0KcKmlhft30VY90vpnIR6x4MxFlhvjNlgLz8VZt8uTbr128wE/gScAPT2rL8VmG2MOU9ERgDve7bVJEu4RCAivYCTgENExACZgAFes3+9OMv1ttLq7MT0vI0xtSLyNlZr9GIgZCu0E9GMb0Mxz297g/3bQvq9rx0l0rV3CcK846/QDa6/I6SNBWXzCPBbY8xSv/U9aOtEvzqpEiWeC4H/GmOGG2NGGGOGAhuAY4FpIjLS7nu6BKuDtSvRnuf9L+BeYIExZn9ixUsKm4BxIpIrIqXAySmWJ5l0l2sP9Y5nEPz6VwOj7MYZWO9+tyStFJQxZqsx5t4gm/4I3CEin9P1WpGXAS/5rXvBXr8AuA9YiVWh/ffr1LTneRtjFgGVwL+TIGLCsKNOG4wxW4BngWX27+cpFSwJdMNrD/WOX0qQ6zfG1AHfA94QkUVAFe2fRqRTo6mO0hQROQH4hTHmrBSLklaIyCAsl99YY0xrisVpN3b04T+NMdNSLUuy6c7XHi0iUmSMqRYRAf4OrDHG3JNquZJNWllQihIOEfk6VrTfTZ1cOV2H1fF9c6plSTbd+dpj5NsishhYjuXyfjC14qQGtaAURVGUtEQtKEVRFCUtSZmCEpGhIjJbRFaIyHIR+bG9vpeIvC0ia+zfnvb6sXZ2gQYR+YXfuX5qn2OZiDxlD3RTFEVROjGptKCagZ8bY8YB04Hvi8g44HrgXWPMaKz0Rdfb++8DfoQ1bsZFRAbb66caYyZgjTG4NDmXoCiKoiSKlCkoY8wOY8xn9t9VWKHUg7EGYT5m7/YYcK69z25jzAKgKcjpsoB8O3y1ANieWOkVRVGURJMWfVD2gLTDsCK0+htjdtibdgL9wx1rjNmGZVVtBnYAFcaYtxInraIoipIMUq6g7Cy/LwA/McZUercZK8QwbJih3Ud1DjASGAQUisgVCRJXURRFSRIpVVB20s8XgCeMMU5SzF0iMtDePhDYHeE0pwAbjDF7jDFNWMk1j0qUzIqiKEpySGUUn2BNn7DSGPNnz6aZwFX231dhJVQMx2ZguogU2Oc8Gas/S1EURenEpGygrogcA3wELAWcrAA3YvVDPQsMw0omebExZp+IDAAWAiX2/tXAOGNMpYj8FiuhYjNWPqtvGWMaUBRFUTotmklCURRFSUtSHiShKIqiKMFQBaUoiqKkJaqgFEVRlLREFZSiKIqSlqiCUhRFUdISVVCKEkdE5Bb/bPt+28+1kyJHOo/PfiLyOxE5JV5yKkpnQBWUoiSXc4GICsp/P2PMr40x7yRIJkVJS1RBKUoHEZGbRORLEfkYGGOv+7aILBCRJSLygp3p5Cjgq8BdIrJYRA6w/70hIotE5CN73rNg+z0qIhfa594oInfY2xaKyGQReVNE1tlTqjty/T9bhi/sweyK0qnISrUAitKZEZEpWPOPTcJ6nz4DFgEvGmP+ae9zG3CNMeZvIjITeNUY87y97V3gOmPMGhE5AviHMeakIPv5F73ZGDNJRO4BHgWOBvKAZcADInIaMBqYBggwU0SOM8Z8mKh7oSjxRhWUonSMY4GXjDG1ALZiAZhgK6ZSoAh40/9AO5P/UcBzHgWUG2W5TjlLgSJ7TrUqe8bpUuA0+9/n9n5FWApLFZTSaVAFpSiJ4VHgXGPMEhG5GjghyD4ZQLkxZlI7zu/kmmz1/O0sZ2FZTXcYYx5sx7kVJS3QPihF6RgfAueKSL6IFANn2+uLgR32lDKXe/avsrdhz3+2QUQuAivDv4hM9N+vnbwJfNO20hCRwSLSrwPnU5SkowpKUTqAMeYz4BlgCfA6sMDe9CuszPyfAKs8hzwN/D8R+VxEDsBSXteIyBJgOdbkm8H2i1Wut4AngbkishR4no4pPEVJOprNXFEURUlL1IJSFEVR0hJVUIqiKEpaogpKURRFSUtUQSmKoihpiSooRVEUJS1RBaUoiqKkJaqgFEVRlLREFZSiKIqSlqiCUhRFUdISVVCKoihKWqIKSlEURUlLVEEpiqIoaYkqKEXpgojI+yLyLfvvy0XkrVTLpCixogpKUTyIyDEiMkdEKkRkn4h8IiKHp1qujmCMecIYc5qzLCJGRA5MpUyKEg06o66i2IhICfAq8F3gWSAHa0r3hnDHKYqSGNSCUpQ2DgIwxjxljGkxxtQZY94yxnwBICLfFJGVIrJfRN4UkeHOgSLyVxHZIiKVIrJIRI71bJsmIgvtbbtE5M+ebV8VkeUiUm675Q72bNsoIr8QkS9si+4ZEcmzt/UUkVdFZI8tz6siMiTYRYnI1SLysf33h/bqJSJSLSKXiMgyETnbs3+2iJSJyGFxuauK0k5UQSlKG18CLSLymIjMEJGezgYROQe4ETgf6At8BDzlOXYBMAnohTWT7XOOMgH+CvzVGFMCHIBlnSEiB9nn+Il9zlnA/0Qkx3Pei4HTgZHAocDV9voM4N/AcGAYUAfcF+kCjTHH2X9ONMYUGWOeAf4DXOHZ7QxghzHm80jnU5REogpKUWyMMZXAMYAB/gnsEZGZItIfuA64wxiz0hjTDPwemORYUcaYx40xe40xzcaYu4FcYIx96ibgQBHpY4ypNsZ8aq+/BHjNGPO2MaYJ+BOQDxzlEeteY8x2Y8w+4H9YShC7rBeMMbXGmCrgduD4dl7648AZtosT4Ergv+08l6LEDVVQiuLBVkBXG2OGABOAQcBfsCyVv9quuHJgHyDAYADbFbfSdsWVAz2APvZpr8FyH64SkQUicpa9fhCwyVN2K7DFOafNTs/ftUCRXV6BiDwoIptEpBL4ECgVkcx2XPN24BPgAhEpBWYAT8R6HkWJNxokoSghMMasEpFHge9gKY7bjTEBH267v+mXwMnAcmNMq4jsx1JgGGPWAJeJSAaWi/B5EekNbAcO8ZxHgKHAtijE+zmWhXaEMWaniEwCPnfKbAePAd/C+ibMNcZEI4OiJBS1oBTFRkTGisjPnWADERkKXAZ8CjwA3CAi4+1tPUTkIvvQYqAZ2ANkicivgRLPea8Qkb62hVRur27F6os6U0ROFpFsLKXTAMyJQtxirH6nchHpBfwmhkvdBYzyW/cyMBn4MVaflKKkHFVQitJGFXAEME9EarAU0zLg58aYl4A/AE/bLrVlWK4wgDeBN7CCLDYB9VgWl8PpwHIRqcYKmLjUjhBcjRWc8DegDDgbONsY0xiFrH/B6q8qs+V8I4brvAV4zHZXXgxgjKkDXsAKxngxhnMpSsIQY0yqZVAUJQ2wLb+DjDFXRNxZUZKA9kEpioLtJrwGK4JPUdICdfEpSjdHRL6N5ZJ83RjzYaT9FSVZqItPURRFSUvUglIURVHSkk7RB9WnTx8zYsSIVIuhKIqiJIBFixaVGWP6+q/vFApqxIgRLFy4MNViKIqiKAlARDYFW68uPkVRFCUtUQWlKIqipCWdQkHtqKhny75a/jN3I43Nrfx37kYamlt4Yt4mahubeWbBZirrm3hh0Vb21TTyyuJt7K6sZ9bSHWwrr+Ot5TvZWFbD7FW7Wbu7mo/W7GHljkrmrtvL0q0VLNy4j88272fxlnLmb9jHsm0VzFlbxuqdVXzw5R7W76nm3ZW72Ly3ljeW7WR7eR2vfrGdPVUNvPz5NsprG3lu4RaqG5p5av5m6pta+O+nm1xZvTL/99NN1De18NT8zVTVN/Hcwi3sr2nk5c+3sbuqnle/2M728jreWLaTzXtreXflLtbtqeaDL/ewemcVc9aWsWxbBfM37GPxlnI+27yfhRstmeeu28vKHZV8tGYPa3dXM3vVbjbtreGt5TvZVl7HrKU72F1ZzyuLt7GvppEXFm2lsr6Jp+dvpq6xhcc/3WTJaMvs3m9b5ifmbaKmoZlnF2yhoraJFz/bSll1A/9bsp2dFfW8vnQHW/bV8vaKXWwoq+H91btZs6uKT9aWsWJ7JfPW7+WLreUs2rSfRZv288XWcj5dv5cV2yv5ZG0Za3ZVMXv1bjaU1fD2il1s2VfL60t3sLOinplLtlNW3cCLn22loraJZxdsoaahmSfn+d5v/zry+KebqGtscevI82HqyKa9vnVk1U7fOvJ5mDqyLkId2V9j1ZGq+iafOuK93+HqSHltx+vI0q3+daTKp45s3V8bso48s2AztY3N7a4jMyPUkY/XWHXk0yB1ZJ5fHXnfr468sSw+deTp+eHryJth6siybb51ZMFG3zryYZg6sruqPmQd8b/fwepIdUOzTx3ZU9XgU0e27Ot4HdlY5ltHdvnVkYo63zpS3+Qrs/MbrI6Eo1OEmecOHG2uu+dZXlm8nUMG92DptgomDunBkq0V7rLze+iQHnyxtYKD+hfx5a5q+hbnsqeqgQyB1g5ean52JnVNLQwuzWdbeR0TBpewbFul++svU7TLzvHjB5WwfHule/687Azqm1o7JHNmhtDSauhXnMvuqgbG9C9m9a6qDsvsf99H9C5g495aeuRnU1EXvtJFi3OukX0K2VBW496fjsqcyjrSUZkTWUf6FOVSVh25jsR6DY7Mo/oUsr6sJq51pCQvi8r65pjrSLTv5NgBxazaWeXWkawMobmDlcR5Zs4zHDewhBU7Kt1nHOu75y+z8+ucvyAnk9rGlg7JLALG4NYR593pqMynjuvPP78+FRFZZIyZ6l9up7CgAMptTbu9vA6AbeX1Psttv9b6nRXW754qa7bujn54AOqaWuyy63zK2GGX6S9TtMs7/GTeUWFt7+iHB6DFvvDd9n1wzt1RmZ3lHa7M1m+8Pjzec233u98dlTmVdSReMieijpRVR1dHYr2GnQmsI5X1zT5lRltHon4nK33rSEeVE7Q9M7eOVDoyxFonQn1HfJ9jR5UTWMoJPHWkPD4yO+cLRadRUOlv5ymKoijxpNMoqHQk3t5RVcJdD60jSiTi383SdWpJp1FQ6dhXln4SRUZlTi6dUXaVObl0RtmTJXOnUVCx0ikfehoq4a5MZ7zbWkeSS2e83Z1R5lAkPJOEiGzEmgiuBWg2xky1U/s/A4wANgIXG2P2x3bmCE8hCQ8p9o+F//4m7Nb0JPw1JIL2zmEemuTd6fgplFTWjvSvmYF1JD71NBkNgrYiIskcnSypfVrx/T4ky4I60RgzyRNGeD3wrjFmNPCuvRyW1jRsFqSfRFGQIKEl/lrExfj9xv3ECaRT9i50woqdsDqSBDqjVZwsmVPl4jsHeMz++zHg3NhPEeqLmMzWcaxl+8ucwK96CAIVfawtnuTLHEh8riEZNSX0e9xOme3dJIEtgkBJon3Xwl9DIhsxrgTuDY/2XUu9V6OtjEgyR3cNzj1Ibh1xiE3mSBImQ0EZ4C0RWSQi19rr+htjdth/7wT6+x8kIteKyEIRWQix+1U7X5uka/mOE0FnbGkqSrLpSm9JMrKZH2OM2SYi/YC3RWSVd6MxxohIoC1izEPAQ2Blkoi+OKelmQzfsX8ZHWux+LR8EiR/5NZxbNfgiJkM3dHxlqbf+VJSRxw6o8z+RHcNrvstLV2qEa4huSZUO0m+V6PjzzI6mRNuQRljttm/u4GXgGnALhEZCGD/7o58noA1ofZst6yxElhSpLKjc4kk11KI1dWUDoEdHXXxpbKOhNqSzjJH+66Fr88mCdcQfcBBdPslVz+1t177u/g6LFJE2p5lfGQORUIVlIgUikix8zdwGrAMmAlcZe92FfBKpHPFWrk7o5mb2j6RDp43Maf1OXmnHPTaCWVWT2rnpiu5whPt4usPvGR31mUBTxpj3hCRBcCzInINsAm4ONKJor/nvp3JCSWgjA6a2t4O8ARfQPTusgjnSeLLEH0HeDoEckSiM8rsTxq5+NxGTKyFhL+G9HKphiJ1Lr72ix6dzAlVUMaY9cDEIOv3AifHdK4E7NlRYnfxpZ5ASzRWV1PIEyeM2GWOTpjU9om0874n0X0Tuag41Z04EL3MgUeGX048HS8xdW7J9peVBi6+xNJ1W5yJpK3l096q5dfCdH8T91q4Msf7vJ2gQdFG8kLjHUJbrLGex/7tmDgxEp93Lb1kTl/vRhvx/cZ1YgUVqkPW+k3GwN7Yo/jCt9YcmZPiVnD/irVCJb9DNrDojr3IyZQ5flF8/vc98Q2CUGW3EaWLLwkayrS1lPz/CLHsEPwakuKWDCijvZ6B4JGHyekXjpPMIeg0CiraFzIl38s4l54EV32YNe0rPZEvcuwyd10XXzIbL53LxddeCVJ/DR235FPh4muvS7XtDNHQaRSUEic63Lnpd7okWqrxKim5brIEnTcxp/U5edzqiPvbeVyqyQyNbyszvc+XCjqNgkrHTBKBnosO+uo7dHSMZcWcEibC+TokTZRlxDmKL7Xvb2eU2Z/U96k6mHa7x1N/Dcka9BpPkhXF12kUVCAR/N1JIHJ0mT/R+uzbK1Fk4p2Lr81XnzihA2fZ7tg1JKNPpE0Sq5B43fdkZO4IlLmDufiSIrO/BB3LxZfUPqgQknQ0F18iCf3ex5iLL0K+wE6joCL1QzjX2Rr6aced2CPiwr/QSe2891uOPq+kCbuYSCLJHO01pNLF116Zkyl1pCCJWK8hGa9koOIO/65FuoakRh6G/I607xoCG3TxJ7TbPTaZI9F5FFRXcKiGIKkfzE523kSSlNQ7fr8dP1/yZO6UD7UTo7c7kE6joKIlqXm//H47fr4UmiOpPU10ZcUtsCM+50kmnVFmh/b3D7WjrHhF0qbADdzh87gid51GTKdRUI7ZGtE0d36T0mvfvrIC3QnOCxwHmSIQr4g45xqSKjvxKSsl97ujMrvn69h5oqE1RB1p7/RCSfS6e8ZBWr8ddQMnM8Fta6vTL+O7PdprSGq/WQT93X5Xti+dRkEpiqIo3YtOo6CibhQksXOzrUXfsdKS2sJ0fuPUzEqFi6+jZaaiRd/hOhLnsWDhy/ItM37ni8vpwpfllhkfkzW1UXwxnieJdcS/zEQhnSH4IHfgaDPwqr+kWgxFURQlzvzunPFcddTIRcaYqf7bOo0FpSiKonQ9fv3K8pDbVEEpiqIoaYkqKEVRFCUtUQWlKIqipCWqoBRFUZS0RBWUoiiKkpaoglIURVHSElVQiqIoSlqiCkpRFEVJS1RBKYqiKGmJKihFURQlLVEFpSiKoqQlqqAURVGUtEQVlKIoipKWqIJSFEVR0hJVUIqiKEpaogpKURRFSUtUQSmKoihpiSooRVEUJS1RBaUoiqKkJaqgFEVRlLREFZSiKIqSlqiCUhRFUdISVVCKoihKWpIyBSUip4vIahFZKyLXp0oORVEUJT1JiYISkUzg78AMYBxwmYiMS4UsiqIoSnqSKgtqGrDWGLPeGNMIPA2ckyJZFEVRlDQkVQpqMLDFs7zVXuciIteKyEIRWZhUyRRFUZS0IG2DJIwxDxljphpjpqZaFkVRFCX5pEpBbQOGepaH2OsURVEUBUidgloAjBaRkSKSA1wKzEyRLIqiKEoakpWKQo0xzSLyA+BNIBN4xBizPBWyKIqiKOlJShQUgDFmFjArVeUriqIo6U3aBkkoiqIo3RtVUIqiKEpaogpKURRFSUtUQSmKoihpiSooRVEUJS1RBaUoiqKkJaqgFEVRlLREFZSiKIqSlqiCUhRFUdISVVCKoihKynjpe0eF3NatFFRBTiYAvQtzAOhT5PvrrC/JszJAZWZIskUMICfLekSlBdlAoKzOck97u7N/KnHuW3GudR8DZc71WXaei6T+dpOfbckS6j6nZR3J9K0joWTuZf+mQx1xbptTR0LJ7CynYx2JJHOxXUeyM1MvtCNDj/zoviN52cmrI0N6FoTclvqamkb4V/40+Pa4OKIYE2K7LXwaiewK48jcdn9NsN3SAgkhs/99d+53WtQRPxlCXYNDOsgsfkJFuu8Z6aCZ/OhMMotdSTqTzNBNFJRzz8Vv2Z+Aj1AafDrbZA7+Qgful3CRIiJ+vyH3c55LGinXaGVu2z/1Ukd7v9v2Tx+ZoxUl9RK3keH3UQ9FOryLLn7fwJC7pUDmcGV2CwXl4HwII1WsjHRoYtoEfBCjfDlSSbQyh7JKUkEkmSNZJemAf/0ObB2nQKgI+HsGIlt/qb+IaK2/UPunAn8J0smSCldS91JQcd4vGQS2doNL12Ylpl76yDJL0KVUSh5YdnQypxOxXkM6EPjx7nz3XWXuGOEUeLdQUO1tDaRBw8elrfUb3nRKK5ldoS2ZQ/VBue6HNJC9ra6El9l1S6aVzBb+MvsvZ6TB/Y5V5vS4z9ZvoCih7nMaCG3jiBKpfofyJCSSbm9BhTJvA/ZLwcOJnuDum+B7pQf+7puAVlqUfvGkEuCODH/f06GOBMrg78r2v4Z0EDr4inSWOZJrL0Dm5IgVFaGCJELd9+BLyad7KCg/H1LEPii30z71fSKhWvCRovlS2t/gyu4vRPBrkLS4344M/gSXua01nepXOLLMoaImU9nCd1/JkJ4Bf4vV+k0HmUM/8vST2SG0CMHvu/sNTILsGiRhE6mipGMHuCNztLK1vfipuwh/5Riq1ea/PZXf+kgyh7JSUklHAztSfwWh63fI+54GQvt7BtI5oMa/7GhlTuZ9DtfI61YKKvqKkgZvgU2gJNHJlloDqn1flfSWOX3qhEPkutH1riEdrqAzBXaEbvulkczd3YKK3Zrw7UxOBZE6kUOSDm+wjX9gR8iAA+c3DWSPOrAjDeqIQ/Qd377LnSlIIh3cZG1uL/8t6RNw4E9bME9wd3skmZNRv7u9iy+grRDihgSavWng7/Zb05mCJCJ2wIbsq0od/u6bSPc9LaL5QrhQ0zvgIGANkOYBB1G6rtMx4MC/ERi9zKm9891DQTkfQns52kGuzv6paCUH9svEGiSRfKEjBXaEDJJwjk/lyxBSWYa/76FdKIkn2sCOUJ336dUA6zxBEqElSH3AgT8S8Ic/IWQOHVMfd8IV0S0UlEN7gyRSG3AQneXkkB4BB8FljmxJJV62UHQ0SCIVdSRamdMpSKK9gR3pEHDgECljRyoDDvxpb5BEMkXu9gN1HWKu3MlrRIQWoZ2Fp4M7ITTBzb/Uyhxr6an3PbXX4kzvupHY4+NBOz8jqWkQOOOfYj0upHUef7q9BRWrFZIOfu9Y8325+yVQpkiE6viOdpBrOvSN+CcCjdYKSel9z4itRZ/anIe+Luj2Wk6puIRQQRLpLHNb2b6Fp5PMGiQR7X5p9MEMLDk6WdJb5mivIQ7CtJvYZE6HIIlY77urVNPKlIp034NfQzKJ/PGOJHMKpPZzn3cKmT10DwUVovUQ+TjrN6UBB+6aKIMk7N9UyhwqsCMdAw7aG9gRcHxKPz7+ZYe/BoeU1BG/3zYiyZxGAQchSX3AgT+R36ngMiezEdNtB+p29OZKwB/JJ9YXMR0CDtpddMgPbuJpb4mprCNdoT8nZlL3rW83Ke2Ditc3MIF0WxdfqIoR6oak1fxEETo3o7+G+MkUibaElO1z5aXEgnJlaafMSexMDiVLrGWnsm8kXhZQUut1iIZTrHOypUMfVOwyq4svYUh732D/83RclNjL7IQy+/u7Yz48JW7J1CmYjuKfobpT0NE6Ej9JYi6z3VZ2Gjd0oz5PAi+h21pQDgEe+pCDXIMfl4r6FanISNeQig9vrGVF+xwSSUdlTmUdaS/+s6am8qMf83GuzMmTOlRDN9pn3qbgUtiX3c6GQSrdk9DFFVS8Wg2pjmRpD7G6rhJRdszHpUHAQfsPT93Hp/0ncM7Teep3YCBO5yEdG7rRniCRdaTbBkk4hBpTFMWRcZcl6pIDhGzfNSTVggooLLZrSEXAQYdl7qDLqj3EKnPU9z0JhG44xXgNcZQpEtHrxPSROXpSL3O3dfGFzj4cnECXU/KzP0eaVjoS/ulVUhEk4Z9du43w15Aat2THZG47j/2bBOGdIqKXOXzmjpQESQRsie4aUiFz9EESkfIJJtMtGbzM9sqcSMnDnbtLK6h4haQm1wqJj9Ap6VfohDLHW5Enp8WZur6jjtLhOpISl3VsDd2I50tiIyZeRSU2SCIFLj4RuUVEtonIYvvfGZ5tN4jIWhFZLSJfSZQMnvJ8lmPtnE/HgIPogySS2GqLcf+uECSRivRBHS3JDZLISH4dcehoFF9SZQ7RZkzngIOOBnb475+qfvisBJ//HmPMn7wrRGQccCkwHhgEvCMiBxljWuJdeNxaD86vSOwDCdpZVofPk8y3IU6k8mWIl5WdjDoSUGhHD+9EdcShE8V1tOFtPCapjsTNe5RICyrMtlS4+M4BnjbGNBhjNgBrgWmJLLD9LZ8Udsx2yiCJGDu6Q1qscRMpIvEKkoiXOzkaOmOQRGTPdYzX0HGRosan8RHVnsGX08kDE3pP/7qSeKlTGSTxAxH5QkQeEZGe9rrBwBbPPlvtdT6IyLUislBEFra38HgFSSQz4CDStNKRCJgEMCky+5bpkSbCcnCS+yJbpXWuIIlYZQ4RJBHj+9ERnCL8s5i3Eds1JFX2EPU7HQMO2sryLdOVKFaZ/X4TQcL6oETkHRFZFuTfOcD9wAHAJGAHcHcs5zbGPGSMmWqMmdp++YIvR7KuUxmGG8lnHP01JLFPJEIYfyhRYn0OiSSSzKHue+DA3WTe9/Ytp9OkdO29hmQS6Zmm4zVECuxIR5mD0aE+KGPMKdHsJyL/BF61F7cBQz2bh9jrEk60H8RQOfmsh55c33GkD2LAcX6tvVR0Jscqc8BpPC3NRN/taBVPOjUIQj3SWK8hpX1+7bzvAR4CkvVGtr/R4j/XUiq+I+5yh2ROPomM4hvoWTwPWGb/PRO4VERyRWQkMBqYH9+yA9ZE2B7yTGEXE0nc+qBS+t1s3zWk1lcfm8xtrpSQJ4w7scoc7TUkEgn4I+Qe0S2HcGElgnZ/L1LYBxV9YTHe9ySTyCi+P4rIJKymwkbgOwDGmOUi8iywAmgGvh/vCD6nfdJ2a43n/7bWQchfv+PiNDQpKvy/c/6yxHoNSZXZ6V9wt5jgyxFkT2a0U9QyO0shZE6ifgpSH8PLHOkaUiFzqHct2uVk3G+n+gXIHOF7EVLmJH5IAt7Jdsoc8A1M/CvpQ8IUlDHmyjDbbgduT1TZDuLXrG17aBF+284AtHXsZmdm0NDcmihxo5Il1mvIyswAWsjKEJpbE1OzopXZXY4ge5YddZGVIbQkSGZfiaKQ2VkKIXNS64h7H4PX71ivwakj2ZlCU0uC6ojdbPQPbohWZv9lS2bIykxcvXZL9pc51vpuLznBRNkZQmNiRG0r2U+29srs/OW8k9kZGTS2JLZ+e+mSmSRa49wydM6Tnen7sBJLfMpwZM7OTNyjjvf9zrTvb04CZXaJk9DOi992vxNfR+JVgvvxSWgd8W2JdxT3Y59AmeNvYdr3OcuSORn1O17322kQJKNee+mSCsohUrsq1o5w58OZlcCH1Bpj4ySyuZ34D2asVk609925z5mJbBC0s/Ed6hrcOpKRuFcrXlalf0d4IhtejpUT7xIcBZXIOuLvGu0omZK870hHA5Yc3EZ6VnJVRqdRUINL8+lVmENxbhbDexcAMGFwCQBHH9gbgNPHDwDg4qlDALj0cCtY8GvTrN+rjhoBwDXHjALgO8dbv9cdf4DPr7P+mmNG+hz3tWnDALjiiOEAXDJ1qE+5jhyHDO4BwPDeBRTnZtGzIJvBpflkZghjBxQDMG1ELwBOHtsPgPMPs4aCXWbL6sh+5ZFWWd88xpLh2uN8Zf7uCbbMx1m/3zrW2v6No639Lz/CkvlrtszO8tkTBwFw/EF9AThsWCkAB/YrIi87g77FufQtziUvO4MD+xX57OMcc9ahA+1zW+e85HDr9/Lpw31kcGT6ji27I7NzDc41fdO+31dOH+Fz3ivt850/2bpHpxzc37qHI617OHZAMZkZwuDSfHoWZMdURy5x6ohd1lX2/b7m2JE+MoeuI9ZvQB2Zbt8Tu46ccYhvHTl0SFsdKcrNoldhDoNL88mKpY7Yv879ce7ft23Z22T2re/fDqgjw+174FtHvupXRyZ76khuVgb9PHVkVN9CoK2OHBepjhzhX0dG+sh4nd+7ee1xI32u0akjl/ndA/86coSnjmQIbXUkL4thvXzryJGjfOvIRVP8viNuHRnhI0vbO+krs1N3nPrv1C3nPM599q8jxxzYB2irIyP7FLp1ZGCPPLIz2+rI4SN6Am115LyQdSQ6mZ3lbx/nW0eusO/vZdN8ZXfqyAljfOvIaE8d6VOUS352pltHJg619nHqSDjEJLPHq51MmTrVzJs336eD1GD5/VtaDZkZbb/Nra1kZ2TQZP82trSSm2X1Czi/edmZ1De1RP3rf3xOZtv5m1pbycrI8JEjQ9qCNPxlFiyXWKwyxyp7vGUOdr+zMsTnnIm4340tvudv9nvercYEyKl1pH0y+99vrSOdu440tVplpHsdycnKQEQWBRvz2ikU1NSpU83Che1OKKEoiqKkMaEUVKdx8SmKoijdC1VQiqIoSlqiCkpRFEVJSzpFH5SIVAGrI+zWA6hox+mTfVx7ju0DlHWgzGTKGq/jnGtOdHkdOTaRx4W6/nSUNV7Hdsd67hBLfU+1rIk4bowxpjhgrTEm7f8BC6PY56F2njupx7XnWOf6O4Os8Toummfe2a8xmmfeGWSN17HdsZ5Het7pKGsijgt1/V3Jxfe/TnJcKsrsDrJ2h2tMRZkqa3odl4oyU3GNQOdx8S00HZgXqrPTHa+/O16zl+54/d3xmh2687VD6OvvLBbUQ6kWIMV0x+vvjtfspTtef3e8ZofufO0Q4vo7hQWlKIqidD86iwWlKIqidDNUQSmKoihpSVooKBExIvK4ZzlLRPaIyKuplCuZiMi59n0Ym2pZEo0+bwsRqU61DKki0rWLyPsi0qWCBrrTOx4v0kJBATXABBHJt5dPBbbFcgIRSeT09cngMuBj+zdqRCQzMeIklA4/b0XphLTrHe/OpIuCApgFnGn/fRnwlLNBRKaJyFwR+VxE5ojIGHv91SIyU0TeA95NvsjxQUSKgGOAa4BL7XUniMiHIvKaiKwWkQdEJMPeVi0id4vIEuDI1EneIdrzvD8UkUme/T4WkYnJFDre2M/5Vc/yfSJytf33RhH5rYh8JiJLu1rLO9y1dzXCvOOhnv0ZIrJKRBaJyL3dzbvgkE4K6mngUhHJAw4F5nm2rQKONcYcBvwa+L1n22TgQmPM8UmTNP6cA7xhjPkS2CsiU+z104AfAuOAA4Dz7fWFwDxjzERjzMdJlzY+tOd5PwxcDSAiBwF5xpglSZM4NZQZYyYD9wO/SLUwSrsJ9Y4HYL8TDwIzjDFTgMgz+3VR0kZBGWO+AEZgtaZn+W3uATwnIsuAe4Dxnm1vG2P2JUXIxHEZ1gcb+9dxAcw3xqw3xrRgWRjH2OtbgBeSK2J8aefzfg44S0SygW8CjyZF2NTyov27COt+KZ2TUO94MMYC640xG+zlp8Ls26VJt36bmcCfgBOA3p71twKzjTHnicgI4H3PtppkCZcIRKQXcBJwiIgYIBNr4snXaJuU0sFZrreVVmcnpudtjKkVkbexWqMXAyFboZ2IZnwbinl+2xvs3xbS733tKJGuvUsQ5h1/hW5w/R0hbSwom0eA3xpjlvqt70FbJ/rVSZUo8VwI/NcYM9wYM8IYMxTYABwLTBORkXbf0yVYHaxdifY8738B9wILjDH7EyteUtgEjBORXBEpBU5OsTzJpLtce6h3PIPg178aGGU3zsB697slaaWgjDFbjTH3Btn0R+AOEfmcrteKvAx4yW/dC/b6BcB9wEqsCu2/X6emPc/bGLMIqAT+nQQRE4YdddpgjNkCPAsss38/T6lgSaAbXnuod/xSgly/MaYO+B7whogsAqpo/zQinRpNdZSmiMgJwC+MMWelWJS0QkQGYbn8xhpjWlMsTruxow//aYyZlmpZkk13vvZoEZEiY0y1iAjwd2CNMeaeVMuVbNLKglKUcIjI17Gi/W7q5MrpOqyO75tTLUuy6c7XHiPfFpHFwHIsl/eDqRUnNagFpSiKoqQlKbOgRGSoiMwWkRUislxEfmyv7yUib4vIGvu3p71+rD14s0FEfuF3rp/a51gmIk/Z4wgURVGUTkwqXXzNwM+NMeOA6cD3RWQccD3wrjFmNFZ2iOvt/fcBP8IKS3YRkcH2+qnGmAlYIZyXJucSFEVRlESRMgVljNlhjPnM/rsKK1JtMNYYl8fs3R4DzrX32W2MWQA0BTldFpBvRwcVANsTK72iKIqSaNIiSMKO9z8MqwO8vzFmh71pJ9A/3LHGmG1YVtVmYAdQYYx5K3HSKoqiKMkg5QrKTqL4AvATY0yld5uxIjjCRnHYfVTnACOBQUChiFyRIHEVRVGUJJFSBWXnVHsBeMIY4+Qc2yUiA+3tA4HdEU5zCrDBGLPHGNOElbvsqETJrCiKoiSHVEbxCVZ26pXGmD97Ns0ErrL/vgorX1U4NgPTRaTAPufJWP1ZiqIoSicmZeOgROQY4CNgKeAMurwRqx/qWWAYVq6ui40x+0RkALAQKLH3rwbGGWMqReS3WPmqmrHShXzLGNOAoiiK0mnRgbqKoihKWpLyIAlFURRFCYYqKEVRFCUtUQWlKIqipCWqoBRFUZS0RBWUoiiKkpaoglKUOCIit/hn2/fbfq6dFDnSeXz2E5Hficgp8ZJTUToDqqAUJbmcC0RUUP77GWN+bYx5J0EyKUpaogpKUTqIiNwkIl+KyMfAGHvdt0VkgYgsEZEX7EwnRwFfBe4SkcUicoD97w0RWSQiH9nzngXb71ERudA+90YRucPetlBEJovImyKyzp6x1pHr/9kyfGEPZleUTkVWqgVQlM6MiEzBmn9sEtb79BmwCHjRGPNPe5/bgGuMMX8TkZnAq8aY5+1t7wLXGWPWiMgRwD+MMScF2c+/6M3GmEkicg/wKHA0kAcsAx4QkdOA0cA0QICZInKcMebDRN0LRYk3qqAUpWMcC7xkjKkFsBULwARbMZUCRcCb/gfamfyPAp7zKKDcKMt1ylkKFNlzqlXZM06XAqfZ/z639yvCUliqoJROgyooRUkMjwLnGmOWiMjVwAlB9skAyo0xk9pxfifXZKvnb2c5C8tqusMY82A7zq0oaYH2QSlKx/gQOFdE8kWkGDjbXl8M7LCnlLncs3+VvQ17/rMNInIRWBn+RWSi/37t5E3gm7aVhogMFpF+HTifoiQdVVCK0gGMMZ8BzwBLgNeBBfamX2Fl5v8EWOU55Gng/4nI5yJyAJbyukZElgDLsSbfDLZfrHK9BTwJzBWRpcDzdEzhKUrS0WzmiqIoSlqiFpSiKIqSlqiCUhRFUdISVVCKoihKWqIKSlEURUlLVEEpiqIoaYkqKEVRFCUtUQWlKIqipCWqoBRFUZS0RBWUoiiKkpaoglIURVHSElVQiqIoSlqiCkpRFEVJS1RBKUoKEJHLReStMNvfF5FvxaGcE0Rka0fPoyipQBWUokSBiGwUkToRqRaRnSLyqDPXUnswxjxhjDktnjIqSldDFZSiRM/ZxpgiYBJwGHBDasVRlK6NKihFiRFjzE6sGWsnAYjIdBGZIyLlIrJERE5w9hWRq0VkvYhUicgGEbncs/5jz36nisgqEakQkfuwpmx3tt0iIo97lkeIiBGRLHv5GyKy0i5jvYh8J5TsIvJ/IrLN3ne1iJwcr/uiKPFGFZSixIiIDAFmAGtFZDDwGnAb0Av4BfCCiPQVkULgXmCGMaYYOApYHOR8fYAXgZuBPsA64OgYRNoNnAWUAN8A7hGRyUHKGQP8ADjclucrwMYYylGUpKIKSlGi52URqQK2YCmF3wBXALOMMbOMMa3GmLeBhcAZ9jGtwAQRyTfG7DDGLA9y3jOA5caY540xTcBfgJ3RCmWMec0Ys85YfAC8BRwbZNcWIBcYJyLZxpiNxph10ZajKMlGFZSiRM+5tuVxAjAWy9oZDlxku/fKRaQcOAYYaIypAS4BrgN2iMhrIjI2yHkHYSk9AIwxxrscCRGZISKfisg+u/wzbNl8MMasBX4C3ALsFpGnRWRQtOUoSrJRBaUoMWJbKY8Cf8JSJP81xpR6/hUaY+60933TGHMqMBBYBfwzyCl3AEOdBRER7zJQAxR4lgd49s0FXrBl6W+MKQVm4enD8pP9SWPMMViK1QB/iOHSFSWpqIJSlPbxF+BUYA5wtoh8RUQyRSTPHns0RET6i8g5dl9UA1CN5fLz5zVgvIicbwc+/AiPEsLqtzpORIaJSA98owdzsNx2e4BmEZkBBA1fF5ExInKSrdTqgboQ8ihKWqAKSlHagTFmD/AfLGVyDnAjlpLYAvw/rHcrA/gZsB3YBxwPfDfIucqAi4A7gb3AaOATz/a3gWeAL4BFwKuebVW2DM8C+4GvATNDiJ1rl1GG1cfVDw2VV9IYsdzdiqIoipJeqAWlKIqipCWqoBRFUZS0RBWUoiiKkpaoglIURVHSkqxUCxANffr0MSNGjEi1GIqiKEoCWLRoUZkxpq//+k6hoEaMGMHChQtTLYaiKIqSAERkU7D16uJTFEVR0hJVUIqiKEpaogpKURRFCYoxhvqmlpSVrwpKURRFCcq9765l7K/eoLK+KSXlq4JSFEVRgvLCZ1sB2F/TmJLyVUEpiqJ0cbaV17GtvC7m4wypzdXaKcLMFUVRlPZz9J3vAbDxzjNTLElsqAWlKIqipCWqoBRFUZSwSPAJmhOOKihFURQlLVEFpSiKoqQlqqAURVGUoKR6wnVVUIqiKEpaogpKURRFSUtUQSmKoihBcVx8kpogPlVQiqIoSnqiCkpRFEVJS1RBKYqiKGmJKihFURQlLVEFpSiKoqQlqqAURVGUuPPqF9upaWju0DlUQSmKoihhiTXMfPn2Cn7w5Ofc+NLSDpWrCkpRFEWJKzUNLQBsb8ckiV46rKBEZKiIzBaRFSKyXER+bK/vJSJvi8ga+7envV5E5F4RWSsiX4jI5I7KoCiKonQ94mFBNQM/N8aMA6YD3xeRccD1wLvGmNHAu/YywAxgtP3vWuD+OMigKIqixBmT4myxHVZQxpgdxpjP7L+rgJXAYOAc4DF7t8eAc+2/zwH+Yyw+BUpFZGBH5VAURVHSg3gptrj2QYnICOAwYB7Q3xizw960E+hv/z0Y2OI5bKu9zv9c14rIQhFZuGfPnniKqSiKonQC4qagRKQIeAH4iTGm0rvNWOo0JpVqjHnIGDPVGDO1b9++8RJTURRFiRGJMYwv1v1DERcFJSLZWMrpCWPMi/bqXY7rzv7dba/fBgz1HD7EXqcoiqIoLvGI4hPgYWClMebPnk0zgavsv68CXvGs/7odzTcdqPC4AhVFURQFgKw4nONo4EpgqYgsttfdCNwJPCsi1wCbgIvtbbOAM4C1QC3wjTjIoCiKosSZFM/43nEFZYz5GAjlcDw5yP4G+H5Hy1UURVGSQ4rmK9RMEoqiKEp8Scswc0VRFKXrkOJxuqqgFEVRlPREFZSiKIqSlqiCUhRFUcIS67jbSAN1L7x/Dsf84b2I54lHmLmiKIrShYm1LypSkMTCTfujOo9aUIqiKEpaogpKURRFCYpJ8VBdVVCKoihKWFKlplRBKYqiKGmJKihFUZQg1De18IvnlrCnqiHVonRapINJklRBKYqiBOHVL3bw/KKt3DFrZapFSTmpmvpdFZSiKIqSlqiCUhRFUYLSUcNpT3XH3KOqoBRFUZSwtFdRbSir6VC5qqCUhHH8XbO5ZebyVIuhKEonRRWUkjA27a3l0TkbUy2GoijtJNUz6qqCUhRFUdISVVCKoihKUJwxYK8t3RH1Me+u3EV1Q3Ncyo9LNnMReQQ4C9htjJlgr+sFPAOMADYCFxtj9ouVh/2vwBlALXC1MeazeMihKIoSLzo2xLRrsWlvdMEOW/fXcs1jCynOjc9EGfGyoB4FTvdbdz3wrjFmNPCuvQwwAxht/7sWuD9OMiiKoigppL6pBYCqOFlQcVFQxpgPgX1+q88BHrP/fgw417P+P8biU6BURAbGQw5FURSl65DIPqj+xhjHcbkT6G//PRjY4tlvq73OBxG5VkQWisjCPXv2hCzEGMNtr65gxfbKOImtKF2bZxZsZuyvXqelNdUxWkrXIzbHaKQUSkkJkjCWFDG9DcaYh4wxU40xU/v27Rtyv/LaJv718QYu++enHRVTUboFt8xcQX1TKw3NLakWRekkJCoV37F/nB12eyIV1C7HdWf/7rbXbwOGevYbYq/rEKI9mgC89sUO5qwtS7UYiqLYrNxRyagbXmNbeV2qRUk4sX6Ht+4Pf08SqaBmAlfZf18FvOJZ/3WxmA5UeFyBXY5Fm/bRartSahubOex3b/HBl6Fdlh3l+09+xtf+NS9h5++uPPjBOhZs9O9m7dykKEF1XFmzq4oDbpzFln21qRYlJE/O20yrgXdW7Eq1KBz7x/c47x+fhNz+4AfrGHPz6wHro1U88c56HhcFJSJPAXOBMSKyVUSuAe4EThWRNcAp9jLALGA9sBb4J/C9eMiQTDaU1XDLzOWu4gnFnLVlXHD/XB78cD0Aa3dXs7+2ibveXJUMMZU4csfrq7jogbmpFkPx49mFW2hpNby+LHFt3I5+cp2Pe6wf76aWVm5+eSm7Kus7KEEbW/bV8fnm8pDb73h9FQ3NrQHrG5paeXvFrojXcP/76zsqog9xCVY3xlwWYtPJQfY1wPfjUS6kJhXHdx9fxKqdVVxy+FAOHlgScr/tFVbFWrOrKlmiKUrUJMItfv0LXzCgRx4/OeWg+J88CM73siMT4y3bVkFxXhbDexfGSSpf2ivZR2v28Pinm9lRXs/DVx8e07GPf7qJCYN7MGloaTtL9+XFz7fx4ufb+N054/n6kSNC7rd8e0VcynPQTBLtwH0pItQ8/80dnV2yq3HW3z7ijtd1MrhU0R5vTENzC00tgS1sh6cXbOEv76zpgFSxEekSDrr59Ygei7P+9jHH3/V+3GTyp6ymEbD6W6bc+jab98bmjmyxH5QxhgUb90Vlid388jLO/XtoV157WbYtuAKqaWjm7rdWxz0yVBVUOzDttNvae1xXZdm2Sh78IL4uAX+O+cN7QT9Q3/7PQn72zOKElt0VGXPzG5z65w9SLYZLpMZiY3Mrf5+9LiFl76yop6K2KeJ+r31huR9f+Gwre2saeeSTDTwxb1NEReM0aJ3d3li2k4semMtT87cE7Hvh/XN45OMNUcs+c8n2dg3NCdXIPuPej/jbe2tZs7s65nOGQxWUzZIt5Yy4/jXmrtub8LLUkkoeW/fXBf1Avb1iFy9+3uHg0ZipbWzme08simu/QrLZGKMFkEiS3ej72TOLGXH9awBMv+Ndjv3je1EfK7YWfXTORm56aRmfhekLsva3fp0r3LLfuu8PfriOrft9n8HCTfv53asropblR099zhn3fsRLn29lV2U95bWNPD1/s7s91v6yTVHWic8273fvXzR0OwW1dnc13/j3fDclh8McWzG9/+XuYIeFZU9VA3WNoceUqN3U9SivbeSVxbEruFeX7GDW0p3c9ebqBEgVHV1pSEabBZWci3IaNSfd/T4AlfXtT+nT0BR+HJpzTf7KYtPeWo75gzV+aNGmfWFdrpH46TNLuPLhefzs2SVc/+JSd30o/dTR2xzrEJguo6CivW+3zFzO7NV7QocMx6BNHEvo8Nvf4aIH50TcvzOE9dY1tlATpzxa6UhFXVNcBqj+4MnP+fHTiyP2JzS1tPo0hjIyrDoTKQI0kXSGehgr8VRPa3dX8WWEwKb1e0InT/1iazn/+ijQdR2LjK8s3sZu28oO9byWbavggvvn8idPY+eOWSsDGt+R2FXZwF6/qdlDVZFkN266jIKKFn+XQEVdEze8uJS6GB5qsAqzbFugPzfUw0znFuzht7/D+N+8GfX+ra0mwN0Qb/ZWNzB7deyWbTAm/vYtLn2o41lHttuDLhtDtF73VDVQWd/ERQ/MZeyv3nDXZ9pvXEuQSnT3W6t5Y9nODssWCaeudwU95VgX8XynTvnzh5x2z4ftPudX7/uE215biTHGx/rxP9/ndreCf2O5trGZHz+9mP/3/BdAaDfmXjv4YsWOtm/Pgx+u5+y/fRyTvMHceaFcfPtqGpm33rcb5L+fbopYxhl//YhvProg5sZRl1FQ+2ubfAbCVdY3sXRrBZ+u38uI619jpf0QvWGp763axVfv+5in5m/myXmBN7m6oZnNe2vZVl7HPrsyhOOVxdv4bPN+dzneHYbJwDuPy8drypj0u7fCzu1y73trOOYPs/l0feL67q54eD7f+PeCuKXmCTcOJBhBX2D7N9RH7PDb3+HoO95j8RbfsjLsA4JFO/3tvbVc9/iiiPLMWVfG32evjbhfJPyva2dFPb94bklSUyBtLKuhMci4m1AYY3hszkb3fXSfQzvLj4e34MtdVYy4/jXmb/BVNF+97xNG3jDLs8ZXyo/XWO6uD1b7Dtz3rxqtIW6PbYzz0Rpft1ms353K+maWbPWNzms1BH0uby7fxSUPfcqqnZWMuP41/j57Lb96eVnEMlbsqOS9VbE3MruMggL41n8Wun9/498LOPu+j90WabDgh28+utDt3Aum2b/2z0857q7ZHH3nexzx+3cilv/jpxdz/j/m0NTSSkur4f73ExM9lCz+9NZqymubAtwdW/bVuh83J6T4B09+njA51u62yk+VaypYuW7LPcxxwaYcyMqwXrnWDlzM1/45LyF9WL+ZuYznF21ldjs+JO2horaJE/70Pje+tDTyzjbLt1fym5nLmXzr20D4Pij/kOgHP1jHk/M2+6xrz0fTH0fRzPKb1G+pX/n+IjrLkeqCY0H5B1dlRGHibd5by/4oGtfBynzp860ht89Za31Po6mHHfF+dCkF5XDh/XNYtMmyZJZsLffZ5tSFFz8LffMdvvC0KppaDGf/7WOfNEWh6sfom17nzHs/ikpWY0zS+yMamluorI8cHhtsBPyiTfs59o+zeXrBlqD7hmPe+r1RT3zmJR63Z19NY9B0OPe9t4ZnFwSG7fqWH86Ciq3t7rj4mlsM9U0tPPLxhqDWVGur4U9vrqbMr28gnviX6nwAY7nf7XmeDjWNlgJ/flHbu7hkSzk/f3ZJyHfC36Xqfrz9HkNFbRNneVxdTS2t3PH6qgBlGO7xfexnmcQSxh2MgHGRroIKv18o/RWNgjrurtkcf1f4hKzBMAaaw1SEWAIzvvHvBTGX79BpFNSybRWMuP41Npb5vhDBXu6Fm9rcbP7uHKdCh3JJhXs3l26r4JfPL4nKd79qZ3TZIx7+eAOjbpxFeW3srZz2ctEDczn0lrci7pfhRhG1rVu/x3IfLNy4P9ghIdlZUc8lD30adkDkvPV7A1xi0KYgWloNOyvqOfXPH7h9QJZ8hucWbvFxRT4xbxOrdrb55iff+nbQzMl/eutLfvnCF2FlD/fBDvaJ2B0khLzW/hg7Cq3VwN/eW8PvXl3By37h7q99sYNRN87ivtlruf6F6K0Lf2av2s0T8zaxoSy4EvH/8NnGXdSW6jsrdnH8Xe/zegzTgUfim48u4IXPtrIvxPvgle3hjze4bij/51Dv56YcfZNvfrnHP90U4JLzx38YQixh3LFgMPzf81/w3MItfP/JzwIaJaHGekXbNmpPpOHy7RVh68Edr7cvXdvdb38Z0/7xmZc3CTitoRP+9D53nH8IZ08cxI7yOr7z38g++2BkZwXXzYnMOBzsed/2mpVJYVdlA6UFOT7bPvxyDxMG96BXYQ7jfv0GtY0tfPTLExnaqyBiWS2thgzxbeFvLKthfVm1j2XosL+mMcB3nRGkhZfhfmBjM2um3/FuxH0usYMXNt55ps96p6hWY3hmwRbW7K7m6fmb+dlpYwDLffv/nv+COev2cs8lkwC46aXIfvFo8V7r7sp65q7fG3bcx5wg7uSn52/hm8eMJNMTOlxRZ1mxjiXh8P0nP3P/7kh/0DcebWu5+t/TYLRZUNb1Lty4jwmDe5CXnQkE9kk4DYBl2yuYcYjvnKP7axppbGmlf0leQDlrd1dzyp8/4NZzJ/isr2loptYerhHKOvBa87d6FMZf313L144YTqZdacN9u//6zhruecf6UN73tcPc9Q3NLQl1I/sPRfnEdpMZA88s3MIzCy1Lfk+lr4IK9a5FY0G1lwvuT4+8k53GgvJyw4tLmfCbNzn1ng9ZH6J1GIpP11utppxM30t3ImKcUd+hMMZ6wWKhpdXwhzdWUVZlVTynWnmjdzI8dW17eR01Dc18/ZH5rq/deXH9rYDK+qagnfgH3DiLP7zh6x8+4U/v881H2/rpvAPmLv/XPC5+sK1SXvGveSywrSTvC+J8APwtV68Ii7eUd+jDGixE15LDI4uIW4YT7fSxPcbiwvsjh/xHYl9NIwvt5+O9tq8/Mp8fP73YXfZ+I3ZV1vOXd8K3EB0rZX9tY1ALNRjGWP2Zbyzb4Vpi8aCppdXHReftE9m0t4YLH5jLr19pU/QH+WW5dho/W/fXBbjMD7v1bY74vW+jZO3uak7/y4c8a3+IvZbX3W+tZvxv3nQjDDNCfHtD3aqy6gZeWbyND7/cw97qBjcPZjDuCfGMjv3DbJ+Iy2jxyuS12v0JNQ26vztzvl9U38JN+/nd/1YEzILQEfdqZ6HTWFDREurj5p+hNzuzfbrZW5daWk1UyRFnLtkOQL/iXJ/12zxzoYgIe6sb2F3VwIy/fsSFU4aElqHV8MT8zUweVsqZ937MHy44hEsOH+aW4/DfuRs57qA+zFm7l198ZUxYGb2hqtD2sQffD6gzjidYmDTA1v21nPv3T7hkatuUX7GOSr/ttZV869hRAeuNaQu4XbmjkjE3v8FDV05xrd6K2iZ2VtT7uHij5cl5m/naEcPc5UsfmsuXu6rZeOeZPgp6exAL+3tPLKIgJ8vtSzl1XP+AfRycj/pnm8tdSzjS/dm6v44/vLEq4NyV9U288vk2rpg+PGJf2K2vruCXp48hNyvTXfebmct9GmSj+xUBVrCPY908u3Art517CDlBPA6Ogn1l8XZeWbydqgiupG8+uoDN+2pd93emRwv97T3fqMTqhmYufGAud114KOMH9XDLD3erfvbskrDlR2J3Vej+vnD9xM62T9fv5djRfWIuN5q345FPAvu/nIZZV6ZTWlDhcFxm/jjuFIdwlfHqf8/n/RCRJ17/8Iy/fsSZ90Y/5iBcmRkCU257hxl/tYIrvB3H/tbK/77Yzq9eXuaW7UQi/egp30g6EeFr/5zHfWFCkif+9i23XykU17/4hWttOS4q/xfW+T46gwS91mGwcRL+AwODMWvpDp8+x1YDc9dZinOJ3Vf1gqfl3mIMJ/wp9g5hgBtfWsqtr65gxPWvUd/Uwpe7rHtijAnrziyvbWLW0p0+z+vtMPP+ZHoUifNBv/ONVW5mgkh4I9N+/fIyfvXKcrcvZd2eakZc/xq/fH5JQJ/mwx9v4JXPfRsw/t4Cr4v3nx+2NfSC5TL85fNLAvpAfjNzeVjZN/sFqfiHR3uZs24va3dXc94/5nDUnVY6od1V9ayLUFdjJZro08827w/b6Ll9lvXNWbWzijeXxz6OrSsOnI6FcOMou5wFFYoWv8EE+TmhdfP7q/fw/urETSq4ZGsFt8xczqNzNrrrwvmTF/qZ/Ov8XIw1DS1BR497gwZC5b+qqGvipLvDJ/8M1t/y+rKdPi6aPbbydcKovTNl/voV3w/X+j3VPmW+/Pm2oMER33viM7I8rexWY1y3ozN+5c3lbcqgpdV0KJvyw3aU1rc9wxUst2LbPv4dzufEmDHaazU411bf1BoyM8FHa8p8jtnhcV3ttxOVPj5vM8N7F3KyfU+fXbg16KSYsbgHvcrknx9t4Irpw322P7twK4cO6RH1+UJlwQ7FLz3WQVl1A4ff/o5bx5LNpr21Pu7vcOwI41oMRVUUEbVdmXB1o9soKP/W25Z9qZ1+2aucIHyEkL/r5F4/d8jHa8va5TuPlcse+pSvjG9zMX33ic8C9nGsjVAZFoAAhfiTIFnFHQvNG+rqDROvCZP7sKN4W/ZTb3ub2b84ocPn/N2rKwKe8cYo+xCyQnTIOG2a/y3Zzv/83Lu7KgM/5pntdGuD1X/pT7Bgm1CcFWN2A39SpZxiJZxVGIrnFkUe8tKVCRex3m0U1JvLd3HgjbMi75giwg0Y/GmaTAsxd/1e5obJGLGvptENQukoDwcZc5KKDOD7a5s4Pw5BF8Fw3IjtJVYr/1cvL+OOWe2bf6u9bqjvP/EZr8UxDF3pejSHSpVBN1JQEH7gWToTKvon3XAiDuPBP4MEu+RmZwbZM/GESwyaDKb9PnKIfrTUJtDyDIYqJyUS4dzyXS5IQukaBAso6ciIdEVR0pNwhkPKFJSInC4iq0VkrYhcnyo5FEVRlNQRLoQ/JQpKRDKBvwMzgHHAZSIyLhWyKIqiKKkjHS2oacBaY8x6Y0wj8DRwTqidOxI6rCiKoqQv4cYZpkpBDQa8KaS32uuC0t0HsimKonRVOmWQhIhcKyILRWRh2d7ETYanKIqipI4ZEwaG3JYqBbUNGOpZHmKvczHGPGSMmWqMmZpfHP2IdUVRFKXzkBkqMzCpU1ALgNEiMlJEcoBLgZmhdk5cUnlFURQllYTRT6kZqGuMaRaRHwBvApnAI8aYkJkmS/KziT2BiKIoipLuhMvEn7JMEsaYWUD65h5SFEVREk44CyptgyQUJZ356JcnploERekShLOgVEEpacH5k0OOMoiK+TeezPdPPCBO0sClhw/l/TBZzJ3JBhPNZdOGRd4pwXx14qCI+xw2rDTs9gmDSzosx7+/cbjPcrhJPZXOQ7i5NlVBpQDvlBWdmWCzrN5/+eR2nevQwaEjNY85sA8/Pnk0933tMACK8wI90wW5WT6TAXr55tEjY5bnzgsOZUSfwqDbvnOcNdvv7887JKZzTh/VK2Y57jg/ujKKciN76399VvTJWk7zzNwbbiAlWMr8xe8eRUFO6GS+r/7w2KjLDsbGO8/kxDH9fNYFqwehOM1vluMnvnVEh+RR4ke4ufC6vIIa0jM/qv3+/rW2D2thmBctHtx72WE+ywf1L2r3uf7zzWk8eOWUjooU9X3y8uVtM1h16+ksuvkUvrxtBhvvPJMZh4Qe0xCOMw8NbKWfbbfc7754Ij899SD6FecBUFqQ7bPfVycOoig3y2diweevO5IXvnskX942g1+fHd8sWqP7FwP4TBEfDX+44FC+uOU0rpw+nFMOtj6YPfJ9r+X4g/qy8c4zgx4/cWhpSKUYSolcc4ylnEsLsvnmMaEVdd/iXJ/l+zzvg3PuI0f1JifInFLfPm4UIkJJXnbANoDcIA2ZX54+JqQsDg9fNTXs9mDzZD1wxWQeuTrwuMNHRG4cjLGfq5JcwkVpd1oFFazSByOavoJrjhnJGYcMcJd7FeW0W65oyM2yFOC4gSV8/H8n8uL3jo762CW/OY35N57sLh93UF++Mr5N9inDewY9bkTv4C6pPva1hkvYGAzHesrLzqR3UW5QayoSf710EgC9CnPoW5zL09dO99l+76WTWPf7M+hfYikm53vUuzCXq48a4e537mGWIjvVbiW/+sNjmDqiF1OG9wop18Y7z2TjnWcy8wdH86+vh/8Q+hPshfrH5ZMZ1Te4xeWQk5VBSV42t547gXy7ERStWzInK4NXvn80l02zhg+Osq07xyprNYaLpgzhWx4ldP7kwfz01IO4/IhhfPx/J7nrL5g8hC9uOc1dfuCKKbz8fd866B2b4oz0//qRw5lzg3We/iWWQjvl4H4c0NdqYP34lNFBZb/Zz3L719en8p3j2q57UI88n+23nzcBgCMP6B30fABjBxRz7XG+9+6F7x7J6RMGctLY/j5eir7FuQzwlJGTlcHofm2NwumjerHm9hm8+dPjQpYXit/EufHj5YiRbUp1YpDZizfeeSZLfnNawHqwvA4OR44KfR/TgXAWVKebD2p0vyLW7K4OO7jLS7gOOIdf+b1AYweUhJ1xd9zAElbsqAQs3/qybZU+2486oDdz1gVmvxjaK5/HvjENgDd+ciwDe+S7Leii3CxOPrgfryzeHnAcWK6znZX11v752TzxrSP4cldVwH4jeheyaNN+d3naiF7M37iP3593CO9/uYfrjj+AJz7dxN1vfwnAz08bww0vLiWcerpi+jDGDijh5peXcd3xB/DAB+vCtnq+d8IBrN9Tw5e7q3zmUrr6qBHsqW5gQEkeK3dUcs6kwRx5QG/y7Hmepo/qzcY7z+SEu2azcW8tIkKmp6AM+5kb4JavjmdPVQOvLd3hVvCJQ0tDWh8ON595ME0tbVd76JBSAA4eWMJFU4bwu1dXBHww/Zk6IrARcMYhAxnSM5+v3vcJF0wewv/NGMO02615nC6YPISTxvZjYI82K9W5LH8LatrIwJb+k98+gmF2n5eI8N9rpjGidyFDexVQ3dDMhN+8SauBuy6aCMC/7Mke/3zxJABu91hdwe7P6RMG+Cx/edsMMjOEJ751BCt3VDLXrstZmRn0KcrlgSumcMTIXizctN9HiZx32GBueHGpz7mClXeK3ZD47zXTeGXxdu44/xBG3/Q6ALN+dCzjBpVw+RHWFPOXTRvqPiMv/+8rYwKsvinD2+7dA1dM4bPN5Vxw/xyMMZx16EDysjOZvXo3F00ZQr+SPM44ZACzlu7kByeOJrsDsw2HozAnk5rGFl763lEcMrgHB9rXCfCd40fx01MOCjkbdqsx3Hzmwdz22komDS1liT2D8Wnj+rsNtB752bz90+PYur+O/bWN/OzZJYD1LD5e2zkG54T7RHc6BfXkt6dz+O3vhNS6JXlZVNZ3bIK/0vzgroqXvncUBnj8002s2FHJXRceykVTh/LHN1bxj/fX0bswh701jQwqzWfjnWeybk81J3umNz/jkIGMslubYwf4dhov++1XAEIqKH/X2dEH9uFoTyvp1nMn8I/ZawMetuOeyc7K4MYzDgYsl8zdb39JTlaGm+fQ+T3+oL4M713Aj04ezeG3v8OFk4dw27nWB+640X3pXZRjKagwleqXp48FoLy2kW3ldZx5rzXd9y1fHR+wr+O28/LKD45hb3WQKcvtQh1r77ZzJzCqbyHHju4bWhg/vnXsqKDrX/+x1Udy2vj+lHie//ybTuahD9bz2NyNrmIb3rvQ57idFdZMv4cOKeXhq6Zy9IF9yMvOdD8upQXZnHmo7/Nz7l92ZgaHj+jJtccdwOh+Ra4iysnK4OCBVh056oA+Psd6r9dpp5k4Jqx0rE6njn3wpTVzr+O1cBTaqX79OqGmpncYO6DYJ3P1saP7utcy78aTycvKpIef+/aO8w8Neq5I7U4RYbjtNWg11vKp4/r7yHzrORM4qH8xR4Wx1PwZ1quAzftq3WXHGxJODoAD+xWR5acErz99rO0azeK7JxzIH95YBcCPTh7Nve+uoaXVBG2I//3yyT4KdXT/Ytft7FVQP3/O+jucd6O0IJvy2ibAen7RTOr62DencdUj87nt3AkU52Xx46cXRzwmHF0iSOKZa6fz6Q0nuz5w56LO9PtwDypta6X2KfJtYUXioSuncMHkIfzq7HH88vQxAaZxTlYGk4f1xDE3nMrnKAp/99oBfYv46Jcn8oMTD7RWRPEN+b/Tx/LXSyfx5LeO4IXvHhW1pXjl9OHMveHkAMvmzgsO5cxDBjLR0wp1znnGhAEYWyhXkWUKvztnAn2Kctlwx5luqxxgmMdNKFHk9ygtyGH8oB48dOWUmNxoPfKzXUXuez7r4zXa7rPrWZjDz08bE9U9evWHx/DmTyK7cIb0LPDpS+lXnMfNZ41jze1nAJCX7fvKHDywhBPHtnXen3xwf9cidAimOxyJReC5647i1HH9GdGn0LUSF9x4Cs9fd2REeZ2GWnv0U7R9n5OHWfU6Uj+l9zlMGd6TW8+d4LP9jZ8cxzs/Oz7osf1L8gKUUzic+ndImOAa596E6p/rXZTLT045yL3nwThtXH8fN96d5x9Cvuf5XjQ1dCThxjvPdMt2ZBk7wFIkE4eWut+PL275Ct89oc1debrtsg/1/YrG2svIEI4/qC+/Omucz7nBN+Ly3kvb+sOj7cueMKiEjXeeyRXTh/s0kkMx/8aT3WsKKmtXcPEdYSuL8tpGwHrBF958CiV52T7TSnvr4sKbTwl6rkumDmVDWQ3byuvYVt7myjtt/ABOs2/k9044kHnr9/kc57wUxl22OPrAPiy6+RTeXbmbt1bs8vl0D+1VwPRRvblv9lomDS2NeJ3+lWnhTadEo9dCcmC/Iv7uF1mXnZnB/JtOpjQ/h2cWWknlnTIifeyzbJ9bLJGIp4WpnLEwvHchT1873UfZRsuEMB+yaHnhu0cxqDS8+8+L0+8xOMiH/djRfXl58XZG9wveMR/txzozw7dOxsIz1x7J+rI2F+yrPzyG91fvDtjvRyeP5rzDBoeManRwPrg/POlAfn5a5CCIDmFX0ye+fQSLN5dTFCSiz6nKsfavOiz59WnucxgzoJj6phaOOrAPc64/icNufZujDujtoyxm/uBoKuqauPLh+e46fwX18vePpqXVUBgm6nLcoBLuuvBQThs/gJc+2+qu//qRw2lqaY1a/se+Oc39+6NfnshNLy/jH5dPpig3i4semMM3jx7JcQe1WePD/fqpv3fCAfzj/XU+6/544aH09ijOUJGzXvqV5PHAlVMYcf1rQbeHO0OnUVAOxmO9BGthRAqJBfjDhZbboKq+ifqm0A/8jxceyiOfbOC9lbtZs7s6wBT1LvcuynWtEX+OGd2HuTec5NMHES09C2ML2Jg+qjfPLdoacT/HtTZuoPWBvP70sSzctJ+fhujodsjNymTejSfTsyCxgSShmJ7CDt9QASihOPOQgRRcnckJB/UL2HbBFKtfKtbn64/zgejTjsCenoU5TPGUP2Fwj6CKPDNDIionh0h9gPHC6bsrycv2+ch6cVxq/Uqib1T4lOFpJHjdrD0Lc3jsm9OYZDeUXvjukfQvyWNIz8BApDH9i1mytcJtSPhb117e+ulxbr/yRVOtYBinYX7a+AFRWSsPXjmFwpzAz/rQXgX8x6OwnrvuqIB9DuxXzDPXTueShz4FrL5CfwV18dShPsuO9ZmblUFDc3jlecvZ49hd1RBwzi5hQfnjoxwKczj6wD7MXLI9qIp45trpZGVmUNfY4tMCKc7LJkgXiEv/kjxumHEws1dZrco2d4oJkAEsl5ZznD/tUU7t4YIpQzj2oD7kZmVSWdcUcf8pw3sx/6aT6VecxwVRDnwMdn1KICLCSWNDW5odVU5gfSD+fPHEqMKouwKrbj2d91fvcd2O4SjKzeKeSyZy5KjIH/ZYOd6jFL3BGWAFNK3bUw3Ao9+YxsqdlVFFuR7Uv5iD/ELdDx5YEpPS/0o7vBXfOX4Ur3xu9X0f4WkARtOv6VrwURipV9vjEf0VVJcKkgh2Hxb96lTW7KqyFJQxPHjlFAZ6IrGO6GCr+6enHMR3n/iMob3yfWTw74c5bVx//nrppLDzmyQDxzryjxCLtL/SOTl/sm/D4oErJgftw+sK5GVnBkQdhuO8w9qXbeJPnr7XWPEGNPUszAkIckk3bphxMDfMODhgvddD1a84l3MPC8z2khmkn+/6GWN58IN17K+N3ECGNE0W21H8L8nxi35l/IB2tSLCMeOQgT6tmFCtBRHhnEkdS9mjKB3l9BQ3kDoz//r6VDIzxCfwpbvxhwsOYfaqPT7RqvNvCt6fn2Ebhv5dK7N+fCxH3vFeh2XpdArK6aT371zuVZjDZ786NWSIeDxxrDP/jAaKonRuThnXNdKQdYRLDh/GJYe3ZUlxBmUHo82Calt33mGD49YN0OkUVEleNv/55rSgkVy94uDTj4afnXYQEwb38PFDK4qidDUW3nxK2MAOpw9qVJ9CNyI0nn3UnU5BASGjdpJFblammydOURSlqxJpLKmI8O9vHM74QSX84rkv4u7B6pQKSlEURUkPnCzz3jB2gDnXnxQxu0gkVEEpiqIocceb1ae9dJpUR4qiKEr3QhWUoiiKkpZ0SEGJyEUislxEWkVkqt+2G0RkrYisFpGveNafbq9bKyLXd6R8RVEUpfNyxfTwk3521IJaBpwPfOhdKSLjgEuB8cDpwD9EJFNEMoG/AzOAccBl9r6KoihKN2LcwBJ3Kp9QdChIwhizEoKmqjgHeNoY0wBsEJG1gBPisdYYs94+7ml73xUdkUNRFEXpXMyy52ALR6L6oAYDWzzLW+11odYHICLXishCEVm4Z8+eBImpKIqipCsRLSgReQcIltzuJmPMK/EXycIY8xDwEMDUqVPjN12ooiiKkjLe+Mmx7KkKnDE7GBEVlDEmeJbA8GwDvBOHDLHXEWa9oiiK0sUZO6CEsVHm806Ui28mcKmI5IrISGA0MB9YAIwWkZEikoMVSDEzQTIoiqIonZgOBUmIyHnA34C+wGsistgY8xVjzHIReRYr+KEZ+L4xpsU+5gfAm0Am8IgxZnmHrkBRFEXpkkg0syammqlTp5qFCxemWgxFURQlAYjIImPM1ID1nUFBiUgVsDrCbj2AinacPtnHtefYPkBZB8pMpqzxOs655kSX15FjE3lcqOtPR1njdWx3rOcOsdT3VMuaiOPGGGOKA9YaY9L+H7Awin0eaue5k3pce451rr8zyBqv46J55p39GqN55p1B1ngd2x3reaTnnY6yJuK4UNfflXLx/a+THJeKMruDrN3hGlNRpsqaXselosxUXCPQeVx8C00Q/2R3oTtef3e8Zi/d8fq74zU7dOdrh9DX31ksqIdSLUCK6Y7X3x2v2Ut3vP7ueM0O3fnaIcT1dwoLSlEURel+dBYLSlEURelmqIJSFEVR0pK0UFAiYkTkcc9ylojsEZFXUylXMhGRc+37MDbVsiQafd4WIlKdahlSRaRrF5H3/SdB7ex0p3c8XqSFggJqgAkikm8vn0qMSWRFpENpm9KAy4CP7d+osSeB7Gx0+HkrSiekXe94dyZdFBTALOBM++/LgKecDSIyTUTmisjnIjJHRMbY668WkZki8h7wbvJFjg8iUgQcA1yDlUAXETlBRD4UkddEZLWIPCAiGfa2ahG5W0SWAEemTvIO0Z7n/aGITPLs97GITEym0PHGfs6vepbvE5Gr7b83ishvReQzEVna1Vre4a69qxHmHQ/17M8QkVUiskhE7u1u3gWHdFJQT2NlQM8DDgXmebatAo41xhwG/Br4vWfbZOBCY8zxSZM0/pwDvGGM+RLYKyJT7PXTgB8C44ADgPPt9YXAPGPMRGPMx0mXNj6053k/DFwNICIHAXnGmCVJkzg1lBljJgP3A79ItTBKuwn1jgdgvxMPAjOMMVOwknF3S9JGQRljvgBGYLWmZ/lt7gE8JyLLgHuA8Z5tbxtj9iVFyMRxGdYHG/vXcQHMN8asN1Ym+KewWmAALcALyRUxvrTzeT8HnCUi2cA3gUeTImxqedH+XYR1v5TOSah3PBhjgfXGmA328lNh9u3SpFu/zUzgT8AJQG/P+luB2caY80RkBPC+Z1tNsoRLBCLSCzgJOEREDNY0JAZ4zf714izX20qrsxPT8zbG1IrI21it0YuBkK3QTkQzvg3FPL/tztSjLaTf+9pRIl17lyDMO/4K3eD6O0LaWFA2jwC/NcYs9Vvfg7ZO9KuTKlHiuRD4rzFmuDFmhDFmKLABOBaYZk/umAFcgtXB2pVoz/P+F3AvsMAYsz+x4iWFTcA4e3LPUuDkFMuTTLrLtYd6xzMIfv2rgVF24wysd79bklYKyhiz1Rhzb5BNfwTuEJH/3969hVhVxXEc//5CKE3DeshUCkIiESG7YGEXpMSnLvNQYRQZmRAFXUghsqIi8CHIhy4kPqQP3UwTJEgtCbTowXtqRRKGUXaBKJVCFH897DUxHaYxZzxn75O/DwxzZq911vnvmTn8Z81e+7+28f/7K/IOYFXLsZXl+CbgZeBLql/o1n5dbTA/b9tbgAPA6x0IsW3KqtPDtr8DlgO7yudttQbWAafguf/be3wW/Zy/7T+BB4A1krYABxn8NiJdLaWOGkrSdGCe7RtrDqVRJI2j+pffRNvHag5n0MrqwyW2p9YdS6edyuf+X0kaafuQJAGvAHtsL6o7rk5r1AwqYiCS7qZa7begy5PT/VQXvp+sO5ZOO5XP/QTNlbQd2E31L+/F9YZTj8ygIiKikTKDioiIRqotQUk6X9LHkr6QtFvSw+X4OZI+lLSnfD67HJ9YqgscljSvZaxHyxi7JL1VbnSLiIguVucM6ijwmO1JwFXAg5ImAY8D621fRFW+6PHS/1fgIar7Zv4maXw5foXtyVT3GMzqzClERES71JagbO+3vbU8Pki1lHo81U2Yy0q3ZUBP6fOz7U3AkX6GGwYML8tXRwA/tDf6iIhot0Zcgyo3pF1KtUJrjO39pelHYMxAz7X9PdWsah+wH/jd9rr2RRsREZ1Qe4IqVX5XAo/YPtC3zdUSwwGXGZZrVLcAFwLjgDMl3dWmcCMiokNqTVCl6OdK4A3bvUUxf5I0trSPBX4+zjAzgL22f7F9hKq45rR2xRwREZ1R5yo+UW2f8KXtF/s0rQZml8ezqQoqDmQfcJWkEWXMG6iuZ0VERBer7UZdSdcAG4GdQG9VgCeorkMtBy6gKiZ5u+1fJZ0HbAbOKv0PAZNsH5D0LFVBxaNU9azus32YiIjoWqkkERERjVT7IomIiIj+JEFFREQjJUFFREQjJUFFREQjJUFFREQjJUFFnESSnmmttt/S3lOKIh9vnH/0k/ScpBknK86IbpAEFdFZPcBxE1RrP9tP2/6oTTFFNFISVMQQSVog6WtJnwAXl2NzJW2StEPSylLpZBpwM/CCpO2SJpSPNZK2SNpY9j3rr99SSbeWsb+VtLC0bZZ0maS1kr4pW6r3xjW/xPB5uZk9oqsMqzuAiG4m6XKq/cemUL2ftgJbgPdsLyl9ngfm2H5J0mrgfdsrStt64H7beyRdCbxq+/p++rW+9D7bUyQtApYCVwNnALuA1yTNBC4CpgICVku6zvaGdn0vIk62JKiIobkWWGX7D4CSWAAml8Q0GhgJrG19YqnkPw14t08COv0/vm7v6+wERpY91Q6WHadHAzPLx7bSbyRVwkqCiq6RBBXRHkuBHts7JN0DTO+nz2nAb7anDGL83lqTx/o87v16GNWsaaHtxYMYO6IRcg0qYmg2AD2ShksaBdxUjo8C9pctZe7s0/9gaaPsf7ZX0m1QVfiXdElrv0FaC9xbZmlIGi/p3CGMF9FxSVARQ2B7K/AOsAP4ANhUmp6iqsz/KfBVn6e8DcyXtE3SBKrkNUfSDmA31eab/fU70bjWAW8Cn0naCaxgaAkvouNSzTwiIhopM6iIiGikJKiIiGikJKiIiGikJKiIiGikJKiIiGikJKiIiGikJKiIiGikvwC6mp8/YhQPRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#разложим временной ряд на тренд и сезонную компоненту\n",
    "\n",
    "decomposed = seasonal_decompose(data) \n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.subplot(311)\n",
    "# Чтобы график корректно отобразился, указываем его\n",
    "# оси ax, равными plt.gca() (англ. get current axis,\n",
    "# получить текущие оси)\n",
    "decomposed.trend.plot(ax=plt.gca())\n",
    "plt.title('Trend')\n",
    "plt.subplot(312)\n",
    "# < напишите код здесь >\n",
    "decomposed.seasonal.plot(ax=plt.gca())\n",
    "plt.title('Seasonality')\n",
    "plt.subplot(313)\n",
    "# < напишите код здесь >\n",
    "decomposed.resid.plot(ax=plt.gca())\n",
    "plt.title('Residuals')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309393ea",
   "metadata": {},
   "source": [
    "Рассмотрим график сезоности в большем масштабе, сделаем срез за месяц, так как судя по графику выше сезонность стабильная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5633949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ecomposed = seasonal_decompose(data) \n",
    "decomposed.seasonal['2018-08-01':'2018-08-07'].plot(ax=plt.gca())\n",
    "plt.title('Seasonality');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ff7a7",
   "metadata": {},
   "source": [
    "Видим определенную сезоность в пределах дня. Рассмотрим ее ниже в масштабе 1 дня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d37fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ecomposed = seasonal_decompose(data) \n",
    "decomposed.seasonal['2018-08-01':'2018-08-01'].plot(ax=plt.gca())\n",
    "plt.title('Seasonality');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda4826",
   "metadata": {},
   "source": [
    "***Вывод по графикам*** \n",
    "\n",
    "Есть тренд по увеличении заказов со временем. При увеличении масштаба на графике сезонности можно отметить точки наибольшего спроса на такси - это время около 16.00  и 00.00 часов.\n",
    "Также есть выбросы, но их удалять не буду, так как данных немного. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee7cf4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['mean'] = data['num_orders'].rolling(24).mean()\n",
    "data['std'] = data['num_orders'].rolling(24).std()\n",
    "data.plot(figsize=figsize)\n",
    "plt.xlabel('Дата заказов в разбивке по часу')\n",
    "plt.ylabel('Количество заказов')\n",
    "plt.title('График количества заказов такси по часам ', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbbdaae",
   "metadata": {},
   "source": [
    "Мы имеем нестанционарный временной ряд, так как его среднее значение  (mean на графике) и стандартное отклоение (std) меняется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a685f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#сделаем ряд стационарным - найдем разности значений между соседними элеметтами ряда.\n",
    "data1 = data - data.shift()\n",
    "data1['mean'] = data1['num_orders'].rolling(15).mean()\n",
    "data1['std'] = data1['num_orders'].rolling(15).std()\n",
    "data1.plot(figsize=figsize)\n",
    "plt.xlabel('Дата заказов в разбивке по часу')\n",
    "plt.ylabel('Количество заказов')\n",
    "plt.title('График количества заказов такси по часам ', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde4054",
   "metadata": {},
   "source": [
    "***Вывод:***\n",
    "Мы видим, что ряд стал более стационарным, следовательно, данные можно прогнозировать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab2994",
   "metadata": {},
   "source": [
    "***Добавим новые признаки в датсет для обучения модели***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdb5a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_160</th>\n",
       "      <th>lag_161</th>\n",
       "      <th>lag_162</th>\n",
       "      <th>lag_163</th>\n",
       "      <th>lag_164</th>\n",
       "      <th>lag_165</th>\n",
       "      <th>lag_166</th>\n",
       "      <th>lag_167</th>\n",
       "      <th>lag_168</th>\n",
       "      <th>rolling_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 01:00:00</th>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 02:00:00</th>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 03:00:00</th>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 04:00:00</th>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     num_orders  mean  std  hour  dayofweek  lag_1  lag_2  \\\n",
       "datetime                                                                    \n",
       "2018-03-01 00:00:00         124   NaN  NaN     0          3    NaN    NaN   \n",
       "2018-03-01 01:00:00          85   NaN  NaN     1          3  124.0    NaN   \n",
       "2018-03-01 02:00:00          71   NaN  NaN     2          3   85.0  124.0   \n",
       "2018-03-01 03:00:00          66   NaN  NaN     3          3   71.0   85.0   \n",
       "2018-03-01 04:00:00          43   NaN  NaN     4          3   66.0   71.0   \n",
       "\n",
       "                     lag_3  lag_4  lag_5  ...  lag_160  lag_161  lag_162  \\\n",
       "datetime                                  ...                              \n",
       "2018-03-01 00:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 01:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 02:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 03:00:00  124.0    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 04:00:00   85.0  124.0    NaN  ...      NaN      NaN      NaN   \n",
       "\n",
       "                     lag_163  lag_164  lag_165  lag_166  lag_167  lag_168  \\\n",
       "datetime                                                                    \n",
       "2018-03-01 00:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 01:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 02:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 03:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 04:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "                     rolling_mean  \n",
       "datetime                           \n",
       "2018-03-01 00:00:00           NaN  \n",
       "2018-03-01 01:00:00           NaN  \n",
       "2018-03-01 02:00:00           NaN  \n",
       "2018-03-01 03:00:00           NaN  \n",
       "2018-03-01 04:00:00           NaN  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создание новых признаков\n",
    "#data['year'] = data.index.year\n",
    "    #data['month'] = data.index.month\n",
    "    #data['day'] = data.index.day\n",
    "\n",
    "def make_features(data, max_lag, rolling_mean_size):\n",
    "    data['hour'] = data.index.hour\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    \n",
    "    for lag in range(1, max_lag + 1):\n",
    "        data['lag_{}'.format(lag)] = data['num_orders'].shift(lag)\n",
    "\n",
    "    data['rolling_mean'] = data['num_orders'].shift().rolling(rolling_mean_size).mean()\n",
    "\n",
    "#примем следующие параметры: max_lag = 24 часам, rolling_mean_size = 48 часов (за 2 суток)\n",
    "make_features(data, 168, 48)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15a93f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('mean', axis=1)\n",
    "data = data.drop('std', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9c49b2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_160</th>\n",
       "      <th>lag_161</th>\n",
       "      <th>lag_162</th>\n",
       "      <th>lag_163</th>\n",
       "      <th>lag_164</th>\n",
       "      <th>lag_165</th>\n",
       "      <th>lag_166</th>\n",
       "      <th>lag_167</th>\n",
       "      <th>lag_168</th>\n",
       "      <th>rolling_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 01:00:00</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 02:00:00</th>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 03:00:00</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 04:00:00</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     num_orders  hour  dayofweek  lag_1  lag_2  lag_3  lag_4  \\\n",
       "datetime                                                                       \n",
       "2018-03-01 00:00:00         124     0          3    NaN    NaN    NaN    NaN   \n",
       "2018-03-01 01:00:00          85     1          3  124.0    NaN    NaN    NaN   \n",
       "2018-03-01 02:00:00          71     2          3   85.0  124.0    NaN    NaN   \n",
       "2018-03-01 03:00:00          66     3          3   71.0   85.0  124.0    NaN   \n",
       "2018-03-01 04:00:00          43     4          3   66.0   71.0   85.0  124.0   \n",
       "\n",
       "                     lag_5  lag_6  lag_7  ...  lag_160  lag_161  lag_162  \\\n",
       "datetime                                  ...                              \n",
       "2018-03-01 00:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 01:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 02:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 03:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "2018-03-01 04:00:00    NaN    NaN    NaN  ...      NaN      NaN      NaN   \n",
       "\n",
       "                     lag_163  lag_164  lag_165  lag_166  lag_167  lag_168  \\\n",
       "datetime                                                                    \n",
       "2018-03-01 00:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 01:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 02:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 03:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018-03-01 04:00:00      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "                     rolling_mean  \n",
       "datetime                           \n",
       "2018-03-01 00:00:00           NaN  \n",
       "2018-03-01 01:00:00           NaN  \n",
       "2018-03-01 02:00:00           NaN  \n",
       "2018-03-01 03:00:00           NaN  \n",
       "2018-03-01 04:00:00           NaN  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d407138",
   "metadata": {},
   "source": [
    "Все данные количественные. Надо будет провест масштабирвоание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6cc151f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тестовой выборки по условиям задачи должен быть равен = 442\n"
     ]
    }
   ],
   "source": [
    "#по условия задачи размер тестовой выборки должен быть равен 10%\n",
    "\n",
    "test_size = data.shape[0] * 0.1\n",
    "print('Размер тестовой выборки по условиям задачи должен быть равен =', round(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b07936bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка: (3974, 172)\n",
      "Тестовая выбока (442, 172)\n"
     ]
    }
   ],
   "source": [
    "#разделим данные на обучающую и тестовую выборки\n",
    "\n",
    "train, test = train_test_split(data, shuffle=False, test_size=0.1)\n",
    "\n",
    "print('Тренировочная выборка:', train.shape)\n",
    "print('Тестовая выбока', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aad062dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3806, 172)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#из тренировочной выборки удалим строки с пропусками\n",
    "train = train.dropna()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0491d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выделяем признаки и целевой признак\n",
    "features_train = train.drop('num_orders', axis=1)\n",
    "target_train = train['num_orders']\n",
    "features_test = test.drop('num_orders', axis=1)\n",
    "target_test = test['num_orders']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f0c46",
   "metadata": {},
   "source": [
    "***Масштабирование данных***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f86eff4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hour', 'dayofweek', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5',\n",
       "       'lag_6', 'lag_7', 'lag_8',\n",
       "       ...\n",
       "       'lag_160', 'lag_161', 'lag_162', 'lag_163', 'lag_164', 'lag_165',\n",
       "       'lag_166', 'lag_167', 'lag_168', 'rolling_mean'],\n",
       "      dtype='object', length=171)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выведем название колонок\n",
    "\n",
    "features_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8fa8aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#масштабирование данных для моделей\n",
    "\n",
    "#выделим количественные признаким (у нас они все количественные)\n",
    "\n",
    "numeric=features_train.columns\n",
    "\n",
    "#создадим объект стандартизации и обучим его для моделей Л\n",
    "scaler = StandardScaler()    \n",
    "scaler.fit(features_train[features_train.columns])\n",
    "\n",
    "#сохраним преобразованные обучающую и тестовую  выборки в переменные\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "\n",
    "#features_train_scaled = scaler.transform(features_train[numeric])\n",
    "\n",
    "#features_test_scaled = scaler.transform(features_test[numeric])\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "806cda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сбросим индексы, чтобы в дальнейшем было проще сопостовлять данные в target и prediction\n",
    "\n",
    "features_train = features_train.reset_index(drop=True)\n",
    "\n",
    "features_test = features_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a5fa3",
   "metadata": {},
   "source": [
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebb870",
   "metadata": {},
   "source": [
    "Данные подготовлены для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c5c3c",
   "metadata": {},
   "source": [
    "## 3. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1afd3f",
   "metadata": {},
   "source": [
    "Обучим данные на 4-х видах моделей и выберем лучшею: Линейная регрессия, Дерево решений, Случайного леса и LightGBM.\n",
    "\n",
    "В качестве метрики будем использовать среднеквадратическую ошибку RMSE, которая показывает разницу между прогнозируемым и фактическим значением. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "096689a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраним randon_state в отдельную переменную\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2feb5",
   "metadata": {},
   "source": [
    "***Обучение модели Линейной регрессии***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21a6c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-22.583597777522094\n"
     ]
    }
   ],
   "source": [
    "#модель Линейной регрессии\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "\n",
    "\n",
    "model_lr.fit(features_train, target_train)                  \n",
    "prediction = model_lr.predict(features_train)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "scores_list = cross_val_score(estimator=model_lr, \n",
    "                              X=features_train, \n",
    "                              y=target_train, \n",
    "                              cv=tscv,  \n",
    "                              scoring= 'neg_root_mean_squared_error')\n",
    "\n",
    "score_lr = scores_list.mean()\n",
    "print(score_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fec5b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.583597777522094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def rmse (target, prediction):\n",
    "    return np.sqrt(mean_squared_error(target, prediction))\n",
    "\n",
    "scorer = make_scorer(rmse)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "scores_list = cross_val_score(estimator=model_lr, \n",
    "                              X=features_train, \n",
    "                              y=target_train, \n",
    "                              cv=tscv,  \n",
    "                              scoring= scorer)\n",
    "\n",
    "score_lr = scores_list.mean()\n",
    "print(score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae21ad7",
   "metadata": {},
   "source": [
    "***Обучение модели Случайного леса***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b19b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8700ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 250 candidates, totalling 1250 fits\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, n_estimators=1;, score=-27.682 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, n_estimators=1;, score=-30.638 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, n_estimators=1;, score=-28.086 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, n_estimators=1;, score=-34.470 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, n_estimators=1;, score=-46.940 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, n_estimators=3;, score=-25.727 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, n_estimators=3;, score=-30.787 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, n_estimators=3;, score=-27.202 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, n_estimators=3;, score=-33.083 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, n_estimators=3;, score=-43.544 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, n_estimators=5;, score=-26.002 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, n_estimators=5;, score=-30.486 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, n_estimators=5;, score=-27.171 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, n_estimators=5;, score=-32.473 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, n_estimators=5;, score=-44.259 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, n_estimators=7;, score=-25.540 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, n_estimators=7;, score=-30.184 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, n_estimators=7;, score=-27.184 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, n_estimators=7;, score=-32.716 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, n_estimators=7;, score=-44.631 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, n_estimators=9;, score=-25.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, n_estimators=9;, score=-30.288 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, n_estimators=9;, score=-27.261 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, n_estimators=9;, score=-32.371 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, n_estimators=9;, score=-44.956 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, n_estimators=1;, score=-27.682 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, n_estimators=1;, score=-30.638 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, n_estimators=1;, score=-28.086 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, n_estimators=1;, score=-34.470 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, n_estimators=1;, score=-46.940 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, n_estimators=3;, score=-25.727 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, n_estimators=3;, score=-30.787 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, n_estimators=3;, score=-27.202 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, n_estimators=3;, score=-33.083 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, n_estimators=3;, score=-43.544 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, n_estimators=5;, score=-26.002 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, n_estimators=5;, score=-30.486 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, n_estimators=5;, score=-27.171 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, n_estimators=5;, score=-32.473 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, n_estimators=5;, score=-44.259 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, n_estimators=7;, score=-25.540 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, n_estimators=7;, score=-30.184 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, n_estimators=7;, score=-27.184 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, n_estimators=7;, score=-32.716 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, n_estimators=7;, score=-44.631 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, n_estimators=9;, score=-25.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, n_estimators=9;, score=-30.288 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, n_estimators=9;, score=-27.261 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, n_estimators=9;, score=-32.371 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, n_estimators=9;, score=-44.956 total time=   0.1s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, n_estimators=1;, score=-27.682 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, n_estimators=1;, score=-30.638 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, n_estimators=1;, score=-28.086 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, n_estimators=1;, score=-34.470 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, n_estimators=1;, score=-46.940 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, n_estimators=3;, score=-25.727 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, n_estimators=3;, score=-30.787 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, n_estimators=3;, score=-27.202 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, n_estimators=3;, score=-33.083 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, n_estimators=3;, score=-43.544 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, n_estimators=5;, score=-26.002 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, n_estimators=5;, score=-30.486 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, n_estimators=5;, score=-27.171 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, n_estimators=5;, score=-32.473 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, n_estimators=5;, score=-44.259 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, n_estimators=7;, score=-25.540 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, n_estimators=7;, score=-30.184 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, n_estimators=7;, score=-27.184 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, n_estimators=7;, score=-32.716 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, n_estimators=7;, score=-44.631 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, n_estimators=9;, score=-25.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, n_estimators=9;, score=-30.288 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, n_estimators=9;, score=-27.261 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, n_estimators=9;, score=-32.371 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, n_estimators=9;, score=-44.956 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, n_estimators=1;, score=-27.682 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, n_estimators=1;, score=-30.638 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, n_estimators=1;, score=-28.086 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, n_estimators=1;, score=-34.470 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, n_estimators=1;, score=-46.940 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, n_estimators=3;, score=-25.727 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, n_estimators=3;, score=-30.787 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, n_estimators=3;, score=-27.202 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, n_estimators=3;, score=-33.083 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, n_estimators=3;, score=-43.544 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, n_estimators=5;, score=-26.002 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, n_estimators=5;, score=-30.486 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, n_estimators=5;, score=-27.171 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, n_estimators=5;, score=-32.473 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, n_estimators=5;, score=-44.259 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, n_estimators=7;, score=-25.540 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, n_estimators=7;, score=-30.184 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, n_estimators=7;, score=-27.184 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, n_estimators=7;, score=-32.716 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, n_estimators=7;, score=-44.631 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, n_estimators=9;, score=-25.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, n_estimators=9;, score=-30.288 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, n_estimators=9;, score=-27.261 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, n_estimators=9;, score=-32.371 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, n_estimators=9;, score=-44.956 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=9, n_estimators=1;, score=-27.682 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=9, n_estimators=1;, score=-30.638 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=9, n_estimators=1;, score=-28.086 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=9, n_estimators=1;, score=-34.470 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=9, n_estimators=1;, score=-46.940 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=9, n_estimators=3;, score=-25.727 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=9, n_estimators=3;, score=-30.787 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=9, n_estimators=3;, score=-27.202 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=9, n_estimators=3;, score=-33.083 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=9, n_estimators=3;, score=-43.544 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=9, n_estimators=5;, score=-26.002 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=9, n_estimators=5;, score=-30.486 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=9, n_estimators=5;, score=-27.171 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=9, n_estimators=5;, score=-32.473 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=9, n_estimators=5;, score=-44.259 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=9, n_estimators=7;, score=-25.540 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=9, n_estimators=7;, score=-30.184 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=9, n_estimators=7;, score=-27.184 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=9, n_estimators=7;, score=-32.716 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=9, n_estimators=7;, score=-44.631 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=9, n_estimators=9;, score=-25.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=9, n_estimators=9;, score=-30.288 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=9, n_estimators=9;, score=-27.261 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=9, n_estimators=9;, score=-32.371 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=9, n_estimators=9;, score=-44.956 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, n_estimators=1;, score=-25.221 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, n_estimators=1;, score=-24.441 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, n_estimators=1;, score=-25.949 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, n_estimators=1;, score=-25.765 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, n_estimators=1;, score=-36.492 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, n_estimators=3;, score=-22.547 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, n_estimators=3;, score=-23.603 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, n_estimators=3;, score=-24.579 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, n_estimators=3;, score=-24.260 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, n_estimators=3;, score=-33.964 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, n_estimators=5;, score=-22.065 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, n_estimators=5;, score=-23.383 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, n_estimators=5;, score=-23.974 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, n_estimators=5;, score=-23.442 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, n_estimators=5;, score=-33.514 total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, n_estimators=7;, score=-21.908 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, n_estimators=7;, score=-23.484 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, n_estimators=7;, score=-23.345 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, n_estimators=7;, score=-23.398 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, n_estimators=7;, score=-33.767 total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, n_estimators=9;, score=-21.853 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, n_estimators=9;, score=-23.496 total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, n_estimators=9;, score=-23.168 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, n_estimators=9;, score=-23.518 total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, n_estimators=9;, score=-34.098 total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, n_estimators=1;, score=-25.221 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, n_estimators=1;, score=-24.441 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, n_estimators=1;, score=-25.949 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, n_estimators=1;, score=-25.765 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, n_estimators=1;, score=-36.492 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, n_estimators=3;, score=-22.517 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, n_estimators=3;, score=-23.603 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, n_estimators=3;, score=-24.579 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, n_estimators=3;, score=-24.260 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, n_estimators=3;, score=-33.964 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, n_estimators=5;, score=-22.054 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, n_estimators=5;, score=-23.383 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, n_estimators=5;, score=-23.974 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, n_estimators=5;, score=-23.442 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, n_estimators=5;, score=-33.514 total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, n_estimators=7;, score=-21.901 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, n_estimators=7;, score=-23.484 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, n_estimators=7;, score=-23.345 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, n_estimators=7;, score=-23.398 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, n_estimators=7;, score=-33.767 total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, n_estimators=9;, score=-21.784 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, n_estimators=9;, score=-23.496 total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, n_estimators=9;, score=-23.168 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, n_estimators=9;, score=-23.518 total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, n_estimators=9;, score=-34.098 total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, n_estimators=1;, score=-25.221 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, n_estimators=1;, score=-24.441 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, n_estimators=1;, score=-25.949 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, n_estimators=1;, score=-25.765 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, n_estimators=1;, score=-36.492 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, n_estimators=3;, score=-22.517 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, n_estimators=3;, score=-23.603 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, n_estimators=3;, score=-24.579 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, n_estimators=3;, score=-24.260 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, n_estimators=3;, score=-33.964 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, n_estimators=5;, score=-22.057 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, n_estimators=5;, score=-23.340 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, n_estimators=5;, score=-23.974 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, n_estimators=5;, score=-23.442 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, n_estimators=5;, score=-33.514 total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, n_estimators=7;, score=-21.890 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, n_estimators=7;, score=-23.476 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, n_estimators=7;, score=-23.345 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, n_estimators=7;, score=-23.391 total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, n_estimators=7;, score=-33.767 total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, n_estimators=9;, score=-21.766 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, n_estimators=9;, score=-23.426 total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, n_estimators=9;, score=-23.168 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, n_estimators=9;, score=-23.512 total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, n_estimators=9;, score=-34.098 total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, n_estimators=1;, score=-25.221 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, n_estimators=1;, score=-24.441 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, n_estimators=1;, score=-25.949 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, n_estimators=1;, score=-25.765 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, n_estimators=1;, score=-36.492 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, n_estimators=3;, score=-22.670 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, n_estimators=3;, score=-23.603 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, n_estimators=3;, score=-24.596 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, n_estimators=3;, score=-24.260 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, n_estimators=3;, score=-33.964 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, n_estimators=5;, score=-22.305 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, n_estimators=5;, score=-23.377 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, n_estimators=5;, score=-23.979 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, n_estimators=5;, score=-23.442 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, n_estimators=5;, score=-33.514 total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, n_estimators=7;, score=-22.079 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, n_estimators=7;, score=-23.542 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, n_estimators=7;, score=-23.346 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, n_estimators=7;, score=-23.394 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, n_estimators=7;, score=-33.767 total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, n_estimators=9;, score=-21.851 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, n_estimators=9;, score=-23.473 total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, n_estimators=9;, score=-23.167 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, n_estimators=9;, score=-23.515 total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, n_estimators=9;, score=-34.098 total time=   0.3s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=9, n_estimators=1;, score=-25.194 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=9, n_estimators=1;, score=-24.441 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=9, n_estimators=1;, score=-25.949 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=9, n_estimators=1;, score=-25.765 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=9, n_estimators=1;, score=-36.492 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=9, n_estimators=3;, score=-22.519 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=9, n_estimators=3;, score=-23.625 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=9, n_estimators=3;, score=-24.474 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=9, n_estimators=3;, score=-24.260 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=9, n_estimators=3;, score=-33.964 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=9, n_estimators=5;, score=-22.051 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=9, n_estimators=5;, score=-23.364 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=9, n_estimators=5;, score=-23.916 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=9, n_estimators=5;, score=-23.442 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=9, n_estimators=5;, score=-33.514 total time=   0.1s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=9, n_estimators=7;, score=-21.877 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=9, n_estimators=7;, score=-23.439 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=9, n_estimators=7;, score=-23.304 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=9, n_estimators=7;, score=-23.394 total time=   0.1s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=9, n_estimators=7;, score=-33.767 total time=   0.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=9, n_estimators=9;, score=-21.697 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=9, n_estimators=9;, score=-23.398 total time=   0.1s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=9, n_estimators=9;, score=-23.133 total time=   0.1s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=9, n_estimators=9;, score=-23.515 total time=   0.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=9, n_estimators=9;, score=-34.098 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, n_estimators=1;, score=-26.702 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, n_estimators=1;, score=-27.852 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, n_estimators=1;, score=-29.331 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, n_estimators=1;, score=-25.759 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, n_estimators=1;, score=-33.459 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, n_estimators=3;, score=-22.804 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, n_estimators=3;, score=-24.678 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, n_estimators=3;, score=-24.201 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, n_estimators=3;, score=-23.856 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, n_estimators=3;, score=-32.103 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, n_estimators=5;, score=-21.875 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, n_estimators=5;, score=-23.364 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, n_estimators=5;, score=-23.549 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, n_estimators=5;, score=-22.943 total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, n_estimators=5;, score=-31.577 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, n_estimators=7;, score=-21.690 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, n_estimators=7;, score=-23.048 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, n_estimators=7;, score=-23.014 total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, n_estimators=7;, score=-22.668 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, n_estimators=7;, score=-31.591 total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, n_estimators=9;, score=-21.279 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, n_estimators=9;, score=-22.843 total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, n_estimators=9;, score=-22.620 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, n_estimators=9;, score=-22.491 total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, n_estimators=9;, score=-31.659 total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, n_estimators=1;, score=-26.757 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, n_estimators=1;, score=-26.403 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, n_estimators=1;, score=-26.198 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, n_estimators=1;, score=-25.762 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, n_estimators=1;, score=-33.469 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, n_estimators=3;, score=-22.230 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, n_estimators=3;, score=-23.505 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, n_estimators=3;, score=-23.114 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, n_estimators=3;, score=-23.475 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, n_estimators=3;, score=-32.119 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, n_estimators=5;, score=-21.546 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, n_estimators=5;, score=-22.804 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, n_estimators=5;, score=-22.967 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, n_estimators=5;, score=-22.911 total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, n_estimators=5;, score=-31.588 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, n_estimators=7;, score=-21.528 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, n_estimators=7;, score=-22.669 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, n_estimators=7;, score=-22.911 total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, n_estimators=7;, score=-22.811 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, n_estimators=7;, score=-31.564 total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, n_estimators=9;, score=-21.180 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, n_estimators=9;, score=-22.575 total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, n_estimators=9;, score=-22.589 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, n_estimators=9;, score=-22.653 total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, n_estimators=9;, score=-31.362 total time=   0.6s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, n_estimators=1;, score=-26.254 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, n_estimators=1;, score=-26.695 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, n_estimators=1;, score=-25.613 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, n_estimators=1;, score=-24.623 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, n_estimators=1;, score=-33.407 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, n_estimators=3;, score=-22.486 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, n_estimators=3;, score=-23.265 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, n_estimators=3;, score=-22.795 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, n_estimators=3;, score=-23.403 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, n_estimators=3;, score=-31.811 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, n_estimators=5;, score=-21.432 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, n_estimators=5;, score=-22.746 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, n_estimators=5;, score=-22.748 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, n_estimators=5;, score=-22.805 total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, n_estimators=5;, score=-31.443 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, n_estimators=7;, score=-21.497 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, n_estimators=7;, score=-22.542 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, n_estimators=7;, score=-22.620 total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, n_estimators=7;, score=-22.717 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, n_estimators=7;, score=-31.458 total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, n_estimators=9;, score=-21.247 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, n_estimators=9;, score=-22.376 total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, n_estimators=9;, score=-22.222 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, n_estimators=9;, score=-22.529 total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, n_estimators=9;, score=-31.371 total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, n_estimators=1;, score=-25.812 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, n_estimators=1;, score=-25.823 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, n_estimators=1;, score=-26.468 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, n_estimators=1;, score=-24.660 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, n_estimators=1;, score=-33.284 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, n_estimators=3;, score=-22.218 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, n_estimators=3;, score=-22.862 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, n_estimators=3;, score=-23.372 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, n_estimators=3;, score=-23.442 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, n_estimators=3;, score=-31.772 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, n_estimators=5;, score=-21.487 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, n_estimators=5;, score=-22.356 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, n_estimators=5;, score=-23.071 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, n_estimators=5;, score=-22.907 total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, n_estimators=5;, score=-31.343 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, n_estimators=7;, score=-21.505 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, n_estimators=7;, score=-22.262 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, n_estimators=7;, score=-22.840 total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, n_estimators=7;, score=-22.746 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, n_estimators=7;, score=-31.325 total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, n_estimators=9;, score=-21.250 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, n_estimators=9;, score=-22.177 total time=   0.2s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, n_estimators=9;, score=-22.432 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, n_estimators=9;, score=-22.536 total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, n_estimators=9;, score=-31.301 total time=   0.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=9, n_estimators=1;, score=-25.803 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=9, n_estimators=1;, score=-25.778 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=9, n_estimators=1;, score=-26.936 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=9, n_estimators=1;, score=-24.619 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=9, n_estimators=1;, score=-33.479 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=9, n_estimators=3;, score=-22.235 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=9, n_estimators=3;, score=-22.809 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=9, n_estimators=3;, score=-23.652 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=9, n_estimators=3;, score=-23.239 total time=   0.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=9, n_estimators=3;, score=-31.638 total time=   0.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=9, n_estimators=5;, score=-21.524 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=9, n_estimators=5;, score=-22.502 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=9, n_estimators=5;, score=-22.989 total time=   0.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=9, n_estimators=5;, score=-22.875 total time=   0.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=9, n_estimators=5;, score=-31.464 total time=   0.3s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=9, n_estimators=7;, score=-21.517 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=9, n_estimators=7;, score=-22.364 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=9, n_estimators=7;, score=-22.754 total time=   0.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=9, n_estimators=7;, score=-22.464 total time=   0.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=9, n_estimators=7;, score=-31.364 total time=   0.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=9, n_estimators=9;, score=-21.274 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=9, n_estimators=9;, score=-22.269 total time=   0.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=9, n_estimators=9;, score=-22.488 total time=   0.3s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=9, n_estimators=9;, score=-22.342 total time=   0.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=9, n_estimators=9;, score=-31.375 total time=   0.5s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, n_estimators=1;, score=-27.543 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, n_estimators=1;, score=-29.862 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, n_estimators=1;, score=-31.452 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, n_estimators=1;, score=-27.527 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, n_estimators=1;, score=-35.031 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, n_estimators=3;, score=-22.780 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, n_estimators=3;, score=-25.126 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, n_estimators=3;, score=-25.533 total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, n_estimators=3;, score=-25.303 total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, n_estimators=3;, score=-31.709 total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, n_estimators=5;, score=-21.998 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, n_estimators=5;, score=-23.139 total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, n_estimators=5;, score=-24.887 total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, n_estimators=5;, score=-23.643 total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, n_estimators=5;, score=-31.208 total time=   0.4s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, n_estimators=7;, score=-21.467 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, n_estimators=7;, score=-22.656 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, n_estimators=7;, score=-23.863 total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, n_estimators=7;, score=-22.980 total time=   0.5s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, n_estimators=7;, score=-31.023 total time=   0.6s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, n_estimators=9;, score=-21.336 total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, n_estimators=9;, score=-22.583 total time=   0.3s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, n_estimators=9;, score=-23.155 total time=   0.4s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, n_estimators=9;, score=-22.552 total time=   0.6s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, n_estimators=9;, score=-30.881 total time=   0.8s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, n_estimators=1;, score=-27.649 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, n_estimators=1;, score=-28.608 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, n_estimators=1;, score=-29.093 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, n_estimators=1;, score=-26.787 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, n_estimators=1;, score=-35.158 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, n_estimators=3;, score=-22.791 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, n_estimators=3;, score=-24.048 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, n_estimators=3;, score=-24.646 total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, n_estimators=3;, score=-24.073 total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, n_estimators=3;, score=-32.199 total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, n_estimators=5;, score=-22.044 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, n_estimators=5;, score=-22.949 total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, n_estimators=5;, score=-23.867 total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, n_estimators=5;, score=-23.340 total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, n_estimators=5;, score=-31.364 total time=   0.4s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, n_estimators=7;, score=-21.755 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, n_estimators=7;, score=-22.642 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, n_estimators=7;, score=-23.467 total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, n_estimators=7;, score=-23.089 total time=   0.4s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, n_estimators=7;, score=-31.058 total time=   0.6s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, n_estimators=9;, score=-21.442 total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, n_estimators=9;, score=-22.512 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, n_estimators=9;, score=-23.001 total time=   0.4s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, n_estimators=9;, score=-22.729 total time=   0.6s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, n_estimators=9;, score=-30.587 total time=   0.8s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, n_estimators=1;, score=-27.353 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, n_estimators=1;, score=-27.191 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, n_estimators=1;, score=-29.000 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, n_estimators=1;, score=-25.754 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, n_estimators=1;, score=-34.333 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, n_estimators=3;, score=-22.792 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, n_estimators=3;, score=-23.344 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, n_estimators=3;, score=-24.272 total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, n_estimators=3;, score=-24.075 total time=   0.2s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, n_estimators=3;, score=-31.511 total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, n_estimators=5;, score=-21.577 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, n_estimators=5;, score=-22.819 total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, n_estimators=5;, score=-23.441 total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, n_estimators=5;, score=-23.355 total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, n_estimators=5;, score=-30.827 total time=   0.4s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, n_estimators=7;, score=-21.442 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, n_estimators=7;, score=-22.444 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, n_estimators=7;, score=-22.898 total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, n_estimators=7;, score=-23.037 total time=   0.4s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, n_estimators=7;, score=-30.584 total time=   0.6s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, n_estimators=9;, score=-21.126 total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, n_estimators=9;, score=-22.194 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, n_estimators=9;, score=-22.490 total time=   0.4s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, n_estimators=9;, score=-22.582 total time=   0.6s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, n_estimators=9;, score=-30.536 total time=   0.9s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, n_estimators=1;, score=-26.447 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, n_estimators=1;, score=-26.837 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, n_estimators=1;, score=-27.927 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, n_estimators=1;, score=-25.266 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, n_estimators=1;, score=-34.541 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, n_estimators=3;, score=-22.443 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, n_estimators=3;, score=-23.241 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, n_estimators=3;, score=-24.212 total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, n_estimators=3;, score=-23.676 total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, n_estimators=3;, score=-31.452 total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, n_estimators=5;, score=-21.610 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, n_estimators=5;, score=-22.553 total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, n_estimators=5;, score=-23.415 total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, n_estimators=5;, score=-23.191 total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, n_estimators=5;, score=-30.800 total time=   0.4s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, n_estimators=7;, score=-21.550 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, n_estimators=7;, score=-22.268 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, n_estimators=7;, score=-22.819 total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, n_estimators=7;, score=-22.946 total time=   0.4s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, n_estimators=7;, score=-30.573 total time=   0.6s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, n_estimators=9;, score=-21.284 total time=   0.1s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, n_estimators=9;, score=-22.073 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, n_estimators=9;, score=-22.354 total time=   0.4s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, n_estimators=9;, score=-22.563 total time=   0.6s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, n_estimators=9;, score=-30.398 total time=   0.8s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=9, n_estimators=1;, score=-25.969 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=9, n_estimators=1;, score=-27.274 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=9, n_estimators=1;, score=-27.891 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=9, n_estimators=1;, score=-24.869 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=9, n_estimators=1;, score=-34.557 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=9, n_estimators=3;, score=-22.463 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=9, n_estimators=3;, score=-23.260 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=9, n_estimators=3;, score=-23.832 total time=   0.1s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=9, n_estimators=3;, score=-23.264 total time=   0.1s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=9, n_estimators=3;, score=-31.299 total time=   0.2s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=9, n_estimators=5;, score=-21.648 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=9, n_estimators=5;, score=-22.708 total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=9, n_estimators=5;, score=-23.222 total time=   0.2s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=9, n_estimators=5;, score=-23.009 total time=   0.3s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=9, n_estimators=5;, score=-30.705 total time=   0.4s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=9, n_estimators=7;, score=-21.608 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=9, n_estimators=7;, score=-22.421 total time=   0.1s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=9, n_estimators=7;, score=-22.658 total time=   0.3s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=9, n_estimators=7;, score=-22.621 total time=   0.4s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=9, n_estimators=7;, score=-30.380 total time=   0.6s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=9, n_estimators=9;, score=-21.384 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=9, n_estimators=9;, score=-22.232 total time=   0.2s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=9, n_estimators=9;, score=-22.368 total time=   0.4s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=9, n_estimators=9;, score=-22.355 total time=   0.6s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=9, n_estimators=9;, score=-30.506 total time=   0.8s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, n_estimators=1;, score=-28.726 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, n_estimators=1;, score=-32.190 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, n_estimators=1;, score=-33.170 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, n_estimators=1;, score=-30.131 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, n_estimators=1;, score=-36.492 total time=   0.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, n_estimators=3;, score=-22.797 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, n_estimators=3;, score=-25.137 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, n_estimators=3;, score=-25.676 total time=   0.1s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, n_estimators=3;, score=-25.509 total time=   0.2s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, n_estimators=3;, score=-31.770 total time=   0.3s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, n_estimators=5;, score=-21.766 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, n_estimators=5;, score=-23.123 total time=   0.1s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, n_estimators=5;, score=-24.387 total time=   0.3s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, n_estimators=5;, score=-24.056 total time=   0.4s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, n_estimators=5;, score=-30.882 total time=   0.5s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, n_estimators=7;, score=-21.373 total time=   0.1s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, n_estimators=7;, score=-22.646 total time=   0.2s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, n_estimators=7;, score=-23.641 total time=   0.4s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, n_estimators=7;, score=-23.340 total time=   0.6s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, n_estimators=7;, score=-31.003 total time=   0.8s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, n_estimators=9;, score=-21.236 total time=   0.1s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, n_estimators=9;, score=-22.558 total time=   0.3s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, n_estimators=9;, score=-23.210 total time=   0.6s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, n_estimators=9;, score=-23.048 total time=   0.8s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, n_estimators=9;, score=-30.900 total time=   1.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, n_estimators=1;, score=-28.390 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, n_estimators=1;, score=-29.620 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, n_estimators=1;, score=-31.196 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, n_estimators=1;, score=-28.259 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, n_estimators=1;, score=-35.551 total time=   0.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, n_estimators=3;, score=-22.885 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, n_estimators=3;, score=-23.971 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, n_estimators=3;, score=-25.275 total time=   0.1s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, n_estimators=3;, score=-24.736 total time=   0.2s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, n_estimators=3;, score=-32.119 total time=   0.3s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, n_estimators=5;, score=-21.818 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, n_estimators=5;, score=-22.772 total time=   0.1s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, n_estimators=5;, score=-24.042 total time=   0.3s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, n_estimators=5;, score=-23.801 total time=   0.4s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, n_estimators=5;, score=-31.179 total time=   0.5s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, n_estimators=7;, score=-21.397 total time=   0.1s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, n_estimators=7;, score=-22.448 total time=   0.2s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, n_estimators=7;, score=-23.589 total time=   0.4s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, n_estimators=7;, score=-23.417 total time=   0.6s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, n_estimators=7;, score=-30.977 total time=   0.7s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, n_estimators=9;, score=-21.177 total time=   0.1s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, n_estimators=9;, score=-22.383 total time=   0.3s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, n_estimators=9;, score=-23.177 total time=   0.5s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, n_estimators=9;, score=-22.982 total time=   0.8s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, n_estimators=9;, score=-30.580 total time=   1.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, n_estimators=1;, score=-27.436 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, n_estimators=1;, score=-27.959 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, n_estimators=1;, score=-30.544 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, n_estimators=1;, score=-27.275 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, n_estimators=1;, score=-34.563 total time=   0.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, n_estimators=3;, score=-22.498 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, n_estimators=3;, score=-23.545 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, n_estimators=3;, score=-24.647 total time=   0.1s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, n_estimators=3;, score=-24.401 total time=   0.2s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, n_estimators=3;, score=-31.570 total time=   0.3s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, n_estimators=5;, score=-21.432 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, n_estimators=5;, score=-22.589 total time=   0.1s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, n_estimators=5;, score=-23.385 total time=   0.2s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, n_estimators=5;, score=-23.836 total time=   0.4s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, n_estimators=5;, score=-30.661 total time=   0.5s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, n_estimators=7;, score=-21.198 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, n_estimators=7;, score=-22.134 total time=   0.2s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, n_estimators=7;, score=-22.895 total time=   0.4s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, n_estimators=7;, score=-23.412 total time=   0.6s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, n_estimators=7;, score=-30.375 total time=   0.7s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, n_estimators=9;, score=-20.947 total time=   0.1s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, n_estimators=9;, score=-21.976 total time=   0.3s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, n_estimators=9;, score=-22.612 total time=   0.5s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, n_estimators=9;, score=-22.903 total time=   0.7s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, n_estimators=9;, score=-30.434 total time=   1.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, n_estimators=1;, score=-26.502 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, n_estimators=1;, score=-27.268 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, n_estimators=1;, score=-28.907 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, n_estimators=1;, score=-27.992 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, n_estimators=1;, score=-36.273 total time=   0.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, n_estimators=3;, score=-22.307 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, n_estimators=3;, score=-23.416 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, n_estimators=3;, score=-24.723 total time=   0.1s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, n_estimators=3;, score=-24.290 total time=   0.2s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, n_estimators=3;, score=-32.209 total time=   0.2s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, n_estimators=5;, score=-21.495 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, n_estimators=5;, score=-22.479 total time=   0.1s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, n_estimators=5;, score=-23.472 total time=   0.2s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, n_estimators=5;, score=-23.593 total time=   0.4s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, n_estimators=5;, score=-31.118 total time=   0.5s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, n_estimators=7;, score=-21.437 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, n_estimators=7;, score=-22.105 total time=   0.2s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, n_estimators=7;, score=-22.921 total time=   0.3s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, n_estimators=7;, score=-23.226 total time=   0.5s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, n_estimators=7;, score=-30.763 total time=   0.7s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, n_estimators=9;, score=-21.171 total time=   0.1s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, n_estimators=9;, score=-21.896 total time=   0.3s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, n_estimators=9;, score=-22.487 total time=   0.5s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, n_estimators=9;, score=-22.789 total time=   0.7s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, n_estimators=9;, score=-30.471 total time=   0.9s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=9, n_estimators=1;, score=-26.190 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=9, n_estimators=1;, score=-27.708 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=9, n_estimators=1;, score=-28.494 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=9, n_estimators=1;, score=-27.900 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=9, n_estimators=1;, score=-35.235 total time=   0.0s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=9, n_estimators=3;, score=-22.672 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=9, n_estimators=3;, score=-23.529 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=9, n_estimators=3;, score=-23.934 total time=   0.1s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=9, n_estimators=3;, score=-23.980 total time=   0.2s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=9, n_estimators=3;, score=-31.709 total time=   0.2s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=9, n_estimators=5;, score=-21.769 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=9, n_estimators=5;, score=-22.779 total time=   0.1s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=9, n_estimators=5;, score=-23.115 total time=   0.2s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=9, n_estimators=5;, score=-23.496 total time=   0.3s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=9, n_estimators=5;, score=-30.870 total time=   0.5s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=9, n_estimators=7;, score=-21.598 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=9, n_estimators=7;, score=-22.420 total time=   0.2s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=9, n_estimators=7;, score=-22.608 total time=   0.3s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=9, n_estimators=7;, score=-23.041 total time=   0.5s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=9, n_estimators=7;, score=-30.472 total time=   0.7s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=9, n_estimators=9;, score=-21.373 total time=   0.1s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=9, n_estimators=9;, score=-22.186 total time=   0.3s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=9, n_estimators=9;, score=-22.379 total time=   0.5s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=9, n_estimators=9;, score=-22.651 total time=   0.7s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=9, n_estimators=9;, score=-30.599 total time=   0.9s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, n_estimators=1;, score=-29.626 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, n_estimators=1;, score=-33.563 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, n_estimators=1;, score=-33.737 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, n_estimators=1;, score=-32.639 total time=   0.0s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, n_estimators=1;, score=-38.553 total time=   0.0s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, n_estimators=3;, score=-23.694 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, n_estimators=3;, score=-26.030 total time=   0.1s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, n_estimators=3;, score=-26.548 total time=   0.2s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, n_estimators=3;, score=-26.897 total time=   0.2s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, n_estimators=3;, score=-33.155 total time=   0.3s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, n_estimators=5;, score=-22.399 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, n_estimators=5;, score=-23.670 total time=   0.2s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, n_estimators=5;, score=-24.447 total time=   0.3s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, n_estimators=5;, score=-24.625 total time=   0.5s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, n_estimators=5;, score=-32.131 total time=   0.6s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, n_estimators=7;, score=-21.829 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, n_estimators=7;, score=-23.022 total time=   0.3s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, n_estimators=7;, score=-23.633 total time=   0.5s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, n_estimators=7;, score=-23.757 total time=   0.7s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, n_estimators=7;, score=-31.861 total time=   0.9s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, n_estimators=9;, score=-21.583 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, n_estimators=9;, score=-22.681 total time=   0.4s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, n_estimators=9;, score=-23.125 total time=   0.6s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, n_estimators=9;, score=-23.170 total time=   0.9s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, n_estimators=9;, score=-31.418 total time=   1.2s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, n_estimators=1;, score=-29.066 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, n_estimators=1;, score=-30.333 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, n_estimators=1;, score=-31.564 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, n_estimators=1;, score=-30.116 total time=   0.0s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, n_estimators=1;, score=-36.538 total time=   0.0s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, n_estimators=3;, score=-23.561 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, n_estimators=3;, score=-23.948 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, n_estimators=3;, score=-25.424 total time=   0.1s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, n_estimators=3;, score=-24.983 total time=   0.2s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, n_estimators=3;, score=-32.560 total time=   0.3s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, n_estimators=5;, score=-22.250 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, n_estimators=5;, score=-22.736 total time=   0.1s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, n_estimators=5;, score=-24.266 total time=   0.3s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, n_estimators=5;, score=-23.971 total time=   0.4s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, n_estimators=5;, score=-31.617 total time=   0.6s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, n_estimators=7;, score=-21.727 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, n_estimators=7;, score=-22.405 total time=   0.2s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, n_estimators=7;, score=-23.695 total time=   0.4s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, n_estimators=7;, score=-23.671 total time=   0.7s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, n_estimators=7;, score=-31.206 total time=   0.8s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, n_estimators=9;, score=-21.246 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, n_estimators=9;, score=-22.332 total time=   0.4s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, n_estimators=9;, score=-23.304 total time=   0.6s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, n_estimators=9;, score=-23.282 total time=   0.9s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, n_estimators=9;, score=-30.577 total time=   1.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, n_estimators=1;, score=-27.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, n_estimators=1;, score=-28.163 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, n_estimators=1;, score=-30.933 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, n_estimators=1;, score=-28.067 total time=   0.0s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, n_estimators=1;, score=-35.665 total time=   0.0s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, n_estimators=3;, score=-22.864 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, n_estimators=3;, score=-23.715 total time=   0.1s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, n_estimators=3;, score=-24.804 total time=   0.1s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, n_estimators=3;, score=-24.697 total time=   0.2s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, n_estimators=3;, score=-31.947 total time=   0.3s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, n_estimators=5;, score=-21.459 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, n_estimators=5;, score=-22.675 total time=   0.1s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, n_estimators=5;, score=-23.482 total time=   0.3s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, n_estimators=5;, score=-23.807 total time=   0.4s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, n_estimators=5;, score=-30.848 total time=   0.5s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, n_estimators=7;, score=-21.228 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, n_estimators=7;, score=-22.180 total time=   0.2s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, n_estimators=7;, score=-23.018 total time=   0.4s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, n_estimators=7;, score=-23.449 total time=   0.6s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, n_estimators=7;, score=-30.461 total time=   0.8s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, n_estimators=9;, score=-20.981 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, n_estimators=9;, score=-21.962 total time=   0.3s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, n_estimators=9;, score=-22.671 total time=   0.5s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, n_estimators=9;, score=-22.963 total time=   0.8s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, n_estimators=9;, score=-30.474 total time=   1.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, n_estimators=1;, score=-26.502 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, n_estimators=1;, score=-27.175 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, n_estimators=1;, score=-29.077 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, n_estimators=1;, score=-28.543 total time=   0.0s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, n_estimators=1;, score=-36.663 total time=   0.0s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, n_estimators=3;, score=-22.547 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, n_estimators=3;, score=-23.479 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, n_estimators=3;, score=-24.718 total time=   0.1s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, n_estimators=3;, score=-24.232 total time=   0.2s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, n_estimators=3;, score=-32.282 total time=   0.3s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, n_estimators=5;, score=-21.581 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, n_estimators=5;, score=-22.532 total time=   0.1s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, n_estimators=5;, score=-23.483 total time=   0.2s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, n_estimators=5;, score=-23.410 total time=   0.4s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, n_estimators=5;, score=-31.130 total time=   0.5s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, n_estimators=7;, score=-21.469 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, n_estimators=7;, score=-22.129 total time=   0.2s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, n_estimators=7;, score=-22.929 total time=   0.4s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, n_estimators=7;, score=-23.101 total time=   0.6s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, n_estimators=7;, score=-30.735 total time=   0.8s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, n_estimators=9;, score=-21.187 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, n_estimators=9;, score=-21.895 total time=   0.3s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, n_estimators=9;, score=-22.552 total time=   0.5s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, n_estimators=9;, score=-22.679 total time=   0.8s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, n_estimators=9;, score=-30.427 total time=   1.0s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=9, n_estimators=1;, score=-26.190 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=9, n_estimators=1;, score=-27.777 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=9, n_estimators=1;, score=-28.720 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=9, n_estimators=1;, score=-28.435 total time=   0.0s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=9, n_estimators=1;, score=-35.360 total time=   0.0s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=9, n_estimators=3;, score=-22.698 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=9, n_estimators=3;, score=-23.535 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=9, n_estimators=3;, score=-23.989 total time=   0.1s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=9, n_estimators=3;, score=-24.010 total time=   0.2s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=9, n_estimators=3;, score=-31.763 total time=   0.3s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=9, n_estimators=5;, score=-21.771 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=9, n_estimators=5;, score=-22.753 total time=   0.1s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=9, n_estimators=5;, score=-23.162 total time=   0.2s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=9, n_estimators=5;, score=-23.473 total time=   0.4s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=9, n_estimators=5;, score=-30.981 total time=   0.5s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=9, n_estimators=7;, score=-21.582 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=9, n_estimators=7;, score=-22.422 total time=   0.2s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=9, n_estimators=7;, score=-22.606 total time=   0.4s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=9, n_estimators=7;, score=-23.088 total time=   0.6s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=9, n_estimators=7;, score=-30.545 total time=   0.7s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=9, n_estimators=9;, score=-21.363 total time=   0.1s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=9, n_estimators=9;, score=-22.187 total time=   0.3s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=9, n_estimators=9;, score=-22.379 total time=   0.5s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=9, n_estimators=9;, score=-22.672 total time=   0.7s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=9, n_estimators=9;, score=-30.627 total time=   1.0s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, n_estimators=1;, score=-29.443 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, n_estimators=1;, score=-33.704 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, n_estimators=1;, score=-36.755 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, n_estimators=1;, score=-34.452 total time=   0.0s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, n_estimators=1;, score=-39.088 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, n_estimators=3;, score=-24.104 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, n_estimators=3;, score=-26.227 total time=   0.1s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, n_estimators=3;, score=-26.770 total time=   0.2s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, n_estimators=3;, score=-27.892 total time=   0.3s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, n_estimators=3;, score=-32.480 total time=   0.4s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, n_estimators=5;, score=-22.361 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, n_estimators=5;, score=-23.376 total time=   0.2s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, n_estimators=5;, score=-24.401 total time=   0.4s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, n_estimators=5;, score=-25.170 total time=   0.5s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, n_estimators=5;, score=-31.438 total time=   0.7s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, n_estimators=7;, score=-21.675 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, n_estimators=7;, score=-22.957 total time=   0.3s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, n_estimators=7;, score=-23.577 total time=   0.5s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, n_estimators=7;, score=-23.966 total time=   0.8s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, n_estimators=7;, score=-31.440 total time=   1.0s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, n_estimators=9;, score=-21.498 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, n_estimators=9;, score=-22.546 total time=   0.4s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, n_estimators=9;, score=-23.098 total time=   0.7s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, n_estimators=9;, score=-23.390 total time=   1.0s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, n_estimators=9;, score=-30.982 total time=   1.3s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, n_estimators=1;, score=-28.484 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, n_estimators=1;, score=-30.041 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, n_estimators=1;, score=-32.436 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, n_estimators=1;, score=-32.525 total time=   0.0s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, n_estimators=1;, score=-37.246 total time=   0.0s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, n_estimators=3;, score=-23.228 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, n_estimators=3;, score=-24.136 total time=   0.1s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, n_estimators=3;, score=-25.485 total time=   0.2s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, n_estimators=3;, score=-25.816 total time=   0.2s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, n_estimators=3;, score=-32.560 total time=   0.3s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, n_estimators=5;, score=-22.135 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, n_estimators=5;, score=-22.854 total time=   0.2s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, n_estimators=5;, score=-24.061 total time=   0.3s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, n_estimators=5;, score=-24.358 total time=   0.5s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, n_estimators=5;, score=-31.450 total time=   0.6s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, n_estimators=7;, score=-21.675 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, n_estimators=7;, score=-22.472 total time=   0.3s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, n_estimators=7;, score=-23.589 total time=   0.5s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, n_estimators=7;, score=-23.893 total time=   0.7s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, n_estimators=7;, score=-31.058 total time=   0.9s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, n_estimators=9;, score=-21.311 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, n_estimators=9;, score=-22.359 total time=   0.4s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, n_estimators=9;, score=-23.247 total time=   0.6s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, n_estimators=9;, score=-23.403 total time=   0.9s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, n_estimators=9;, score=-30.479 total time=   1.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, n_estimators=1;, score=-27.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, n_estimators=1;, score=-28.172 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, n_estimators=1;, score=-31.099 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, n_estimators=1;, score=-28.024 total time=   0.0s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, n_estimators=1;, score=-35.693 total time=   0.0s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, n_estimators=3;, score=-22.833 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, n_estimators=3;, score=-23.710 total time=   0.1s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, n_estimators=3;, score=-24.952 total time=   0.1s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, n_estimators=3;, score=-24.919 total time=   0.2s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, n_estimators=3;, score=-31.969 total time=   0.3s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, n_estimators=5;, score=-21.428 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, n_estimators=5;, score=-22.635 total time=   0.1s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, n_estimators=5;, score=-23.481 total time=   0.3s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, n_estimators=5;, score=-23.924 total time=   0.4s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, n_estimators=5;, score=-30.847 total time=   0.6s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, n_estimators=7;, score=-21.282 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, n_estimators=7;, score=-22.176 total time=   0.2s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, n_estimators=7;, score=-23.033 total time=   0.4s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, n_estimators=7;, score=-23.534 total time=   0.7s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, n_estimators=7;, score=-30.458 total time=   0.8s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, n_estimators=9;, score=-21.021 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, n_estimators=9;, score=-21.958 total time=   0.3s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, n_estimators=9;, score=-22.712 total time=   0.6s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, n_estimators=9;, score=-23.004 total time=   0.9s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, n_estimators=9;, score=-30.493 total time=   1.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, n_estimators=1;, score=-26.502 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, n_estimators=1;, score=-27.213 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, n_estimators=1;, score=-29.271 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, n_estimators=1;, score=-28.806 total time=   0.0s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, n_estimators=1;, score=-36.597 total time=   0.0s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, n_estimators=3;, score=-22.531 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, n_estimators=3;, score=-23.473 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, n_estimators=3;, score=-24.766 total time=   0.1s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, n_estimators=3;, score=-24.354 total time=   0.2s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, n_estimators=3;, score=-32.337 total time=   0.3s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, n_estimators=5;, score=-21.563 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, n_estimators=5;, score=-22.466 total time=   0.1s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, n_estimators=5;, score=-23.535 total time=   0.3s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, n_estimators=5;, score=-23.551 total time=   0.4s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, n_estimators=5;, score=-31.182 total time=   0.5s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, n_estimators=7;, score=-21.455 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, n_estimators=7;, score=-22.102 total time=   0.2s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, n_estimators=7;, score=-22.944 total time=   0.4s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, n_estimators=7;, score=-23.192 total time=   0.6s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, n_estimators=7;, score=-30.761 total time=   0.8s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, n_estimators=9;, score=-21.179 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, n_estimators=9;, score=-21.868 total time=   0.3s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, n_estimators=9;, score=-22.564 total time=   0.5s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, n_estimators=9;, score=-22.767 total time=   0.8s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, n_estimators=9;, score=-30.442 total time=   1.0s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=9, n_estimators=1;, score=-26.190 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=9, n_estimators=1;, score=-27.907 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=9, n_estimators=1;, score=-28.765 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=9, n_estimators=1;, score=-28.388 total time=   0.0s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=9, n_estimators=1;, score=-35.348 total time=   0.0s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=9, n_estimators=3;, score=-22.698 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=9, n_estimators=3;, score=-23.554 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=9, n_estimators=3;, score=-24.019 total time=   0.1s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=9, n_estimators=3;, score=-23.993 total time=   0.2s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=9, n_estimators=3;, score=-31.772 total time=   0.3s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=9, n_estimators=5;, score=-21.771 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=9, n_estimators=5;, score=-22.756 total time=   0.1s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=9, n_estimators=5;, score=-23.171 total time=   0.2s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=9, n_estimators=5;, score=-23.475 total time=   0.4s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=9, n_estimators=5;, score=-30.989 total time=   0.5s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=9, n_estimators=7;, score=-21.582 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=9, n_estimators=7;, score=-22.421 total time=   0.2s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=9, n_estimators=7;, score=-22.593 total time=   0.4s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=9, n_estimators=7;, score=-23.098 total time=   0.6s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=9, n_estimators=7;, score=-30.566 total time=   0.7s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=9, n_estimators=9;, score=-21.363 total time=   0.1s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=9, n_estimators=9;, score=-22.183 total time=   0.3s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=9, n_estimators=9;, score=-22.369 total time=   0.5s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=9, n_estimators=9;, score=-22.680 total time=   0.7s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=9, n_estimators=9;, score=-30.641 total time=   1.0s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, n_estimators=1;, score=-29.140 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, n_estimators=1;, score=-33.176 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, n_estimators=1;, score=-36.298 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, n_estimators=1;, score=-34.161 total time=   0.0s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, n_estimators=1;, score=-38.514 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, n_estimators=3;, score=-23.377 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, n_estimators=3;, score=-26.119 total time=   0.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, n_estimators=3;, score=-26.323 total time=   0.2s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, n_estimators=3;, score=-27.530 total time=   0.3s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, n_estimators=3;, score=-32.355 total time=   0.4s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, n_estimators=5;, score=-22.236 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, n_estimators=5;, score=-23.873 total time=   0.2s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, n_estimators=5;, score=-24.617 total time=   0.4s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, n_estimators=5;, score=-25.135 total time=   0.6s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, n_estimators=5;, score=-31.311 total time=   0.7s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, n_estimators=7;, score=-21.730 total time=   0.1s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, n_estimators=7;, score=-23.042 total time=   0.3s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, n_estimators=7;, score=-23.921 total time=   0.6s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, n_estimators=7;, score=-24.061 total time=   0.8s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, n_estimators=7;, score=-31.336 total time=   1.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, n_estimators=9;, score=-21.571 total time=   0.1s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, n_estimators=9;, score=-22.848 total time=   0.4s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, n_estimators=9;, score=-23.269 total time=   0.7s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, n_estimators=9;, score=-23.505 total time=   1.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, n_estimators=9;, score=-30.927 total time=   1.4s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, n_estimators=1;, score=-28.484 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, n_estimators=1;, score=-29.942 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, n_estimators=1;, score=-32.047 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, n_estimators=1;, score=-32.847 total time=   0.0s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, n_estimators=1;, score=-37.283 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, n_estimators=3;, score=-23.328 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, n_estimators=3;, score=-24.170 total time=   0.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, n_estimators=3;, score=-25.411 total time=   0.2s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, n_estimators=3;, score=-25.866 total time=   0.3s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, n_estimators=3;, score=-32.262 total time=   0.4s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, n_estimators=5;, score=-22.022 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, n_estimators=5;, score=-22.934 total time=   0.2s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, n_estimators=5;, score=-24.448 total time=   0.3s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, n_estimators=5;, score=-24.200 total time=   0.5s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, n_estimators=5;, score=-31.319 total time=   0.7s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, n_estimators=7;, score=-21.552 total time=   0.1s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, n_estimators=7;, score=-22.470 total time=   0.3s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, n_estimators=7;, score=-23.779 total time=   0.5s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, n_estimators=7;, score=-23.736 total time=   0.7s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, n_estimators=7;, score=-30.963 total time=   0.9s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, n_estimators=9;, score=-21.203 total time=   0.1s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, n_estimators=9;, score=-22.398 total time=   0.4s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, n_estimators=9;, score=-23.353 total time=   0.6s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, n_estimators=9;, score=-23.238 total time=   1.0s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, n_estimators=9;, score=-30.380 total time=   1.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, n_estimators=1;, score=-27.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, n_estimators=1;, score=-28.090 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, n_estimators=1;, score=-31.279 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, n_estimators=1;, score=-28.380 total time=   0.0s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, n_estimators=1;, score=-35.809 total time=   0.0s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, n_estimators=3;, score=-22.844 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, n_estimators=3;, score=-23.619 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, n_estimators=3;, score=-24.946 total time=   0.1s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, n_estimators=3;, score=-25.128 total time=   0.2s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, n_estimators=3;, score=-32.071 total time=   0.3s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, n_estimators=5;, score=-21.432 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, n_estimators=5;, score=-22.561 total time=   0.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, n_estimators=5;, score=-23.633 total time=   0.3s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, n_estimators=5;, score=-24.154 total time=   0.4s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, n_estimators=5;, score=-30.922 total time=   0.6s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, n_estimators=7;, score=-21.283 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, n_estimators=7;, score=-22.118 total time=   0.2s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, n_estimators=7;, score=-23.105 total time=   0.4s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, n_estimators=7;, score=-23.655 total time=   0.7s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, n_estimators=7;, score=-30.501 total time=   0.8s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, n_estimators=9;, score=-21.022 total time=   0.1s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, n_estimators=9;, score=-21.914 total time=   0.3s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, n_estimators=9;, score=-22.703 total time=   0.6s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, n_estimators=9;, score=-23.084 total time=   0.9s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, n_estimators=9;, score=-30.561 total time=   1.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, n_estimators=1;, score=-26.502 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, n_estimators=1;, score=-27.221 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, n_estimators=1;, score=-29.237 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, n_estimators=1;, score=-28.896 total time=   0.0s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, n_estimators=1;, score=-36.620 total time=   0.0s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, n_estimators=3;, score=-22.531 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, n_estimators=3;, score=-23.486 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, n_estimators=3;, score=-24.801 total time=   0.1s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, n_estimators=3;, score=-24.364 total time=   0.2s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, n_estimators=3;, score=-32.286 total time=   0.3s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, n_estimators=5;, score=-21.563 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, n_estimators=5;, score=-22.471 total time=   0.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, n_estimators=5;, score=-23.546 total time=   0.2s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, n_estimators=5;, score=-23.568 total time=   0.4s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, n_estimators=5;, score=-31.178 total time=   0.5s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, n_estimators=7;, score=-21.455 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, n_estimators=7;, score=-22.106 total time=   0.2s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, n_estimators=7;, score=-22.966 total time=   0.4s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, n_estimators=7;, score=-23.206 total time=   0.6s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, n_estimators=7;, score=-30.760 total time=   0.8s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, n_estimators=9;, score=-21.179 total time=   0.1s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, n_estimators=9;, score=-21.872 total time=   0.3s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, n_estimators=9;, score=-22.574 total time=   0.5s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, n_estimators=9;, score=-22.775 total time=   0.8s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, n_estimators=9;, score=-30.445 total time=   1.0s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=9, n_estimators=1;, score=-26.190 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=9, n_estimators=1;, score=-27.907 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=9, n_estimators=1;, score=-28.765 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=9, n_estimators=1;, score=-28.368 total time=   0.0s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=9, n_estimators=1;, score=-35.351 total time=   0.0s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=9, n_estimators=3;, score=-22.698 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=9, n_estimators=3;, score=-23.552 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=9, n_estimators=3;, score=-24.012 total time=   0.1s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=9, n_estimators=3;, score=-23.997 total time=   0.2s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=9, n_estimators=3;, score=-31.772 total time=   0.3s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=9, n_estimators=5;, score=-21.771 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=9, n_estimators=5;, score=-22.755 total time=   0.1s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=9, n_estimators=5;, score=-23.173 total time=   0.2s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=9, n_estimators=5;, score=-23.485 total time=   0.4s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=9, n_estimators=5;, score=-30.999 total time=   0.5s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=9, n_estimators=7;, score=-21.582 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=9, n_estimators=7;, score=-22.419 total time=   0.2s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=9, n_estimators=7;, score=-22.601 total time=   0.4s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=9, n_estimators=7;, score=-23.100 total time=   0.6s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=9, n_estimators=7;, score=-30.570 total time=   0.7s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=9, n_estimators=9;, score=-21.363 total time=   0.1s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=9, n_estimators=9;, score=-22.182 total time=   0.3s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=9, n_estimators=9;, score=-22.378 total time=   0.5s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=9, n_estimators=9;, score=-22.682 total time=   0.7s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=9, n_estimators=9;, score=-30.643 total time=   1.0s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, n_estimators=1;, score=-29.140 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, n_estimators=1;, score=-32.058 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, n_estimators=1;, score=-35.092 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, n_estimators=1;, score=-34.355 total time=   0.0s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, n_estimators=1;, score=-39.458 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, n_estimators=3;, score=-23.539 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, n_estimators=3;, score=-25.401 total time=   0.1s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, n_estimators=3;, score=-26.809 total time=   0.2s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, n_estimators=3;, score=-26.942 total time=   0.3s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, n_estimators=3;, score=-32.699 total time=   0.4s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, n_estimators=5;, score=-22.315 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, n_estimators=5;, score=-23.196 total time=   0.2s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, n_estimators=5;, score=-25.401 total time=   0.4s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, n_estimators=5;, score=-24.698 total time=   0.6s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, n_estimators=5;, score=-31.266 total time=   0.8s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, n_estimators=7;, score=-21.789 total time=   0.1s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, n_estimators=7;, score=-22.638 total time=   0.3s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, n_estimators=7;, score=-24.308 total time=   0.6s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, n_estimators=7;, score=-23.687 total time=   0.9s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, n_estimators=7;, score=-31.156 total time=   1.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, n_estimators=9;, score=-21.465 total time=   0.2s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, n_estimators=9;, score=-22.569 total time=   0.4s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, n_estimators=9;, score=-23.747 total time=   0.8s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, n_estimators=9;, score=-23.321 total time=   1.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, n_estimators=9;, score=-30.926 total time=   1.4s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, n_estimators=1;, score=-28.484 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, n_estimators=1;, score=-29.849 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, n_estimators=1;, score=-31.595 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, n_estimators=1;, score=-32.853 total time=   0.0s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, n_estimators=1;, score=-37.097 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, n_estimators=3;, score=-23.328 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, n_estimators=3;, score=-24.274 total time=   0.1s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, n_estimators=3;, score=-25.473 total time=   0.2s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, n_estimators=3;, score=-26.029 total time=   0.3s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, n_estimators=3;, score=-32.202 total time=   0.4s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, n_estimators=5;, score=-22.159 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, n_estimators=5;, score=-22.886 total time=   0.2s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, n_estimators=5;, score=-23.900 total time=   0.3s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, n_estimators=5;, score=-24.231 total time=   0.5s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, n_estimators=5;, score=-31.173 total time=   0.7s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, n_estimators=7;, score=-21.684 total time=   0.1s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, n_estimators=7;, score=-22.458 total time=   0.3s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, n_estimators=7;, score=-23.442 total time=   0.5s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, n_estimators=7;, score=-23.835 total time=   0.7s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, n_estimators=7;, score=-30.958 total time=   0.9s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, n_estimators=9;, score=-21.332 total time=   0.1s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, n_estimators=9;, score=-22.394 total time=   0.4s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, n_estimators=9;, score=-23.151 total time=   0.7s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, n_estimators=9;, score=-23.305 total time=   1.0s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, n_estimators=9;, score=-30.554 total time=   1.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, n_estimators=1;, score=-27.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, n_estimators=1;, score=-28.136 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, n_estimators=1;, score=-31.279 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, n_estimators=1;, score=-28.491 total time=   0.0s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, n_estimators=1;, score=-35.706 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, n_estimators=3;, score=-22.844 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, n_estimators=3;, score=-23.698 total time=   0.1s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, n_estimators=3;, score=-24.962 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, n_estimators=3;, score=-25.161 total time=   0.2s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, n_estimators=3;, score=-32.047 total time=   0.3s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, n_estimators=5;, score=-21.432 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, n_estimators=5;, score=-22.606 total time=   0.1s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, n_estimators=5;, score=-23.658 total time=   0.3s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, n_estimators=5;, score=-24.256 total time=   0.5s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, n_estimators=5;, score=-30.880 total time=   0.6s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, n_estimators=7;, score=-21.283 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, n_estimators=7;, score=-22.148 total time=   0.2s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, n_estimators=7;, score=-23.137 total time=   0.4s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, n_estimators=7;, score=-23.701 total time=   0.7s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, n_estimators=7;, score=-30.465 total time=   0.9s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, n_estimators=9;, score=-21.022 total time=   0.1s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, n_estimators=9;, score=-21.966 total time=   0.3s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, n_estimators=9;, score=-22.759 total time=   0.6s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, n_estimators=9;, score=-23.118 total time=   0.9s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, n_estimators=9;, score=-30.531 total time=   1.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, n_estimators=1;, score=-26.502 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, n_estimators=1;, score=-27.221 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, n_estimators=1;, score=-29.237 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, n_estimators=1;, score=-28.896 total time=   0.0s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, n_estimators=1;, score=-36.618 total time=   0.0s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, n_estimators=3;, score=-22.531 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, n_estimators=3;, score=-23.489 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, n_estimators=3;, score=-24.801 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, n_estimators=3;, score=-24.361 total time=   0.2s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, n_estimators=3;, score=-32.323 total time=   0.3s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, n_estimators=5;, score=-21.563 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, n_estimators=5;, score=-22.472 total time=   0.1s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, n_estimators=5;, score=-23.546 total time=   0.3s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, n_estimators=5;, score=-23.570 total time=   0.4s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, n_estimators=5;, score=-31.180 total time=   0.5s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, n_estimators=7;, score=-21.455 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, n_estimators=7;, score=-22.107 total time=   0.2s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, n_estimators=7;, score=-22.966 total time=   0.4s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, n_estimators=7;, score=-23.202 total time=   0.6s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, n_estimators=7;, score=-30.761 total time=   0.8s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, n_estimators=9;, score=-21.179 total time=   0.1s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, n_estimators=9;, score=-21.872 total time=   0.3s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, n_estimators=9;, score=-22.573 total time=   0.5s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, n_estimators=9;, score=-22.772 total time=   0.8s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, n_estimators=9;, score=-30.443 total time=   1.0s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=9, n_estimators=1;, score=-26.190 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=9, n_estimators=1;, score=-27.907 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=9, n_estimators=1;, score=-28.765 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=9, n_estimators=1;, score=-28.368 total time=   0.0s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=9, n_estimators=1;, score=-35.344 total time=   0.0s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=9, n_estimators=3;, score=-22.698 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=9, n_estimators=3;, score=-23.552 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=9, n_estimators=3;, score=-24.012 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=9, n_estimators=3;, score=-23.997 total time=   0.2s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=9, n_estimators=3;, score=-31.774 total time=   0.3s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=9, n_estimators=5;, score=-21.771 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=9, n_estimators=5;, score=-22.755 total time=   0.1s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=9, n_estimators=5;, score=-23.173 total time=   0.2s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=9, n_estimators=5;, score=-23.485 total time=   0.4s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=9, n_estimators=5;, score=-30.999 total time=   0.5s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=9, n_estimators=7;, score=-21.582 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=9, n_estimators=7;, score=-22.419 total time=   0.2s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=9, n_estimators=7;, score=-22.601 total time=   0.4s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=9, n_estimators=7;, score=-23.099 total time=   0.6s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=9, n_estimators=7;, score=-30.570 total time=   0.7s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=9, n_estimators=9;, score=-21.363 total time=   0.1s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=9, n_estimators=9;, score=-22.182 total time=   0.3s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=9, n_estimators=9;, score=-22.378 total time=   0.5s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=9, n_estimators=9;, score=-22.681 total time=   0.8s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=9, n_estimators=9;, score=-30.643 total time=   1.0s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, n_estimators=1;, score=-29.140 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, n_estimators=1;, score=-32.713 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, n_estimators=1;, score=-36.409 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, n_estimators=1;, score=-34.291 total time=   0.0s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, n_estimators=1;, score=-39.279 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, n_estimators=3;, score=-23.597 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, n_estimators=3;, score=-25.770 total time=   0.1s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, n_estimators=3;, score=-26.778 total time=   0.2s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, n_estimators=3;, score=-26.879 total time=   0.3s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, n_estimators=3;, score=-33.485 total time=   0.4s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, n_estimators=5;, score=-22.001 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, n_estimators=5;, score=-23.781 total time=   0.2s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, n_estimators=5;, score=-25.276 total time=   0.4s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, n_estimators=5;, score=-24.634 total time=   0.6s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, n_estimators=5;, score=-32.226 total time=   0.8s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, n_estimators=7;, score=-21.482 total time=   0.1s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, n_estimators=7;, score=-23.099 total time=   0.3s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, n_estimators=7;, score=-24.364 total time=   0.5s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, n_estimators=7;, score=-23.587 total time=   0.8s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, n_estimators=7;, score=-31.780 total time=   1.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, n_estimators=9;, score=-21.275 total time=   0.1s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, n_estimators=9;, score=-22.887 total time=   0.4s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, n_estimators=9;, score=-23.729 total time=   0.7s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, n_estimators=9;, score=-22.986 total time=   1.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, n_estimators=9;, score=-31.435 total time=   1.4s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, n_estimators=1;, score=-28.484 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, n_estimators=1;, score=-30.047 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, n_estimators=1;, score=-32.450 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, n_estimators=1;, score=-32.664 total time=   0.0s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, n_estimators=1;, score=-36.880 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, n_estimators=3;, score=-23.328 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, n_estimators=3;, score=-24.133 total time=   0.1s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, n_estimators=3;, score=-25.579 total time=   0.2s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, n_estimators=3;, score=-26.058 total time=   0.3s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, n_estimators=3;, score=-32.256 total time=   0.3s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, n_estimators=5;, score=-22.077 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, n_estimators=5;, score=-22.714 total time=   0.2s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, n_estimators=5;, score=-24.528 total time=   0.3s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, n_estimators=5;, score=-24.339 total time=   0.5s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, n_estimators=5;, score=-31.584 total time=   0.7s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, n_estimators=7;, score=-21.611 total time=   0.1s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, n_estimators=7;, score=-22.343 total time=   0.3s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, n_estimators=7;, score=-23.855 total time=   0.5s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, n_estimators=7;, score=-23.909 total time=   0.7s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, n_estimators=7;, score=-31.297 total time=   0.9s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, n_estimators=9;, score=-21.267 total time=   0.1s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, n_estimators=9;, score=-22.293 total time=   0.4s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, n_estimators=9;, score=-23.460 total time=   0.6s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, n_estimators=9;, score=-23.339 total time=   1.0s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, n_estimators=9;, score=-30.646 total time=   1.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, n_estimators=1;, score=-27.411 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, n_estimators=1;, score=-28.136 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, n_estimators=1;, score=-31.279 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, n_estimators=1;, score=-28.504 total time=   0.0s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, n_estimators=1;, score=-35.660 total time=   0.0s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, n_estimators=3;, score=-22.844 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, n_estimators=3;, score=-23.691 total time=   0.1s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, n_estimators=3;, score=-24.962 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, n_estimators=3;, score=-25.177 total time=   0.2s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, n_estimators=3;, score=-32.059 total time=   0.3s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, n_estimators=5;, score=-21.432 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, n_estimators=5;, score=-22.600 total time=   0.1s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, n_estimators=5;, score=-23.658 total time=   0.3s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, n_estimators=5;, score=-24.214 total time=   0.4s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, n_estimators=5;, score=-30.891 total time=   0.6s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, n_estimators=7;, score=-21.283 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, n_estimators=7;, score=-22.142 total time=   0.2s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, n_estimators=7;, score=-23.137 total time=   0.4s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, n_estimators=7;, score=-23.679 total time=   0.7s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, n_estimators=7;, score=-30.470 total time=   0.9s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, n_estimators=9;, score=-21.022 total time=   0.1s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, n_estimators=9;, score=-21.960 total time=   0.3s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, n_estimators=9;, score=-22.755 total time=   0.6s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, n_estimators=9;, score=-23.099 total time=   0.9s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, n_estimators=9;, score=-30.517 total time=   1.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, n_estimators=1;, score=-26.502 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, n_estimators=1;, score=-27.221 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, n_estimators=1;, score=-29.237 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, n_estimators=1;, score=-28.896 total time=   0.0s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, n_estimators=1;, score=-36.618 total time=   0.0s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, n_estimators=3;, score=-22.531 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, n_estimators=3;, score=-23.489 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, n_estimators=3;, score=-24.801 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, n_estimators=3;, score=-24.327 total time=   0.2s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, n_estimators=3;, score=-32.323 total time=   0.3s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, n_estimators=5;, score=-21.563 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, n_estimators=5;, score=-22.472 total time=   0.1s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, n_estimators=5;, score=-23.546 total time=   0.2s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, n_estimators=5;, score=-23.550 total time=   0.4s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, n_estimators=5;, score=-31.180 total time=   0.5s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, n_estimators=7;, score=-21.455 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, n_estimators=7;, score=-22.107 total time=   0.2s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, n_estimators=7;, score=-22.966 total time=   0.4s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, n_estimators=7;, score=-23.186 total time=   0.6s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, n_estimators=7;, score=-30.761 total time=   0.8s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, n_estimators=9;, score=-21.179 total time=   0.1s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, n_estimators=9;, score=-21.872 total time=   0.3s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, n_estimators=9;, score=-22.573 total time=   0.5s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, n_estimators=9;, score=-22.759 total time=   0.8s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, n_estimators=9;, score=-30.443 total time=   1.0s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=9, n_estimators=1;, score=-26.190 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=9, n_estimators=1;, score=-27.907 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=9, n_estimators=1;, score=-28.765 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=9, n_estimators=1;, score=-28.368 total time=   0.0s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=9, n_estimators=1;, score=-35.344 total time=   0.0s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=9, n_estimators=3;, score=-22.698 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=9, n_estimators=3;, score=-23.552 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=9, n_estimators=3;, score=-24.012 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=9, n_estimators=3;, score=-23.997 total time=   0.2s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=9, n_estimators=3;, score=-31.774 total time=   0.3s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=9, n_estimators=5;, score=-21.771 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=9, n_estimators=5;, score=-22.755 total time=   0.1s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=9, n_estimators=5;, score=-23.173 total time=   0.2s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=9, n_estimators=5;, score=-23.485 total time=   0.4s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=9, n_estimators=5;, score=-30.999 total time=   0.5s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=9, n_estimators=7;, score=-21.582 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=9, n_estimators=7;, score=-22.419 total time=   0.2s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=9, n_estimators=7;, score=-22.601 total time=   0.4s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=9, n_estimators=7;, score=-23.099 total time=   0.6s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=9, n_estimators=7;, score=-30.570 total time=   0.7s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=9, n_estimators=9;, score=-21.363 total time=   0.1s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=9, n_estimators=9;, score=-22.182 total time=   0.3s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=9, n_estimators=9;, score=-22.378 total time=   0.5s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=9, n_estimators=9;, score=-22.681 total time=   0.8s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=9, n_estimators=9;, score=-30.643 total time=   1.0s\n",
      "{'max_depth': 7, 'min_samples_leaf': 7, 'n_estimators': 9}\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parametrs = {\n",
    "    'n_estimators': range (1,10, 2),\n",
    "    'max_depth': range (1,20, 2),\n",
    "    'min_samples_leaf': range (1,10,2)                     \n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "grid = GridSearchCV(model_rf,\n",
    "                     parametrs, cv=tscv, scoring = 'neg_root_mean_squared_error', verbose=3)\n",
    "grid.fit(features_train, target_train)\n",
    "#выводим результат\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e82ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf = grid.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f4c4deb",
   "metadata": {},
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15418f34",
   "metadata": {},
   "source": [
    "***Обучение модели Дерево решений***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e9f1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#модель\n",
    "model_dtr = DecisionTreeRegressor(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "994b1096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, min_samples_split=2;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, min_samples_split=2;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, min_samples_split=2;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, min_samples_split=2;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, min_samples_split=2;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, min_samples_split=4;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, min_samples_split=4;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, min_samples_split=4;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, min_samples_split=4;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, min_samples_split=4;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, min_samples_split=6;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, min_samples_split=6;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, min_samples_split=6;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, min_samples_split=6;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, min_samples_split=6;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=1, min_samples_split=8;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=1, min_samples_split=8;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=1, min_samples_split=8;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=1, min_samples_split=8;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=1, min_samples_split=8;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=2, min_samples_split=2;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=2, min_samples_split=4;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=2, min_samples_split=4;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=2, min_samples_split=4;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=2, min_samples_split=4;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=2, min_samples_split=4;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=2, min_samples_split=6;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=2, min_samples_split=6;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=2, min_samples_split=6;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=2, min_samples_split=6;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=2, min_samples_split=6;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=2, min_samples_split=8;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=2, min_samples_split=8;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=2, min_samples_split=8;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=2, min_samples_split=8;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=2, min_samples_split=8;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=2;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=4;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=6;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=6;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=6;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=6;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=6;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=3, min_samples_split=8;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=3, min_samples_split=8;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=3, min_samples_split=8;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=3, min_samples_split=8;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=3, min_samples_split=8;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=2;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=4;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=6;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=6;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=6;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=6;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=6;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=4, min_samples_split=8;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=4, min_samples_split=8;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=4, min_samples_split=8;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=4, min_samples_split=8;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=4, min_samples_split=8;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, min_samples_split=2;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, min_samples_split=2;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, min_samples_split=2;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, min_samples_split=2;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, min_samples_split=2;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, min_samples_split=4;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, min_samples_split=4;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, min_samples_split=4;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, min_samples_split=4;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, min_samples_split=4;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, min_samples_split=6;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, min_samples_split=6;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, min_samples_split=6;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, min_samples_split=6;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, min_samples_split=6;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=5, min_samples_split=8;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=5, min_samples_split=8;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=5, min_samples_split=8;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=5, min_samples_split=8;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=5, min_samples_split=8;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=6, min_samples_split=2;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=6, min_samples_split=2;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=6, min_samples_split=2;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=6, min_samples_split=2;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=6, min_samples_split=2;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=6, min_samples_split=4;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=6, min_samples_split=4;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=6, min_samples_split=4;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=6, min_samples_split=4;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=6, min_samples_split=4;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=6, min_samples_split=6;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=6, min_samples_split=6;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=6, min_samples_split=6;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=6, min_samples_split=6;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=6, min_samples_split=6;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=6, min_samples_split=8;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=6, min_samples_split=8;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=6, min_samples_split=8;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=6, min_samples_split=8;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=6, min_samples_split=8;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, min_samples_split=2;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, min_samples_split=2;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, min_samples_split=2;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, min_samples_split=2;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, min_samples_split=2;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, min_samples_split=4;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, min_samples_split=4;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, min_samples_split=4;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, min_samples_split=4;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, min_samples_split=4;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, min_samples_split=6;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, min_samples_split=6;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, min_samples_split=6;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, min_samples_split=6;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, min_samples_split=6;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=1, min_samples_leaf=7, min_samples_split=8;, score=-26.994 total time=   0.0s\n",
      "[CV 2/5] END max_depth=1, min_samples_leaf=7, min_samples_split=8;, score=-30.733 total time=   0.0s\n",
      "[CV 3/5] END max_depth=1, min_samples_leaf=7, min_samples_split=8;, score=-28.123 total time=   0.0s\n",
      "[CV 4/5] END max_depth=1, min_samples_leaf=7, min_samples_split=8;, score=-32.682 total time=   0.0s\n",
      "[CV 5/5] END max_depth=1, min_samples_leaf=7, min_samples_split=8;, score=-44.953 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, min_samples_split=2;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, min_samples_split=4;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, min_samples_split=4;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, min_samples_split=4;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, min_samples_split=4;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, min_samples_split=4;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, min_samples_split=6;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, min_samples_split=6;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, min_samples_split=6;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, min_samples_split=6;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, min_samples_split=6;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=1, min_samples_split=8;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=1, min_samples_split=8;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=1, min_samples_split=8;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=1, min_samples_split=8;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=1, min_samples_split=8;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=2, min_samples_split=2;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=2, min_samples_split=2;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=2, min_samples_split=2;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=2, min_samples_split=2;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=2, min_samples_split=2;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=2, min_samples_split=4;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=2, min_samples_split=6;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=2, min_samples_split=6;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=2, min_samples_split=6;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=2, min_samples_split=6;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=2, min_samples_split=6;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=2, min_samples_split=8;, score=-23.526 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=2, min_samples_split=8;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=2, min_samples_split=8;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=2, min_samples_split=8;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=2, min_samples_split=8;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, min_samples_split=2;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, min_samples_split=4;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, min_samples_split=4;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, min_samples_split=4;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, min_samples_split=4;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, min_samples_split=4;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, min_samples_split=6;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, min_samples_split=6;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, min_samples_split=6;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, min_samples_split=6;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, min_samples_split=6;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=3, min_samples_split=8;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=3, min_samples_split=8;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=3, min_samples_split=8;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=3, min_samples_split=8;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=3, min_samples_split=8;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=2;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=4;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=4;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=4;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=4;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=4;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=6;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=6;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=6;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=6;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=6;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=4, min_samples_split=8;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=4, min_samples_split=8;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=4, min_samples_split=8;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=4, min_samples_split=8;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=4, min_samples_split=8;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, min_samples_split=2;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, min_samples_split=4;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, min_samples_split=4;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, min_samples_split=4;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, min_samples_split=4;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, min_samples_split=4;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, min_samples_split=6;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, min_samples_split=6;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, min_samples_split=6;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, min_samples_split=6;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, min_samples_split=6;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=5, min_samples_split=8;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=5, min_samples_split=8;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=5, min_samples_split=8;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=5, min_samples_split=8;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=5, min_samples_split=8;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=6, min_samples_split=2;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=6, min_samples_split=2;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=6, min_samples_split=2;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=6, min_samples_split=2;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=6, min_samples_split=2;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=6, min_samples_split=4;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=6, min_samples_split=4;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=6, min_samples_split=4;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=6, min_samples_split=4;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=6, min_samples_split=4;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=6, min_samples_split=6;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=6, min_samples_split=6;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=6, min_samples_split=6;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=6, min_samples_split=6;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=6, min_samples_split=6;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=6, min_samples_split=8;, score=-23.521 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=6, min_samples_split=8;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=6, min_samples_split=8;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=6, min_samples_split=8;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=6, min_samples_split=8;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, min_samples_split=2;, score=-23.506 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, min_samples_split=2;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, min_samples_split=2;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, min_samples_split=2;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, min_samples_split=2;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, min_samples_split=4;, score=-23.506 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, min_samples_split=4;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, min_samples_split=4;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, min_samples_split=4;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, min_samples_split=4;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, min_samples_split=6;, score=-23.506 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, min_samples_split=6;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, min_samples_split=6;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, min_samples_split=6;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, min_samples_split=6;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=3, min_samples_leaf=7, min_samples_split=8;, score=-23.506 total time=   0.0s\n",
      "[CV 2/5] END max_depth=3, min_samples_leaf=7, min_samples_split=8;, score=-25.913 total time=   0.0s\n",
      "[CV 3/5] END max_depth=3, min_samples_leaf=7, min_samples_split=8;, score=-24.809 total time=   0.0s\n",
      "[CV 4/5] END max_depth=3, min_samples_leaf=7, min_samples_split=8;, score=-24.857 total time=   0.0s\n",
      "[CV 5/5] END max_depth=3, min_samples_leaf=7, min_samples_split=8;, score=-36.269 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-25.313 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-26.517 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-28.188 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=2;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=4;, score=-25.280 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=4;, score=-26.517 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=4;, score=-28.188 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=4;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=4;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=6;, score=-25.311 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=6;, score=-26.323 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=6;, score=-28.188 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=6;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=6;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=1, min_samples_split=8;, score=-25.251 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=1, min_samples_split=8;, score=-26.298 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=1, min_samples_split=8;, score=-28.188 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=1, min_samples_split=8;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=1, min_samples_split=8;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=-25.258 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=-26.514 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=-24.660 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=2;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=4;, score=-25.258 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=4;, score=-26.514 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=4;, score=-24.660 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=4;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=4;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=6;, score=-25.289 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=6;, score=-26.323 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=6;, score=-24.660 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=6;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=6;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=2, min_samples_split=8;, score=-25.279 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=2, min_samples_split=8;, score=-26.298 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=2, min_samples_split=8;, score=-24.660 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=2, min_samples_split=8;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=2, min_samples_split=8;, score=-33.583 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, min_samples_split=2;, score=-25.191 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, min_samples_split=2;, score=-26.189 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, min_samples_split=2;, score=-24.676 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, min_samples_split=2;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, min_samples_split=2;, score=-33.386 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, min_samples_split=4;, score=-25.191 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, min_samples_split=4;, score=-26.189 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, min_samples_split=4;, score=-24.676 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, min_samples_split=4;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, min_samples_split=4;, score=-33.386 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, min_samples_split=6;, score=-25.191 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, min_samples_split=6;, score=-26.189 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, min_samples_split=6;, score=-24.676 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, min_samples_split=6;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, min_samples_split=6;, score=-33.386 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=3, min_samples_split=8;, score=-25.112 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=3, min_samples_split=8;, score=-26.186 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=3, min_samples_split=8;, score=-24.676 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=3, min_samples_split=8;, score=-24.948 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=3, min_samples_split=8;, score=-33.386 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=-25.036 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=-25.942 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=-24.671 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=-24.916 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=2;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=4;, score=-25.036 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=4;, score=-25.942 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=4;, score=-24.671 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=4;, score=-24.916 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=4;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=6;, score=-25.036 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=6;, score=-25.942 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=6;, score=-24.671 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=6;, score=-24.916 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=6;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=4, min_samples_split=8;, score=-25.036 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=4, min_samples_split=8;, score=-25.942 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=4, min_samples_split=8;, score=-24.671 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=4, min_samples_split=8;, score=-24.916 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=4, min_samples_split=8;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-24.982 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-26.105 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-24.440 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-24.689 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, min_samples_split=2;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, min_samples_split=4;, score=-24.982 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, min_samples_split=4;, score=-26.105 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, min_samples_split=4;, score=-24.440 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, min_samples_split=4;, score=-24.689 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, min_samples_split=4;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, min_samples_split=6;, score=-24.982 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, min_samples_split=6;, score=-26.105 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, min_samples_split=6;, score=-24.440 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, min_samples_split=6;, score=-24.689 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, min_samples_split=6;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=5, min_samples_split=8;, score=-24.982 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=5, min_samples_split=8;, score=-26.105 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=5, min_samples_split=8;, score=-24.440 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=5, min_samples_split=8;, score=-24.689 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=5, min_samples_split=8;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=6, min_samples_split=2;, score=-25.037 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=6, min_samples_split=2;, score=-25.543 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=6, min_samples_split=2;, score=-24.673 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=6, min_samples_split=2;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=6, min_samples_split=2;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=6, min_samples_split=4;, score=-25.037 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=6, min_samples_split=4;, score=-25.543 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=6, min_samples_split=4;, score=-24.673 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=6, min_samples_split=4;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=6, min_samples_split=4;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=6, min_samples_split=6;, score=-25.037 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=6, min_samples_split=6;, score=-25.543 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=6, min_samples_split=6;, score=-24.673 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=6, min_samples_split=6;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=6, min_samples_split=6;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=6, min_samples_split=8;, score=-25.037 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=6, min_samples_split=8;, score=-25.543 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=6, min_samples_split=8;, score=-24.673 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=6, min_samples_split=8;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=6, min_samples_split=8;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, min_samples_split=2;, score=-24.573 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, min_samples_split=2;, score=-25.842 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, min_samples_split=2;, score=-24.518 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, min_samples_split=2;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, min_samples_split=2;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, min_samples_split=4;, score=-24.573 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, min_samples_split=4;, score=-25.842 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, min_samples_split=4;, score=-24.518 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, min_samples_split=4;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, min_samples_split=4;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, min_samples_split=6;, score=-24.573 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, min_samples_split=6;, score=-25.842 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, min_samples_split=6;, score=-24.518 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, min_samples_split=6;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, min_samples_split=6;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_leaf=7, min_samples_split=8;, score=-24.573 total time=   0.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_leaf=7, min_samples_split=8;, score=-25.842 total time=   0.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_leaf=7, min_samples_split=8;, score=-24.518 total time=   0.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_leaf=7, min_samples_split=8;, score=-24.694 total time=   0.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_leaf=7, min_samples_split=8;, score=-33.340 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-26.827 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-28.968 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-31.746 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-29.294 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, min_samples_split=2;, score=-34.636 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, min_samples_split=4;, score=-26.615 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, min_samples_split=4;, score=-26.786 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, min_samples_split=4;, score=-32.015 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, min_samples_split=4;, score=-28.737 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, min_samples_split=4;, score=-34.620 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, min_samples_split=6;, score=-27.154 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, min_samples_split=6;, score=-26.966 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, min_samples_split=6;, score=-31.780 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, min_samples_split=6;, score=-28.768 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, min_samples_split=6;, score=-34.737 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=1, min_samples_split=8;, score=-26.116 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=1, min_samples_split=8;, score=-26.887 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=1, min_samples_split=8;, score=-31.849 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=1, min_samples_split=8;, score=-29.481 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=1, min_samples_split=8;, score=-34.617 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=2, min_samples_split=2;, score=-26.501 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=2, min_samples_split=2;, score=-26.891 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=2, min_samples_split=2;, score=-29.063 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=2, min_samples_split=2;, score=-28.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=2, min_samples_split=2;, score=-34.644 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=2, min_samples_split=4;, score=-26.501 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=2, min_samples_split=4;, score=-26.891 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=2, min_samples_split=4;, score=-29.063 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=2, min_samples_split=4;, score=-28.740 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=2, min_samples_split=4;, score=-34.644 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=2, min_samples_split=6;, score=-27.034 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=2, min_samples_split=6;, score=-26.835 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=2, min_samples_split=6;, score=-28.829 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=2, min_samples_split=6;, score=-28.797 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=2, min_samples_split=6;, score=-34.755 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=2, min_samples_split=8;, score=-26.293 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=2, min_samples_split=8;, score=-26.770 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=2, min_samples_split=8;, score=-28.716 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=2, min_samples_split=8;, score=-29.425 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=2, min_samples_split=8;, score=-34.634 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, min_samples_split=2;, score=-26.000 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, min_samples_split=2;, score=-26.342 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, min_samples_split=2;, score=-27.818 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, min_samples_split=2;, score=-29.262 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, min_samples_split=2;, score=-35.445 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, min_samples_split=4;, score=-26.000 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, min_samples_split=4;, score=-26.342 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, min_samples_split=4;, score=-27.818 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, min_samples_split=4;, score=-29.262 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, min_samples_split=4;, score=-35.445 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, min_samples_split=6;, score=-26.000 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, min_samples_split=6;, score=-26.342 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, min_samples_split=6;, score=-27.818 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, min_samples_split=6;, score=-29.262 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, min_samples_split=6;, score=-35.445 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=3, min_samples_split=8;, score=-26.403 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=3, min_samples_split=8;, score=-26.307 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=3, min_samples_split=8;, score=-27.757 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=3, min_samples_split=8;, score=-28.627 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=3, min_samples_split=8;, score=-35.264 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=4, min_samples_split=2;, score=-26.373 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=4, min_samples_split=2;, score=-26.073 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=4, min_samples_split=2;, score=-27.442 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=4, min_samples_split=2;, score=-28.380 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=4, min_samples_split=2;, score=-34.541 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=4, min_samples_split=4;, score=-26.373 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=4, min_samples_split=4;, score=-26.073 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=4, min_samples_split=4;, score=-27.442 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=4, min_samples_split=4;, score=-28.380 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=4, min_samples_split=4;, score=-34.541 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=4, min_samples_split=6;, score=-26.373 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=4, min_samples_split=6;, score=-26.073 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=4, min_samples_split=6;, score=-27.442 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=4, min_samples_split=6;, score=-28.380 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=4, min_samples_split=6;, score=-34.541 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=4, min_samples_split=8;, score=-26.373 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=4, min_samples_split=8;, score=-26.073 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=4, min_samples_split=8;, score=-27.442 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=4, min_samples_split=8;, score=-28.380 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=4, min_samples_split=8;, score=-34.541 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-26.393 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-25.624 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-27.179 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-27.163 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, min_samples_split=2;, score=-34.405 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, min_samples_split=4;, score=-26.393 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, min_samples_split=4;, score=-25.624 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, min_samples_split=4;, score=-27.179 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, min_samples_split=4;, score=-27.163 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, min_samples_split=4;, score=-34.405 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, min_samples_split=6;, score=-26.393 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, min_samples_split=6;, score=-25.624 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, min_samples_split=6;, score=-27.179 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, min_samples_split=6;, score=-27.163 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, min_samples_split=6;, score=-34.405 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=5, min_samples_split=8;, score=-26.393 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=5, min_samples_split=8;, score=-25.624 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=5, min_samples_split=8;, score=-27.179 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=5, min_samples_split=8;, score=-27.163 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=5, min_samples_split=8;, score=-34.405 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=6, min_samples_split=2;, score=-26.134 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=6, min_samples_split=2;, score=-25.525 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=6, min_samples_split=2;, score=-26.366 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=6, min_samples_split=2;, score=-27.171 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=6, min_samples_split=2;, score=-33.964 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=6, min_samples_split=4;, score=-26.134 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=6, min_samples_split=4;, score=-25.525 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=6, min_samples_split=4;, score=-26.366 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=6, min_samples_split=4;, score=-27.171 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=6, min_samples_split=4;, score=-33.964 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=6, min_samples_split=6;, score=-26.134 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=6, min_samples_split=6;, score=-25.525 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=6, min_samples_split=6;, score=-26.366 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=6, min_samples_split=6;, score=-27.171 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=6, min_samples_split=6;, score=-33.964 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=6, min_samples_split=8;, score=-26.134 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=6, min_samples_split=8;, score=-25.525 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=6, min_samples_split=8;, score=-26.366 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=6, min_samples_split=8;, score=-27.171 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=6, min_samples_split=8;, score=-33.964 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, min_samples_split=2;, score=-25.725 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, min_samples_split=2;, score=-26.260 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, min_samples_split=2;, score=-25.969 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, min_samples_split=2;, score=-26.918 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, min_samples_split=2;, score=-33.489 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, min_samples_split=4;, score=-25.725 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, min_samples_split=4;, score=-26.260 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, min_samples_split=4;, score=-25.969 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, min_samples_split=4;, score=-26.918 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, min_samples_split=4;, score=-33.489 total time=   0.0s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, min_samples_split=6;, score=-25.725 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, min_samples_split=6;, score=-26.260 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, min_samples_split=6;, score=-25.969 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, min_samples_split=6;, score=-26.918 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, min_samples_split=6;, score=-33.489 total time=   0.1s\n",
      "[CV 1/5] END max_depth=7, min_samples_leaf=7, min_samples_split=8;, score=-25.725 total time=   0.0s\n",
      "[CV 2/5] END max_depth=7, min_samples_leaf=7, min_samples_split=8;, score=-26.260 total time=   0.0s\n",
      "[CV 3/5] END max_depth=7, min_samples_leaf=7, min_samples_split=8;, score=-25.969 total time=   0.0s\n",
      "[CV 4/5] END max_depth=7, min_samples_leaf=7, min_samples_split=8;, score=-26.918 total time=   0.0s\n",
      "[CV 5/5] END max_depth=7, min_samples_leaf=7, min_samples_split=8;, score=-33.489 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, min_samples_split=2;, score=-28.474 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, min_samples_split=2;, score=-28.647 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, min_samples_split=2;, score=-33.951 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, min_samples_split=2;, score=-31.863 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, min_samples_split=2;, score=-37.649 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, min_samples_split=4;, score=-28.099 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, min_samples_split=4;, score=-28.626 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, min_samples_split=4;, score=-33.300 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, min_samples_split=4;, score=-32.301 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, min_samples_split=4;, score=-37.815 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, min_samples_split=6;, score=-27.840 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, min_samples_split=6;, score=-28.560 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, min_samples_split=6;, score=-32.812 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, min_samples_split=6;, score=-32.462 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, min_samples_split=6;, score=-37.802 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=1, min_samples_split=8;, score=-27.550 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=1, min_samples_split=8;, score=-28.126 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=1, min_samples_split=8;, score=-32.407 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=1, min_samples_split=8;, score=-32.391 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=1, min_samples_split=8;, score=-37.381 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=2, min_samples_split=2;, score=-27.459 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=2, min_samples_split=2;, score=-28.553 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=2, min_samples_split=2;, score=-30.608 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=2, min_samples_split=2;, score=-31.398 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=2, min_samples_split=2;, score=-37.292 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=2, min_samples_split=4;, score=-27.459 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=2, min_samples_split=4;, score=-28.553 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=2, min_samples_split=4;, score=-30.608 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=2, min_samples_split=4;, score=-31.398 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=2, min_samples_split=4;, score=-37.292 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=2, min_samples_split=6;, score=-27.453 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=2, min_samples_split=6;, score=-28.451 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=2, min_samples_split=6;, score=-30.380 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=2, min_samples_split=6;, score=-31.939 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=2, min_samples_split=6;, score=-37.586 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=2, min_samples_split=8;, score=-27.083 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=2, min_samples_split=8;, score=-28.005 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=2, min_samples_split=8;, score=-29.566 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=2, min_samples_split=8;, score=-32.452 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=2, min_samples_split=8;, score=-37.481 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, min_samples_split=2;, score=-27.141 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, min_samples_split=2;, score=-27.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, min_samples_split=2;, score=-28.717 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, min_samples_split=2;, score=-31.806 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, min_samples_split=2;, score=-37.729 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, min_samples_split=4;, score=-27.141 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, min_samples_split=4;, score=-27.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, min_samples_split=4;, score=-28.717 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, min_samples_split=4;, score=-31.806 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, min_samples_split=4;, score=-37.729 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, min_samples_split=6;, score=-27.141 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, min_samples_split=6;, score=-27.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, min_samples_split=6;, score=-28.717 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, min_samples_split=6;, score=-31.806 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, min_samples_split=6;, score=-37.729 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=3, min_samples_split=8;, score=-27.124 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=3, min_samples_split=8;, score=-27.783 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=3, min_samples_split=8;, score=-28.975 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=3, min_samples_split=8;, score=-32.195 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=3, min_samples_split=8;, score=-37.252 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=4, min_samples_split=2;, score=-27.488 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=4, min_samples_split=2;, score=-27.170 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=4, min_samples_split=2;, score=-28.573 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=4, min_samples_split=2;, score=-31.101 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=4, min_samples_split=2;, score=-36.719 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=4, min_samples_split=4;, score=-27.488 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=4, min_samples_split=4;, score=-27.170 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=4, min_samples_split=4;, score=-28.573 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=4, min_samples_split=4;, score=-31.101 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=4, min_samples_split=4;, score=-36.719 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=4, min_samples_split=6;, score=-27.488 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=4, min_samples_split=6;, score=-27.170 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=4, min_samples_split=6;, score=-28.573 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=4, min_samples_split=6;, score=-31.101 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=4, min_samples_split=6;, score=-36.719 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=4, min_samples_split=8;, score=-27.488 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=4, min_samples_split=8;, score=-27.170 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=4, min_samples_split=8;, score=-28.573 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=4, min_samples_split=8;, score=-31.101 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=4, min_samples_split=8;, score=-36.719 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, min_samples_split=2;, score=-27.327 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, min_samples_split=2;, score=-27.040 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, min_samples_split=2;, score=-28.060 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, min_samples_split=2;, score=-29.598 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, min_samples_split=2;, score=-36.484 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, min_samples_split=4;, score=-27.327 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, min_samples_split=4;, score=-27.040 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, min_samples_split=4;, score=-28.060 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, min_samples_split=4;, score=-29.598 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, min_samples_split=4;, score=-36.484 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, min_samples_split=6;, score=-27.327 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, min_samples_split=6;, score=-27.040 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, min_samples_split=6;, score=-28.060 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, min_samples_split=6;, score=-29.598 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, min_samples_split=6;, score=-36.484 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=5, min_samples_split=8;, score=-27.327 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=5, min_samples_split=8;, score=-27.040 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=5, min_samples_split=8;, score=-28.060 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=5, min_samples_split=8;, score=-29.598 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=5, min_samples_split=8;, score=-36.484 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=6, min_samples_split=2;, score=-27.397 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=6, min_samples_split=2;, score=-26.388 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=6, min_samples_split=2;, score=-26.721 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=6, min_samples_split=2;, score=-29.395 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=6, min_samples_split=2;, score=-35.676 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=6, min_samples_split=4;, score=-27.397 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=6, min_samples_split=4;, score=-26.388 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=6, min_samples_split=4;, score=-26.721 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=6, min_samples_split=4;, score=-29.395 total time=   0.1s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=6, min_samples_split=4;, score=-35.676 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=6, min_samples_split=6;, score=-27.397 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=6, min_samples_split=6;, score=-26.388 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=6, min_samples_split=6;, score=-26.721 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=6, min_samples_split=6;, score=-29.395 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=6, min_samples_split=6;, score=-35.676 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=6, min_samples_split=8;, score=-27.397 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=6, min_samples_split=8;, score=-26.388 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=6, min_samples_split=8;, score=-26.721 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=6, min_samples_split=8;, score=-29.395 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=6, min_samples_split=8;, score=-35.676 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, min_samples_split=2;, score=-26.942 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, min_samples_split=2;, score=-27.269 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, min_samples_split=2;, score=-27.108 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, min_samples_split=2;, score=-28.567 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, min_samples_split=2;, score=-34.167 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, min_samples_split=4;, score=-26.942 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, min_samples_split=4;, score=-27.269 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, min_samples_split=4;, score=-27.108 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, min_samples_split=4;, score=-28.567 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, min_samples_split=4;, score=-34.167 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, min_samples_split=6;, score=-26.942 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, min_samples_split=6;, score=-27.269 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, min_samples_split=6;, score=-27.108 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, min_samples_split=6;, score=-28.567 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, min_samples_split=6;, score=-34.167 total time=   0.1s\n",
      "[CV 1/5] END max_depth=9, min_samples_leaf=7, min_samples_split=8;, score=-26.942 total time=   0.0s\n",
      "[CV 2/5] END max_depth=9, min_samples_leaf=7, min_samples_split=8;, score=-27.269 total time=   0.0s\n",
      "[CV 3/5] END max_depth=9, min_samples_leaf=7, min_samples_split=8;, score=-27.108 total time=   0.0s\n",
      "[CV 4/5] END max_depth=9, min_samples_leaf=7, min_samples_split=8;, score=-28.567 total time=   0.0s\n",
      "[CV 5/5] END max_depth=9, min_samples_leaf=7, min_samples_split=8;, score=-34.167 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, min_samples_split=2;, score=-28.489 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, min_samples_split=2;, score=-30.296 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, min_samples_split=2;, score=-35.052 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, min_samples_split=2;, score=-34.745 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, min_samples_split=2;, score=-39.328 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, min_samples_split=4;, score=-28.482 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, min_samples_split=4;, score=-30.103 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, min_samples_split=4;, score=-34.501 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, min_samples_split=4;, score=-34.888 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, min_samples_split=4;, score=-38.909 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, min_samples_split=6;, score=-28.081 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, min_samples_split=6;, score=-29.524 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, min_samples_split=6;, score=-34.529 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, min_samples_split=6;, score=-32.785 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, min_samples_split=6;, score=-38.347 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=1, min_samples_split=8;, score=-27.727 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=1, min_samples_split=8;, score=-29.432 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=1, min_samples_split=8;, score=-33.794 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=1, min_samples_split=8;, score=-33.076 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=1, min_samples_split=8;, score=-38.081 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=2, min_samples_split=2;, score=-27.781 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=2, min_samples_split=2;, score=-29.684 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=2, min_samples_split=2;, score=-31.638 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=2, min_samples_split=2;, score=-33.733 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=2, min_samples_split=2;, score=-37.679 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=2, min_samples_split=4;, score=-27.781 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=2, min_samples_split=4;, score=-29.684 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=2, min_samples_split=4;, score=-31.638 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=2, min_samples_split=4;, score=-33.733 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=2, min_samples_split=4;, score=-37.679 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=2, min_samples_split=6;, score=-28.545 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=2, min_samples_split=6;, score=-28.939 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=2, min_samples_split=6;, score=-31.752 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=2, min_samples_split=6;, score=-33.587 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=2, min_samples_split=6;, score=-38.694 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=2, min_samples_split=8;, score=-27.576 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=2, min_samples_split=8;, score=-29.530 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=2, min_samples_split=8;, score=-31.052 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=2, min_samples_split=8;, score=-33.667 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=2, min_samples_split=8;, score=-38.172 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, min_samples_split=2;, score=-27.882 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, min_samples_split=2;, score=-29.295 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, min_samples_split=2;, score=-30.324 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, min_samples_split=2;, score=-32.733 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, min_samples_split=2;, score=-38.023 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, min_samples_split=4;, score=-27.882 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, min_samples_split=4;, score=-29.295 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, min_samples_split=4;, score=-30.324 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, min_samples_split=4;, score=-32.733 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, min_samples_split=4;, score=-38.023 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, min_samples_split=6;, score=-27.882 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, min_samples_split=6;, score=-29.295 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, min_samples_split=6;, score=-30.324 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, min_samples_split=6;, score=-32.733 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, min_samples_split=6;, score=-38.023 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=3, min_samples_split=8;, score=-27.992 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=3, min_samples_split=8;, score=-28.954 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=3, min_samples_split=8;, score=-30.303 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=3, min_samples_split=8;, score=-32.946 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=3, min_samples_split=8;, score=-38.041 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=4, min_samples_split=2;, score=-27.762 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=4, min_samples_split=2;, score=-28.510 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=4, min_samples_split=2;, score=-29.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=4, min_samples_split=2;, score=-32.736 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=4, min_samples_split=2;, score=-37.215 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=4, min_samples_split=4;, score=-27.762 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=4, min_samples_split=4;, score=-28.510 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=4, min_samples_split=4;, score=-29.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=4, min_samples_split=4;, score=-32.736 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=4, min_samples_split=4;, score=-37.215 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=4, min_samples_split=6;, score=-27.762 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=4, min_samples_split=6;, score=-28.510 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=4, min_samples_split=6;, score=-29.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=4, min_samples_split=6;, score=-32.736 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=4, min_samples_split=6;, score=-37.215 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=4, min_samples_split=8;, score=-27.762 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=4, min_samples_split=8;, score=-28.510 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=4, min_samples_split=8;, score=-29.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=4, min_samples_split=8;, score=-32.736 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=4, min_samples_split=8;, score=-37.215 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, min_samples_split=2;, score=-27.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, min_samples_split=2;, score=-28.177 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, min_samples_split=2;, score=-29.726 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, min_samples_split=2;, score=-31.564 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, min_samples_split=2;, score=-36.489 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, min_samples_split=4;, score=-27.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, min_samples_split=4;, score=-28.177 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, min_samples_split=4;, score=-29.726 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, min_samples_split=4;, score=-31.564 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, min_samples_split=4;, score=-36.489 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, min_samples_split=6;, score=-27.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, min_samples_split=6;, score=-28.177 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, min_samples_split=6;, score=-29.726 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, min_samples_split=6;, score=-31.564 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, min_samples_split=6;, score=-36.489 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=5, min_samples_split=8;, score=-27.660 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=5, min_samples_split=8;, score=-28.177 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=5, min_samples_split=8;, score=-29.726 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=5, min_samples_split=8;, score=-31.564 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=5, min_samples_split=8;, score=-36.489 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=6, min_samples_split=2;, score=-27.404 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=6, min_samples_split=2;, score=-27.298 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=6, min_samples_split=2;, score=-27.735 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=6, min_samples_split=2;, score=-31.153 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=6, min_samples_split=2;, score=-36.386 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=6, min_samples_split=4;, score=-27.404 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=6, min_samples_split=4;, score=-27.298 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=6, min_samples_split=4;, score=-27.735 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=6, min_samples_split=4;, score=-31.153 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=6, min_samples_split=4;, score=-36.386 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=6, min_samples_split=6;, score=-27.404 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=6, min_samples_split=6;, score=-27.298 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=6, min_samples_split=6;, score=-27.735 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=6, min_samples_split=6;, score=-31.153 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=6, min_samples_split=6;, score=-36.386 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=6, min_samples_split=8;, score=-27.404 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=6, min_samples_split=8;, score=-27.298 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=6, min_samples_split=8;, score=-27.735 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=6, min_samples_split=8;, score=-31.153 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=6, min_samples_split=8;, score=-36.386 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, min_samples_split=2;, score=-26.952 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, min_samples_split=2;, score=-28.047 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, min_samples_split=2;, score=-27.858 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, min_samples_split=2;, score=-30.353 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, min_samples_split=2;, score=-35.252 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, min_samples_split=4;, score=-26.952 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, min_samples_split=4;, score=-28.047 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, min_samples_split=4;, score=-27.858 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, min_samples_split=4;, score=-30.353 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, min_samples_split=4;, score=-35.252 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, min_samples_split=6;, score=-26.952 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, min_samples_split=6;, score=-28.047 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, min_samples_split=6;, score=-27.858 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, min_samples_split=6;, score=-30.353 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, min_samples_split=6;, score=-35.252 total time=   0.1s\n",
      "[CV 1/5] END max_depth=11, min_samples_leaf=7, min_samples_split=8;, score=-26.952 total time=   0.0s\n",
      "[CV 2/5] END max_depth=11, min_samples_leaf=7, min_samples_split=8;, score=-28.047 total time=   0.0s\n",
      "[CV 3/5] END max_depth=11, min_samples_leaf=7, min_samples_split=8;, score=-27.858 total time=   0.0s\n",
      "[CV 4/5] END max_depth=11, min_samples_leaf=7, min_samples_split=8;, score=-30.353 total time=   0.1s\n",
      "[CV 5/5] END max_depth=11, min_samples_leaf=7, min_samples_split=8;, score=-35.252 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, min_samples_split=2;, score=-28.608 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, min_samples_split=2;, score=-29.724 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, min_samples_split=2;, score=-34.359 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, min_samples_split=2;, score=-35.365 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, min_samples_split=2;, score=-40.578 total time=   0.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, min_samples_split=4;, score=-28.934 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, min_samples_split=4;, score=-29.494 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, min_samples_split=4;, score=-35.334 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, min_samples_split=4;, score=-35.753 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, min_samples_split=4;, score=-39.466 total time=   0.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, min_samples_split=6;, score=-28.911 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, min_samples_split=6;, score=-29.856 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, min_samples_split=6;, score=-34.520 total time=   0.1s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, min_samples_split=6;, score=-35.198 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, min_samples_split=6;, score=-39.343 total time=   0.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=1, min_samples_split=8;, score=-28.459 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=1, min_samples_split=8;, score=-28.976 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=1, min_samples_split=8;, score=-34.911 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=1, min_samples_split=8;, score=-34.935 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=1, min_samples_split=8;, score=-39.414 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=2, min_samples_split=2;, score=-28.701 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=2, min_samples_split=2;, score=-29.720 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=2, min_samples_split=2;, score=-32.042 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=2, min_samples_split=2;, score=-34.964 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=2, min_samples_split=2;, score=-38.600 total time=   0.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=2, min_samples_split=4;, score=-28.701 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=2, min_samples_split=4;, score=-29.720 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=2, min_samples_split=4;, score=-32.042 total time=   0.1s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=2, min_samples_split=4;, score=-34.964 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=2, min_samples_split=4;, score=-38.600 total time=   0.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=2, min_samples_split=6;, score=-28.457 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=2, min_samples_split=6;, score=-29.673 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=2, min_samples_split=6;, score=-31.864 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=2, min_samples_split=6;, score=-35.554 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=2, min_samples_split=6;, score=-38.800 total time=   0.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=2, min_samples_split=8;, score=-27.658 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=2, min_samples_split=8;, score=-29.955 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=2, min_samples_split=8;, score=-31.385 total time=   0.1s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=2, min_samples_split=8;, score=-34.707 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=2, min_samples_split=8;, score=-38.858 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, min_samples_split=2;, score=-28.443 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, min_samples_split=2;, score=-29.613 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, min_samples_split=2;, score=-31.613 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, min_samples_split=2;, score=-34.295 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, min_samples_split=2;, score=-38.062 total time=   0.2s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, min_samples_split=4;, score=-28.443 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, min_samples_split=4;, score=-29.613 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, min_samples_split=4;, score=-31.613 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, min_samples_split=4;, score=-34.295 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, min_samples_split=4;, score=-38.062 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, min_samples_split=6;, score=-28.443 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, min_samples_split=6;, score=-29.613 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, min_samples_split=6;, score=-31.613 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, min_samples_split=6;, score=-34.295 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, min_samples_split=6;, score=-38.062 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=3, min_samples_split=8;, score=-27.721 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=3, min_samples_split=8;, score=-29.383 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=3, min_samples_split=8;, score=-30.895 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=3, min_samples_split=8;, score=-34.084 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=3, min_samples_split=8;, score=-38.205 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=4, min_samples_split=2;, score=-27.804 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=4, min_samples_split=2;, score=-28.544 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=4, min_samples_split=2;, score=-30.100 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=4, min_samples_split=2;, score=-33.980 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=4, min_samples_split=2;, score=-37.327 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=4, min_samples_split=4;, score=-27.804 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=4, min_samples_split=4;, score=-28.544 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=4, min_samples_split=4;, score=-30.100 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=4, min_samples_split=4;, score=-33.980 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=4, min_samples_split=4;, score=-37.327 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=4, min_samples_split=6;, score=-27.804 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=4, min_samples_split=6;, score=-28.544 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=4, min_samples_split=6;, score=-30.100 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=4, min_samples_split=6;, score=-33.980 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=4, min_samples_split=6;, score=-37.327 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=4, min_samples_split=8;, score=-27.804 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=4, min_samples_split=8;, score=-28.544 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=4, min_samples_split=8;, score=-30.100 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=4, min_samples_split=8;, score=-33.980 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=4, min_samples_split=8;, score=-37.327 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, min_samples_split=2;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, min_samples_split=2;, score=-27.997 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, min_samples_split=2;, score=-30.209 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, min_samples_split=2;, score=-32.096 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, min_samples_split=2;, score=-36.661 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, min_samples_split=4;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, min_samples_split=4;, score=-27.997 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, min_samples_split=4;, score=-30.209 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, min_samples_split=4;, score=-32.096 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, min_samples_split=4;, score=-36.661 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, min_samples_split=6;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, min_samples_split=6;, score=-27.997 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, min_samples_split=6;, score=-30.209 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, min_samples_split=6;, score=-32.096 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, min_samples_split=6;, score=-36.661 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=5, min_samples_split=8;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=5, min_samples_split=8;, score=-27.997 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=5, min_samples_split=8;, score=-30.209 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=5, min_samples_split=8;, score=-32.096 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=5, min_samples_split=8;, score=-36.661 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=6, min_samples_split=2;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=6, min_samples_split=2;, score=-27.427 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=6, min_samples_split=2;, score=-27.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=6, min_samples_split=2;, score=-31.542 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=6, min_samples_split=2;, score=-36.176 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=6, min_samples_split=4;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=6, min_samples_split=4;, score=-27.427 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=6, min_samples_split=4;, score=-27.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=6, min_samples_split=4;, score=-31.542 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=6, min_samples_split=4;, score=-36.176 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=6, min_samples_split=6;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=6, min_samples_split=6;, score=-27.427 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=6, min_samples_split=6;, score=-27.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=6, min_samples_split=6;, score=-31.542 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=6, min_samples_split=6;, score=-36.176 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=6, min_samples_split=8;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=6, min_samples_split=8;, score=-27.427 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=6, min_samples_split=8;, score=-27.528 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=6, min_samples_split=8;, score=-31.542 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=6, min_samples_split=8;, score=-36.176 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, min_samples_split=2;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, min_samples_split=2;, score=-28.181 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, min_samples_split=2;, score=-27.754 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, min_samples_split=2;, score=-30.343 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, min_samples_split=2;, score=-35.281 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, min_samples_split=4;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, min_samples_split=4;, score=-28.181 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, min_samples_split=4;, score=-27.754 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, min_samples_split=4;, score=-30.343 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, min_samples_split=4;, score=-35.281 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, min_samples_split=6;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, min_samples_split=6;, score=-28.181 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, min_samples_split=6;, score=-27.754 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, min_samples_split=6;, score=-30.343 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, min_samples_split=6;, score=-35.281 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, min_samples_leaf=7, min_samples_split=8;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, min_samples_leaf=7, min_samples_split=8;, score=-28.181 total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, min_samples_leaf=7, min_samples_split=8;, score=-27.754 total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, min_samples_leaf=7, min_samples_split=8;, score=-30.343 total time=   0.1s\n",
      "[CV 5/5] END max_depth=13, min_samples_leaf=7, min_samples_split=8;, score=-35.281 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=-28.856 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=-31.368 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=-36.415 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=-35.735 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=2;, score=-41.086 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=4;, score=-29.147 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=4;, score=-29.587 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=4;, score=-35.182 total time=   0.1s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=4;, score=-35.835 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=4;, score=-40.634 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=6;, score=-29.089 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=6;, score=-29.406 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=6;, score=-34.979 total time=   0.1s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=6;, score=-35.480 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=6;, score=-40.028 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8;, score=-28.581 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8;, score=-30.467 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8;, score=-34.805 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8;, score=-35.781 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=1, min_samples_split=8;, score=-39.768 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=-28.907 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=-29.825 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=-31.464 total time=   0.1s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=-35.682 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=2, min_samples_split=2;, score=-40.015 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=2, min_samples_split=4;, score=-28.907 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=2, min_samples_split=4;, score=-29.825 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=2, min_samples_split=4;, score=-31.464 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=2, min_samples_split=4;, score=-35.682 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=2, min_samples_split=4;, score=-40.015 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=2, min_samples_split=6;, score=-28.298 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=2, min_samples_split=6;, score=-29.408 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=2, min_samples_split=6;, score=-31.379 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=2, min_samples_split=6;, score=-36.437 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=2, min_samples_split=6;, score=-39.073 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=2, min_samples_split=8;, score=-28.220 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=2, min_samples_split=8;, score=-29.879 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=2, min_samples_split=8;, score=-31.726 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=2, min_samples_split=8;, score=-35.586 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=2, min_samples_split=8;, score=-39.274 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2;, score=-28.242 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2;, score=-29.740 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2;, score=-31.429 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2;, score=-34.891 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=2;, score=-38.520 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=4;, score=-28.242 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=4;, score=-29.740 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=4;, score=-31.429 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=4;, score=-34.891 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=4;, score=-38.520 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=6;, score=-28.242 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=6;, score=-29.740 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=6;, score=-31.429 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=6;, score=-34.891 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=6;, score=-38.520 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8;, score=-27.861 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8;, score=-29.727 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8;, score=-31.238 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8;, score=-35.131 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=3, min_samples_split=8;, score=-38.573 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=-28.793 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=-30.111 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=-34.456 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=4, min_samples_split=2;, score=-37.630 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=4, min_samples_split=4;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=4, min_samples_split=4;, score=-28.793 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=4, min_samples_split=4;, score=-30.111 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=4, min_samples_split=4;, score=-34.456 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=4, min_samples_split=4;, score=-37.630 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=4, min_samples_split=6;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=4, min_samples_split=6;, score=-28.793 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=4, min_samples_split=6;, score=-30.111 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=4, min_samples_split=6;, score=-34.456 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=4, min_samples_split=6;, score=-37.630 total time=   0.2s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=4, min_samples_split=8;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=4, min_samples_split=8;, score=-28.793 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=4, min_samples_split=8;, score=-30.111 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=4, min_samples_split=8;, score=-34.456 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=4, min_samples_split=8;, score=-37.630 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2;, score=-28.257 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2;, score=-30.115 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2;, score=-32.033 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=2;, score=-36.761 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=4;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=4;, score=-28.257 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=4;, score=-30.115 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=4;, score=-32.033 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=4;, score=-36.761 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=6;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=6;, score=-28.257 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=6;, score=-30.115 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=6;, score=-32.033 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=6;, score=-36.761 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8;, score=-28.257 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8;, score=-30.115 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8;, score=-32.033 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=5, min_samples_split=8;, score=-36.761 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=6, min_samples_split=2;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=6, min_samples_split=2;, score=-27.600 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=6, min_samples_split=2;, score=-27.581 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=6, min_samples_split=2;, score=-31.488 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=6, min_samples_split=2;, score=-36.551 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=6, min_samples_split=4;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=6, min_samples_split=4;, score=-27.600 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=6, min_samples_split=4;, score=-27.581 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=6, min_samples_split=4;, score=-31.488 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=6, min_samples_split=4;, score=-36.551 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=6, min_samples_split=6;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=6, min_samples_split=6;, score=-27.600 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=6, min_samples_split=6;, score=-27.581 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=6, min_samples_split=6;, score=-31.488 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=6, min_samples_split=6;, score=-36.551 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=6, min_samples_split=8;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=6, min_samples_split=8;, score=-27.600 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=6, min_samples_split=8;, score=-27.581 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=6, min_samples_split=8;, score=-31.488 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=6, min_samples_split=8;, score=-36.551 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, min_samples_split=2;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, min_samples_split=2;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, min_samples_split=2;, score=-27.890 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, min_samples_split=2;, score=-30.714 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, min_samples_split=2;, score=-35.471 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, min_samples_split=4;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, min_samples_split=4;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, min_samples_split=4;, score=-27.890 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, min_samples_split=4;, score=-30.714 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, min_samples_split=4;, score=-35.471 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, min_samples_split=6;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, min_samples_split=6;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, min_samples_split=6;, score=-27.890 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, min_samples_split=6;, score=-30.714 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, min_samples_split=6;, score=-35.471 total time=   0.1s\n",
      "[CV 1/5] END max_depth=15, min_samples_leaf=7, min_samples_split=8;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=15, min_samples_leaf=7, min_samples_split=8;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=15, min_samples_leaf=7, min_samples_split=8;, score=-27.890 total time=   0.0s\n",
      "[CV 4/5] END max_depth=15, min_samples_leaf=7, min_samples_split=8;, score=-30.714 total time=   0.1s\n",
      "[CV 5/5] END max_depth=15, min_samples_leaf=7, min_samples_split=8;, score=-35.471 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, min_samples_split=2;, score=-28.926 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, min_samples_split=2;, score=-30.929 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, min_samples_split=2;, score=-34.730 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, min_samples_split=2;, score=-38.094 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, min_samples_split=2;, score=-40.535 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, min_samples_split=4;, score=-29.546 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, min_samples_split=4;, score=-29.752 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, min_samples_split=4;, score=-35.458 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, min_samples_split=4;, score=-36.923 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, min_samples_split=4;, score=-40.284 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, min_samples_split=6;, score=-29.174 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, min_samples_split=6;, score=-30.111 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, min_samples_split=6;, score=-35.232 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, min_samples_split=6;, score=-36.973 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, min_samples_split=6;, score=-40.809 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=1, min_samples_split=8;, score=-28.337 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=1, min_samples_split=8;, score=-29.676 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=1, min_samples_split=8;, score=-34.976 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=1, min_samples_split=8;, score=-36.093 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=1, min_samples_split=8;, score=-39.858 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=2, min_samples_split=2;, score=-29.243 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=2, min_samples_split=2;, score=-30.011 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=2, min_samples_split=2;, score=-32.579 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=2, min_samples_split=2;, score=-36.142 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=2, min_samples_split=2;, score=-40.388 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=2, min_samples_split=4;, score=-29.243 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=2, min_samples_split=4;, score=-30.011 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=2, min_samples_split=4;, score=-32.579 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=2, min_samples_split=4;, score=-36.142 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=2, min_samples_split=4;, score=-40.388 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=2, min_samples_split=6;, score=-28.195 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=2, min_samples_split=6;, score=-29.584 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=2, min_samples_split=6;, score=-31.825 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=2, min_samples_split=6;, score=-35.783 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=2, min_samples_split=6;, score=-39.772 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=2, min_samples_split=8;, score=-28.202 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=2, min_samples_split=8;, score=-29.708 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=2, min_samples_split=8;, score=-31.893 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=2, min_samples_split=8;, score=-35.212 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=2, min_samples_split=8;, score=-39.475 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, min_samples_split=2;, score=-28.284 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, min_samples_split=2;, score=-29.445 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, min_samples_split=2;, score=-31.604 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, min_samples_split=2;, score=-34.216 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, min_samples_split=2;, score=-38.373 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, min_samples_split=4;, score=-28.284 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, min_samples_split=4;, score=-29.445 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, min_samples_split=4;, score=-31.604 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, min_samples_split=4;, score=-34.216 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, min_samples_split=4;, score=-38.373 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, min_samples_split=6;, score=-28.284 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, min_samples_split=6;, score=-29.445 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, min_samples_split=6;, score=-31.604 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, min_samples_split=6;, score=-34.216 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, min_samples_split=6;, score=-38.373 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=3, min_samples_split=8;, score=-27.725 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=3, min_samples_split=8;, score=-29.362 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=3, min_samples_split=8;, score=-31.037 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=3, min_samples_split=8;, score=-33.428 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=3, min_samples_split=8;, score=-38.415 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=4, min_samples_split=2;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=4, min_samples_split=2;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=4, min_samples_split=2;, score=-30.056 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=4, min_samples_split=2;, score=-34.328 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=4, min_samples_split=2;, score=-37.625 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=4, min_samples_split=4;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=4, min_samples_split=4;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=4, min_samples_split=4;, score=-30.056 total time=   0.1s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=4, min_samples_split=4;, score=-34.328 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=4, min_samples_split=4;, score=-37.625 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=4, min_samples_split=6;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=4, min_samples_split=6;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=4, min_samples_split=6;, score=-30.056 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=4, min_samples_split=6;, score=-34.328 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=4, min_samples_split=6;, score=-37.625 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=4, min_samples_split=8;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=4, min_samples_split=8;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=4, min_samples_split=8;, score=-30.056 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=4, min_samples_split=8;, score=-34.328 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=4, min_samples_split=8;, score=-37.625 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, min_samples_split=2;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, min_samples_split=2;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, min_samples_split=2;, score=-30.085 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, min_samples_split=2;, score=-32.297 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, min_samples_split=2;, score=-37.056 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, min_samples_split=4;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, min_samples_split=4;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, min_samples_split=4;, score=-30.085 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, min_samples_split=4;, score=-32.297 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, min_samples_split=4;, score=-37.056 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, min_samples_split=6;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, min_samples_split=6;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, min_samples_split=6;, score=-30.085 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, min_samples_split=6;, score=-32.297 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, min_samples_split=6;, score=-37.056 total time=   0.2s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=5, min_samples_split=8;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=5, min_samples_split=8;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=5, min_samples_split=8;, score=-30.085 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=5, min_samples_split=8;, score=-32.297 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=5, min_samples_split=8;, score=-37.056 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=6, min_samples_split=2;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=6, min_samples_split=2;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=6, min_samples_split=2;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=6, min_samples_split=2;, score=-31.469 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=6, min_samples_split=2;, score=-36.579 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=6, min_samples_split=4;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=6, min_samples_split=4;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=6, min_samples_split=4;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=6, min_samples_split=4;, score=-31.469 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=6, min_samples_split=4;, score=-36.579 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=6, min_samples_split=6;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=6, min_samples_split=6;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=6, min_samples_split=6;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=6, min_samples_split=6;, score=-31.469 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=6, min_samples_split=6;, score=-36.579 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=6, min_samples_split=8;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=6, min_samples_split=8;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=6, min_samples_split=8;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=6, min_samples_split=8;, score=-31.469 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=6, min_samples_split=8;, score=-36.579 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, min_samples_split=2;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, min_samples_split=2;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, min_samples_split=2;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, min_samples_split=2;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, min_samples_split=2;, score=-35.475 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, min_samples_split=4;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, min_samples_split=4;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, min_samples_split=4;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, min_samples_split=4;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, min_samples_split=4;, score=-35.475 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, min_samples_split=6;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, min_samples_split=6;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, min_samples_split=6;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, min_samples_split=6;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, min_samples_split=6;, score=-35.475 total time=   0.1s\n",
      "[CV 1/5] END max_depth=17, min_samples_leaf=7, min_samples_split=8;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=17, min_samples_leaf=7, min_samples_split=8;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=17, min_samples_leaf=7, min_samples_split=8;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=17, min_samples_leaf=7, min_samples_split=8;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=17, min_samples_leaf=7, min_samples_split=8;, score=-35.475 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, min_samples_split=2;, score=-29.259 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, min_samples_split=2;, score=-30.162 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, min_samples_split=2;, score=-36.161 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, min_samples_split=2;, score=-35.424 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, min_samples_split=2;, score=-41.377 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, min_samples_split=4;, score=-29.469 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, min_samples_split=4;, score=-29.669 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, min_samples_split=4;, score=-35.357 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, min_samples_split=4;, score=-36.171 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, min_samples_split=4;, score=-40.775 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, min_samples_split=6;, score=-28.926 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, min_samples_split=6;, score=-29.912 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, min_samples_split=6;, score=-35.070 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, min_samples_split=6;, score=-35.096 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, min_samples_split=6;, score=-40.202 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=1, min_samples_split=8;, score=-28.558 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=1, min_samples_split=8;, score=-29.873 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=1, min_samples_split=8;, score=-34.489 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=1, min_samples_split=8;, score=-36.005 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=1, min_samples_split=8;, score=-39.969 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=2, min_samples_split=2;, score=-29.204 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=2, min_samples_split=2;, score=-29.888 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=2, min_samples_split=2;, score=-32.433 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=2, min_samples_split=2;, score=-36.075 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=2, min_samples_split=2;, score=-39.977 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=2, min_samples_split=4;, score=-29.204 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=2, min_samples_split=4;, score=-29.888 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=2, min_samples_split=4;, score=-32.433 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=2, min_samples_split=4;, score=-36.075 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=2, min_samples_split=4;, score=-39.977 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=2, min_samples_split=6;, score=-28.553 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=2, min_samples_split=6;, score=-29.559 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=2, min_samples_split=6;, score=-32.331 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=2, min_samples_split=6;, score=-36.758 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=2, min_samples_split=6;, score=-39.686 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=2, min_samples_split=8;, score=-28.346 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=2, min_samples_split=8;, score=-29.272 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=2, min_samples_split=8;, score=-31.729 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=2, min_samples_split=8;, score=-35.740 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=2, min_samples_split=8;, score=-39.567 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, min_samples_split=2;, score=-28.284 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, min_samples_split=2;, score=-29.742 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, min_samples_split=2;, score=-31.604 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, min_samples_split=2;, score=-33.954 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, min_samples_split=2;, score=-39.022 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, min_samples_split=4;, score=-28.284 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, min_samples_split=4;, score=-29.742 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, min_samples_split=4;, score=-31.604 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, min_samples_split=4;, score=-33.954 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, min_samples_split=4;, score=-39.022 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, min_samples_split=6;, score=-28.284 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, min_samples_split=6;, score=-29.742 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, min_samples_split=6;, score=-31.604 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, min_samples_split=6;, score=-33.954 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, min_samples_split=6;, score=-39.022 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=3, min_samples_split=8;, score=-27.725 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=3, min_samples_split=8;, score=-29.362 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=3, min_samples_split=8;, score=-31.081 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=3, min_samples_split=8;, score=-35.289 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=3, min_samples_split=8;, score=-38.620 total time=   0.2s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=4, min_samples_split=2;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=4, min_samples_split=2;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=4, min_samples_split=2;, score=-30.224 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=4, min_samples_split=2;, score=-34.236 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=4, min_samples_split=2;, score=-37.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=4, min_samples_split=4;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=4, min_samples_split=4;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=4, min_samples_split=4;, score=-30.224 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=4, min_samples_split=4;, score=-34.236 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=4, min_samples_split=4;, score=-37.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=4, min_samples_split=6;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=4, min_samples_split=6;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=4, min_samples_split=6;, score=-30.224 total time=   0.1s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=4, min_samples_split=6;, score=-34.236 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=4, min_samples_split=6;, score=-37.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=4, min_samples_split=8;, score=-27.867 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=4, min_samples_split=8;, score=-28.550 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=4, min_samples_split=8;, score=-30.224 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=4, min_samples_split=8;, score=-34.236 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=4, min_samples_split=8;, score=-37.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, min_samples_split=2;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, min_samples_split=2;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, min_samples_split=2;, score=-30.239 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, min_samples_split=2;, score=-32.174 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, min_samples_split=2;, score=-37.087 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, min_samples_split=4;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, min_samples_split=4;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, min_samples_split=4;, score=-30.239 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, min_samples_split=4;, score=-32.174 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, min_samples_split=4;, score=-37.087 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, min_samples_split=6;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, min_samples_split=6;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, min_samples_split=6;, score=-30.239 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, min_samples_split=6;, score=-32.174 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, min_samples_split=6;, score=-37.087 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=5, min_samples_split=8;, score=-27.628 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=5, min_samples_split=8;, score=-28.609 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=5, min_samples_split=8;, score=-30.239 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=5, min_samples_split=8;, score=-32.174 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=5, min_samples_split=8;, score=-37.087 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=6, min_samples_split=2;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=6, min_samples_split=2;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=6, min_samples_split=2;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=6, min_samples_split=2;, score=-31.468 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=6, min_samples_split=2;, score=-36.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=6, min_samples_split=4;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=6, min_samples_split=4;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=6, min_samples_split=4;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=6, min_samples_split=4;, score=-31.468 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=6, min_samples_split=4;, score=-36.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=6, min_samples_split=6;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=6, min_samples_split=6;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=6, min_samples_split=6;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=6, min_samples_split=6;, score=-31.468 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=6, min_samples_split=6;, score=-36.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=6, min_samples_split=8;, score=-27.422 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=6, min_samples_split=8;, score=-27.700 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=6, min_samples_split=8;, score=-27.709 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=6, min_samples_split=8;, score=-31.468 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=6, min_samples_split=8;, score=-36.574 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, min_samples_split=2;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, min_samples_split=2;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, min_samples_split=2;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, min_samples_split=2;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, min_samples_split=2;, score=-35.475 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, min_samples_split=4;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, min_samples_split=4;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, min_samples_split=4;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, min_samples_split=4;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, min_samples_split=4;, score=-35.475 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, min_samples_split=6;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, min_samples_split=6;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, min_samples_split=6;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, min_samples_split=6;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, min_samples_split=6;, score=-35.475 total time=   0.1s\n",
      "[CV 1/5] END max_depth=19, min_samples_leaf=7, min_samples_split=8;, score=-27.222 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, min_samples_leaf=7, min_samples_split=8;, score=-28.321 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, min_samples_leaf=7, min_samples_split=8;, score=-27.736 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, min_samples_leaf=7, min_samples_split=8;, score=-30.742 total time=   0.1s\n",
      "[CV 5/5] END max_depth=19, min_samples_leaf=7, min_samples_split=8;, score=-35.475 total time=   0.1s\n",
      "{'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#подбор параметров\n",
    "\n",
    "#параметры\n",
    "parametrs = { 'max_depth': range (1,20, 2),\n",
    "              'min_samples_leaf': range (1,8),\n",
    "              'min_samples_split': range (2,10,2)\n",
    "            }\n",
    "\n",
    "def rmse(predict, actual):\n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "    score = sqrt(mean_squared_error(target_test, pred_lr))\n",
    "    return score\n",
    "\n",
    "rmse_score = make_scorer(rmse, greater_is_better = False)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "#запускаем обучение\n",
    "grid = GridSearchCV(model_dtr, parametrs, cv=tscv, scoring = 'neg_root_mean_squared_error', verbose=3)\n",
    "grid.fit(features_train, target_train)\n",
    "\n",
    "#выводим результат\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba3ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26.59323361437394"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dtr = grid.best_score_\n",
    "score_dtr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5454468",
   "metadata": {},
   "source": [
    "***Обучение модели LGBMRegressor***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "900a7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#модель \n",
    "model_lgbm = LGBMRegressor(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5361333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.320 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=10;, score=-17.661 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.875 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=10;, score=-18.728 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=10;, score=-25.004 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=10;, score=-14.951 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.341 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.232 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=10;, score=-17.012 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=10;, score=-22.182 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=10;, score=-20.238 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=10;, score=-22.091 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=10;, score=-20.887 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=10;, score=-25.338 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=10;, score=-33.953 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.145 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=10;, score=-17.137 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=10;, score=-18.152 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=10;, score=-24.377 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=10;, score=-14.829 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.128 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.202 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.801 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=10;, score=-22.007 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=10;, score=-20.118 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=10;, score=-21.660 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=10;, score=-20.458 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.137 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=10;, score=-17.108 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.618 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=10;, score=-18.142 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=10;, score=-24.404 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=10;, score=-14.890 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.109 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.192 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.824 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=10;, score=-22.011 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=10;, score=-20.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=10;, score=-21.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=10;, score=-20.466 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=6, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.113 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=10;, score=-17.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=10;, score=-18.134 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=10;, score=-24.404 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=10;, score=-14.825 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.070 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.201 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.808 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=10;, score=-22.013 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=10;, score=-20.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=10;, score=-21.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=10;, score=-20.466 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.113 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=10;, score=-17.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=10;, score=-18.134 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=10;, score=-24.404 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=10;, score=-14.823 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.085 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.191 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.814 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=10;, score=-22.027 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=10;, score=-20.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=10;, score=-21.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=10;, score=-20.466 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=9, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.113 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=10;, score=-17.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=10;, score=-18.134 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=10;, score=-24.404 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=10;, score=-14.823 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.085 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.191 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.814 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=10;, score=-22.027 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=10;, score=-20.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=10;, score=-21.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=10;, score=-20.466 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=12, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.113 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=10;, score=-17.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=10;, score=-18.134 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=10;, score=-24.404 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=10;, score=-14.823 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.085 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.191 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.814 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=10;, score=-22.027 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=10;, score=-20.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=10;, score=-21.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=10;, score=-20.466 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.113 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=10;, score=-17.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=10;, score=-18.134 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=10;, score=-24.404 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=10;, score=-14.823 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.085 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.191 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.814 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=10;, score=-22.027 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=10;, score=-20.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=10;, score=-21.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=10;, score=-20.466 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=17, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.113 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=10;, score=-17.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=10;, score=-18.134 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=10;, score=-24.404 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=2;, score=-18.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=2;, score=-20.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=2;, score=-19.367 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=2;, score=-23.075 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=150, num_leaves=2;, score=-30.920 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=10;, score=-14.823 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.085 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.191 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.814 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=10;, score=-22.027 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.676 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=2;, score=-18.691 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=2;, score=-17.521 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=2;, score=-20.179 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=251, num_leaves=2;, score=-26.942 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=10;, score=-20.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=10;, score=-21.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=10;, score=-20.466 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=10;, score=-24.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=10;, score=-33.389 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=2;, score=-21.348 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=2;, score=-24.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=2;, score=-23.342 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=2;, score=-28.308 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=25, n_estimators=50, num_leaves=2;, score=-37.508 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=10;, score=-15.185 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.533 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.307 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=10;, score=-17.269 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=10;, score=-22.650 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=10;, score=-14.435 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=10;, score=-15.851 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.337 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.662 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=10;, score=-21.068 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=10;, score=-18.781 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=10;, score=-20.345 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=10;, score=-19.240 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=10;, score=-22.867 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=10;, score=-30.623 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=3, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=10;, score=-15.021 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.260 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.245 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.940 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=10;, score=-22.431 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=10;, score=-14.435 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=10;, score=-15.837 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.363 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.504 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=10;, score=-21.042 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=10;, score=-18.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=10;, score=-19.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=10;, score=-18.782 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=10;, score=-22.150 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=5, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=10;, score=-15.074 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.238 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.222 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.953 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=10;, score=-22.421 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=10;, score=-14.474 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=10;, score=-15.798 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.356 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.499 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=10;, score=-21.083 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=10;, score=-18.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=10;, score=-19.742 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=10;, score=-18.788 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=10;, score=-22.143 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=6, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=10;, score=-15.035 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.233 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.237 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=10;, score=-17.001 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=10;, score=-22.424 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=10;, score=-14.433 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=10;, score=-15.773 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.388 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.531 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=10;, score=-21.044 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=10;, score=-18.636 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=10;, score=-19.742 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=10;, score=-18.788 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=10;, score=-22.143 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=7, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=10;, score=-15.054 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.233 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.237 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=10;, score=-22.424 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=10;, score=-14.446 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=10;, score=-15.785 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.388 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.506 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=10;, score=-21.048 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=10;, score=-18.636 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=10;, score=-19.742 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=10;, score=-18.788 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=10;, score=-22.143 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=9, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=10;, score=-15.054 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.233 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.237 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.981 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=10;, score=-22.424 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=10;, score=-14.446 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=10;, score=-15.785 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.388 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.506 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=10;, score=-21.048 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=10;, score=-18.636 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=10;, score=-19.742 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=10;, score=-18.788 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=10;, score=-22.143 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=12, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=10;, score=-15.054 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.233 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.237 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=10;, score=-22.424 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=10;, score=-14.446 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=10;, score=-15.785 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.388 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.506 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=10;, score=-21.048 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=10;, score=-18.636 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=10;, score=-19.742 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=10;, score=-18.788 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=10;, score=-22.143 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=15, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=10;, score=-15.054 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.233 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.237 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=10;, score=-22.424 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=10;, score=-14.446 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=10;, score=-15.785 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.388 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.506 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=10;, score=-21.048 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=10;, score=-18.636 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=10;, score=-19.742 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=10;, score=-18.788 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=10;, score=-22.143 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=17, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=10;, score=-15.054 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.233 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.237 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.981 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=10;, score=-22.424 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=2;, score=-17.042 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=2;, score=-19.073 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=2;, score=-17.860 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=2;, score=-20.787 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=150, num_leaves=2;, score=-27.756 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=10;, score=-14.446 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=10;, score=-15.785 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.388 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.506 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=10;, score=-21.048 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=2;, score=-15.424 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=2;, score=-17.609 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.585 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=2;, score=-18.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=251, num_leaves=2;, score=-24.379 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=10;, score=-18.636 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=10;, score=-19.742 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=10;, score=-18.788 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=10;, score=-22.143 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=10;, score=-30.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=2;, score=-20.380 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=2;, score=-23.411 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=2;, score=-22.094 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=2;, score=-26.695 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.015, max_depth=25, n_estimators=50, num_leaves=2;, score=-35.481 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=10;, score=-14.527 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=10;, score=-15.886 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.256 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.646 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=10;, score=-20.977 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=10;, score=-14.292 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=10;, score=-15.699 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.484 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.551 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=10;, score=-20.454 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=10;, score=-16.995 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=10;, score=-18.206 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=10;, score=-17.365 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=10;, score=-19.663 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=10;, score=-26.242 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=3, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=10;, score=-14.475 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=10;, score=-15.821 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.246 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.515 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=10;, score=-20.969 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=10;, score=-14.298 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=10;, score=-15.766 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.472 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.481 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=10;, score=-20.526 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=10;, score=-16.729 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=10;, score=-17.625 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=10;, score=-17.007 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=10;, score=-18.958 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=10;, score=-25.696 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=5, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=10;, score=-14.509 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=10;, score=-15.761 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.431 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.460 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=10;, score=-21.040 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=10;, score=-14.302 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=10;, score=-15.705 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.694 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.437 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=10;, score=-20.561 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=10;, score=-16.733 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=10;, score=-17.604 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=10;, score=-17.009 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=10;, score=-18.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=10;, score=-25.643 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=6, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=10;, score=-14.477 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=10;, score=-15.786 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.442 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.454 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=10;, score=-20.978 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=10;, score=-14.324 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=10;, score=-15.744 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.630 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.392 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=10;, score=-20.534 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=10;, score=-16.698 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=10;, score=-17.606 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=10;, score=-17.009 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=10;, score=-18.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=10;, score=-25.643 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=7, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=10;, score=-14.465 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=10;, score=-15.800 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.416 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.455 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=10;, score=-20.987 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=10;, score=-14.311 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=10;, score=-15.758 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.661 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.415 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=10;, score=-20.552 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=10;, score=-16.698 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=10;, score=-17.606 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=10;, score=-17.009 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=10;, score=-18.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=10;, score=-25.643 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=9, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=10;, score=-14.465 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=10;, score=-15.800 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.416 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.455 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=10;, score=-20.987 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=10;, score=-14.311 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=10;, score=-15.758 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.661 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.415 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=10;, score=-20.552 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=10;, score=-16.698 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=10;, score=-17.606 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=10;, score=-17.009 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=10;, score=-18.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=10;, score=-25.643 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=12, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=10;, score=-14.465 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=10;, score=-15.800 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.416 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.455 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=10;, score=-20.987 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=10;, score=-14.311 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=10;, score=-15.758 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.661 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.415 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=10;, score=-20.552 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=10;, score=-16.698 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=10;, score=-17.606 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=10;, score=-17.009 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=10;, score=-18.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=10;, score=-25.643 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=15, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=10;, score=-14.465 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=10;, score=-15.800 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.416 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.455 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=10;, score=-20.987 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=10;, score=-14.311 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=10;, score=-15.758 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.661 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.415 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=10;, score=-20.552 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=10;, score=-16.698 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=10;, score=-17.606 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=10;, score=-17.009 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=10;, score=-18.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=10;, score=-25.643 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=17, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=10;, score=-14.465 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=10;, score=-15.800 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.416 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.455 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=10;, score=-20.987 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=2;, score=-15.406 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=2;, score=-17.618 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=2;, score=-16.603 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=2;, score=-18.217 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=150, num_leaves=2;, score=-24.396 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=10;, score=-14.311 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=10;, score=-15.758 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.661 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.415 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=10;, score=-20.552 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=2;, score=-14.616 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.306 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=251, num_leaves=2;, score=-21.957 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=10;, score=-16.698 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=10;, score=-17.606 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=10;, score=-17.009 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=10;, score=-18.965 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=10;, score=-25.643 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=2;, score=-18.981 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=2;, score=-21.450 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=2;, score=-20.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=2;, score=-24.049 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.025, max_depth=25, n_estimators=50, num_leaves=2;, score=-32.171 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=10;, score=-14.131 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=10;, score=-15.721 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.685 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.542 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=10;, score=-20.387 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=10;, score=-14.139 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=10;, score=-15.704 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.834 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=10;, score=-16.631 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=10;, score=-20.265 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=10;, score=-14.960 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=10;, score=-16.396 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=10;, score=-16.387 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=10;, score=-16.992 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=10;, score=-22.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=3, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=10;, score=-14.288 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=10;, score=-15.634 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.926 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.365 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=10;, score=-20.641 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=10;, score=-14.270 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=10;, score=-15.686 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.893 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.463 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=10;, score=-20.637 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=10;, score=-14.871 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=10;, score=-16.152 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=10;, score=-16.298 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=10;, score=-16.715 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=10;, score=-22.093 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=5, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=10;, score=-14.282 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=10;, score=-15.731 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.804 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.473 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=10;, score=-20.694 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=10;, score=-14.335 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=10;, score=-15.862 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.966 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.602 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=10;, score=-20.727 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=10;, score=-14.932 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=10;, score=-16.057 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=10;, score=-16.284 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=10;, score=-16.768 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=10;, score=-22.161 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=6, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=10;, score=-14.383 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=10;, score=-15.685 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.652 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.544 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=10;, score=-20.576 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=10;, score=-14.379 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=10;, score=-15.845 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.795 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.571 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=10;, score=-20.685 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=10;, score=-14.963 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=10;, score=-16.070 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=10;, score=-16.270 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=10;, score=-16.782 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=10;, score=-22.111 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=7, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=10;, score=-14.333 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=10;, score=-15.760 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.749 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.479 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=10;, score=-20.662 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=10;, score=-14.340 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=10;, score=-15.843 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.945 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.384 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=10;, score=-20.782 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=10;, score=-14.941 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=10;, score=-16.070 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=10;, score=-16.293 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=10;, score=-16.774 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=10;, score=-22.111 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=9, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=10;, score=-14.333 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=10;, score=-15.760 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.749 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.479 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=10;, score=-20.662 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=10;, score=-14.340 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=10;, score=-15.843 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.945 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.384 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=10;, score=-20.782 total time=   0.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=10;, score=-14.941 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=10;, score=-16.070 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=10;, score=-16.293 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=10;, score=-16.774 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=10;, score=-22.111 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=12, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=10;, score=-14.333 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=10;, score=-15.760 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.749 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.479 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=10;, score=-20.662 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=10;, score=-14.340 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=10;, score=-15.843 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.945 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.384 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=10;, score=-20.782 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=10;, score=-14.941 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=10;, score=-16.070 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=10;, score=-16.293 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=10;, score=-16.774 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=10;, score=-22.111 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=10;, score=-14.333 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=10;, score=-15.760 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.749 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.479 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=10;, score=-20.662 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=10;, score=-14.340 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=10;, score=-15.843 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.945 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.384 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=10;, score=-20.782 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=10;, score=-14.941 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=10;, score=-16.070 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=10;, score=-16.293 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=10;, score=-16.774 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=10;, score=-22.111 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=17, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=10;, score=-14.333 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=10;, score=-15.760 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.749 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.479 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=10;, score=-20.662 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=2;, score=-14.451 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=2;, score=-16.582 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=2;, score=-16.385 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=2;, score=-16.837 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=150, num_leaves=2;, score=-21.488 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=10;, score=-14.340 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=10;, score=-15.843 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.945 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.384 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=10;, score=-20.782 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=2;, score=-14.216 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.281 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.668 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.808 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=251, num_leaves=2;, score=-20.878 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=10;, score=-14.941 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=10;, score=-16.070 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=10;, score=-16.293 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=10;, score=-16.774 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=10;, score=-22.111 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=2;, score=-16.591 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=2;, score=-18.666 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=2;, score=-17.468 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=2;, score=-20.068 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=25, n_estimators=50, num_leaves=2;, score=-26.872 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=10;, score=-14.234 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=10;, score=-15.804 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=10;, score=-17.099 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=10;, score=-16.936 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=10;, score=-20.268 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=10;, score=-14.255 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=10;, score=-15.920 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=10;, score=-17.275 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=10;, score=-17.098 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=10;, score=-20.439 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=10;, score=-14.254 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=10;, score=-15.707 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=10;, score=-16.750 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=10;, score=-16.790 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=10;, score=-20.567 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=10;, score=-14.145 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=10;, score=-15.936 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.918 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=10;, score=-16.901 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=10;, score=-20.435 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=10;, score=-14.136 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.063 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=10;, score=-17.241 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=10;, score=-16.957 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=10;, score=-20.401 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=10;, score=-14.345 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=10;, score=-15.867 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=10;, score=-16.578 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=10;, score=-16.710 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=10;, score=-20.610 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=10;, score=-14.517 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.012 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=10;, score=-17.346 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=10;, score=-16.762 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=10;, score=-20.407 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=10;, score=-14.527 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.107 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=10;, score=-17.542 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=10;, score=-16.980 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=10;, score=-20.457 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=10;, score=-14.522 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=10;, score=-15.891 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=10;, score=-16.735 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=10;, score=-16.674 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=10;, score=-20.645 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=6, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=10;, score=-14.513 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.062 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=10;, score=-17.145 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=10;, score=-16.745 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=10;, score=-20.609 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=10;, score=-14.492 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.174 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=10;, score=-17.364 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=10;, score=-16.725 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=10;, score=-20.757 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=10;, score=-14.599 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=10;, score=-15.920 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=10;, score=-16.814 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=10;, score=-16.671 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=10;, score=-20.507 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=10;, score=-14.357 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.118 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=10;, score=-17.222 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=10;, score=-16.610 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=10;, score=-20.290 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=10;, score=-14.408 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.162 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=10;, score=-17.347 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=10;, score=-16.818 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=10;, score=-20.427 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=10;, score=-14.552 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=10;, score=-16.003 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=10;, score=-16.777 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=10;, score=-16.678 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=10;, score=-20.445 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=9, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=10;, score=-14.357 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.118 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=10;, score=-17.222 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=10;, score=-16.610 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=10;, score=-20.290 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=10;, score=-14.408 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.162 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=10;, score=-17.347 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=10;, score=-16.818 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=10;, score=-20.427 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=10;, score=-14.552 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=10;, score=-16.003 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=10;, score=-16.777 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=10;, score=-16.678 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=10;, score=-20.445 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=12, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=10;, score=-14.357 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.118 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=10;, score=-17.222 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=10;, score=-16.610 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=10;, score=-20.290 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=10;, score=-14.408 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.162 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=10;, score=-17.347 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=10;, score=-16.818 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=10;, score=-20.427 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=10;, score=-14.552 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=10;, score=-16.003 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=10;, score=-16.777 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=10;, score=-16.678 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=10;, score=-20.445 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=10;, score=-14.357 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.118 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=10;, score=-17.222 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=10;, score=-16.610 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=10;, score=-20.290 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=10;, score=-14.408 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.162 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=10;, score=-17.347 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=10;, score=-16.818 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=10;, score=-20.427 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=10;, score=-14.552 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=10;, score=-16.003 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=10;, score=-16.777 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=10;, score=-16.678 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=10;, score=-20.445 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=17, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=10;, score=-14.357 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.118 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=10;, score=-17.222 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=10;, score=-16.610 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=10;, score=-20.290 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=2;, score=-14.123 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=2;, score=-16.183 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=2;, score=-16.747 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=2;, score=-16.824 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=150, num_leaves=2;, score=-20.681 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=10;, score=-14.408 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.162 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=10;, score=-17.347 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=10;, score=-16.818 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=10;, score=-20.427 total time=   0.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=2;, score=-13.972 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.090 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.862 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=2;, score=-16.776 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=251, num_leaves=2;, score=-20.460 total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=1;, score=nan total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=10;, score=-14.552 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=10;, score=-16.003 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=10;, score=-16.777 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=10;, score=-16.678 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=10;, score=-20.445 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17085\n",
      "[LightGBM] [Info] Number of data points in the train set: 636, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 57.938679\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=2;, score=-14.773 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21675\n",
      "[LightGBM] [Info] Number of data points in the train set: 1270, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 61.134646\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=2;, score=-16.971 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24222\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 65.247374\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=2;, score=-16.278 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26361\n",
      "[LightGBM] [Info] Number of data points in the train set: 2538, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 68.784870\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=2;, score=-17.299 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28952\n",
      "[LightGBM] [Info] Number of data points in the train set: 3172, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 73.536885\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=25, n_estimators=50, num_leaves=2;, score=-22.678 total time=   0.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31479\n",
      "[LightGBM] [Info] Number of data points in the train set: 3806, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score 79.352864\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 150, 'num_leaves': 10}\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#подбор параметров\n",
    "\n",
    "#параметры\n",
    "\n",
    "parametrs = {\n",
    "    'max_depth':[3, 5, 6, 7, 9, 12, 15, 17, 25],\n",
    "    'n_estimators': (150,251, 50),\n",
    "    'learning_rate': [0.01, 0.015, 0.025, 0.05, 0.1],\n",
    "    'num_leaves': [1, 10, 2]\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "#запускаем обучение\n",
    "grid = GridSearchCV(model_lgbm, parametrs, cv=tscv, scoring = 'neg_root_mean_squared_error', verbose=3)\n",
    "grid.fit(features_train, target_train)\n",
    "\n",
    "#выводим результат\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f94c720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16.69295782838668"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lgbm = grid.best_score_\n",
    "score_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83c3b0",
   "metadata": {},
   "source": [
    "***Выбор лучшей модели***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b27eb838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-22.657425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>-23.734257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>-26.593234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>-16.692958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model       RMSE\n",
       "0       LinearRegression -22.657425\n",
       "1  RandomForestRegressor -23.734257\n",
       "2  DecisionTreeRegressor -26.593234\n",
       "3          LGBMRegressor -16.692958"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создание DataFrame с результатами\n",
    "pd.options.display.width = 0\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "results_valid = pd.DataFrame({'Model': ['LinearRegression','RandomForestRegressor', 'DecisionTreeRegressor', 'LGBMRegressor'],\n",
    "                        'RMSE': [score_lr, score_rf, score_dtr, score_lgbm]\n",
    "                        })\n",
    "\n",
    "# Вывод результатов\n",
    "display(results_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39147b",
   "metadata": {},
   "source": [
    "***Анализ метрик моделей:*** \n",
    "\n",
    "Лучший результат на валидацонных данных показала модель LGBMRegressor, ее метриика составила -16,629\n",
    "\n",
    "Проверим работу этой модели на тестовой выборке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888efb4e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4. Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "249b4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE модели LGBMRegressor на тестовой выбоорке: 37.192241770063646\n"
     ]
    }
   ],
   "source": [
    "#модель LGBMRegressor\n",
    "predictions_test_lgbm = grid.predict(features_test)                            \n",
    "rmse_lgbm_test = sqrt(mean_squared_error(target_test, predictions_test_lgbm))\n",
    "print('RMSE модели LGBMRegressor на тестовой выбоорке:', rmse_lgbm_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd34119",
   "metadata": {},
   "source": [
    "По тестовой выборке модель показала немного большую метрику RMSE, но все равно она в пределах условия - иниже 48. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c58bfb",
   "metadata": {},
   "source": [
    "***Вывод:***\n",
    "\n",
    "В проекте была задача на основании исторических данных о заказ такси в аэропортах построить модель для прогнозирования заказов такси на следующий час. При этом значение метрики RMSE на тестовой выборке должно быть не больше 48.\n",
    "\n",
    "Мы провели анализ данных - они представлены за период 01.03.2018 - 31.08.2018 в разбивке по 10 минут. Далее сделали ресемплинг данных по 1 часу, так в задача проекта спрогнозировать заказы такси на следующий час. Проанализировали тренд и сезонность. Для сезонности у нас выборка за меленький период, поэтому график ничего не показал. Но по тренду видно постепенное увеличение количества заказов на такси.\n",
    "\n",
    "Для обучения моделей мы разделили данные на 2 выборки. Провели их масштабирование. Обучили 4 модели: LinearRegression, RandomForestRegressor, DecisionTreeRegressor и LGBMRegressor.\n",
    "\n",
    "Провели ранжирование моделей на валидационной выборке и финальное тестирование на тестовой. По итогу все модели удовлетворяют условию залачи - их RMSE меньше 48, но выбрали для тестирования одну лучшую - ей стала модель LGBMRegressor, с RMSE на кросвалидации  = 16,692 и на тестовой выборке = 37,192.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcef30",
   "metadata": {},
   "source": [
    "## 5. Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3e9b2",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Данные проанализированы\n",
    "- [ ]  Модель обучена, гиперпараметры подобраны\n",
    "- [ ]  Качество моделей проверено, выводы сделаны\n",
    "- [ ]  Значение *RMSE* на тестовой выборке не больше 48"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2458,
    "start_time": "2023-10-08T16:52:18.037Z"
   },
   {
    "duration": 3428,
    "start_time": "2023-10-08T16:52:20.497Z"
   },
   {
    "duration": 1334,
    "start_time": "2023-10-08T16:52:23.927Z"
   },
   {
    "duration": 18,
    "start_time": "2023-10-08T16:52:25.263Z"
   },
   {
    "duration": 46,
    "start_time": "2023-10-08T16:52:25.284Z"
   },
   {
    "duration": 19,
    "start_time": "2023-10-08T16:52:25.332Z"
   },
   {
    "duration": 21,
    "start_time": "2023-10-08T16:52:25.353Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-08T16:52:26.718Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-08T16:52:27.060Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-08T16:52:27.399Z"
   },
   {
    "duration": 350,
    "start_time": "2023-10-08T16:52:27.885Z"
   },
   {
    "duration": 809,
    "start_time": "2023-10-08T16:52:28.243Z"
   },
   {
    "duration": 338,
    "start_time": "2023-10-08T16:52:29.183Z"
   },
   {
    "duration": 402,
    "start_time": "2023-10-08T16:52:30.149Z"
   },
   {
    "duration": 45,
    "start_time": "2023-10-08T16:52:31.270Z"
   },
   {
    "duration": 15,
    "start_time": "2023-10-08T16:52:31.882Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-08T16:52:32.880Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-08T16:52:33.075Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-08T16:52:33.620Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-08T16:52:34.123Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-08T16:52:34.885Z"
   },
   {
    "duration": 54,
    "start_time": "2023-10-08T16:52:35.365Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-08T16:52:35.816Z"
   },
   {
    "duration": 29,
    "start_time": "2023-10-08T16:52:36.113Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-08T16:52:38.231Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-08T16:52:38.873Z"
   },
   {
    "duration": 140888,
    "start_time": "2023-10-08T16:52:39.406Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-08T16:55:00.296Z"
   },
   {
    "duration": 119,
    "start_time": "2023-10-08T16:55:00.309Z"
   },
   {
    "duration": 54355,
    "start_time": "2023-10-08T16:55:00.430Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-08T16:55:54.787Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-08T16:55:54.797Z"
   },
   {
    "duration": 4374337,
    "start_time": "2023-10-08T16:55:54.816Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-08T18:08:49.154Z"
   },
   {
    "duration": 64,
    "start_time": "2023-10-08T18:08:49.165Z"
   },
   {
    "duration": 319,
    "start_time": "2023-10-08T18:08:49.231Z"
   },
   {
    "duration": 32,
    "start_time": "2023-10-08T18:08:49.552Z"
   },
   {
    "duration": 1179,
    "start_time": "2023-10-08T18:08:49.585Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-08T18:08:50.849Z"
   },
   {
    "duration": 1217,
    "start_time": "2023-10-10T08:40:44.071Z"
   },
   {
    "duration": 2691,
    "start_time": "2023-10-10T08:40:58.600Z"
   },
   {
    "duration": 693,
    "start_time": "2023-10-10T08:41:01.293Z"
   },
   {
    "duration": 1485,
    "start_time": "2023-10-10T08:41:01.987Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-10T08:41:03.474Z"
   },
   {
    "duration": 59,
    "start_time": "2023-10-10T08:41:03.487Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-10T08:41:03.547Z"
   },
   {
    "duration": 37,
    "start_time": "2023-10-10T08:41:03.554Z"
   },
   {
    "duration": 23,
    "start_time": "2023-10-10T08:41:03.592Z"
   },
   {
    "duration": 31,
    "start_time": "2023-10-10T08:41:03.616Z"
   },
   {
    "duration": 23,
    "start_time": "2023-10-10T08:41:03.649Z"
   },
   {
    "duration": 41,
    "start_time": "2023-10-10T08:41:03.674Z"
   },
   {
    "duration": 401,
    "start_time": "2023-10-10T08:41:03.717Z"
   },
   {
    "duration": 327,
    "start_time": "2023-10-10T08:41:04.120Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-10T08:41:04.450Z"
   },
   {
    "duration": 382,
    "start_time": "2023-10-10T08:41:04.460Z"
   },
   {
    "duration": 710,
    "start_time": "2023-10-10T08:41:04.844Z"
   },
   {
    "duration": 137,
    "start_time": "2023-10-10T08:41:05.555Z"
   },
   {
    "duration": 137,
    "start_time": "2023-10-10T08:41:05.694Z"
   },
   {
    "duration": 374,
    "start_time": "2023-10-10T08:41:05.832Z"
   },
   {
    "duration": 533,
    "start_time": "2023-10-10T08:41:06.208Z"
   },
   {
    "duration": 149,
    "start_time": "2023-10-10T08:41:06.746Z"
   },
   {
    "duration": 37,
    "start_time": "2023-10-10T08:41:06.897Z"
   },
   {
    "duration": 60,
    "start_time": "2023-10-10T08:41:06.935Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-10T08:41:06.997Z"
   },
   {
    "duration": 45,
    "start_time": "2023-10-10T08:41:07.015Z"
   },
   {
    "duration": 30,
    "start_time": "2023-10-10T08:41:07.062Z"
   },
   {
    "duration": 23,
    "start_time": "2023-10-10T08:41:07.095Z"
   },
   {
    "duration": 44,
    "start_time": "2023-10-10T08:41:07.120Z"
   },
   {
    "duration": 214,
    "start_time": "2023-10-10T08:41:07.166Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-10T08:41:07.382Z"
   },
   {
    "duration": 42,
    "start_time": "2023-10-10T08:41:07.390Z"
   },
   {
    "duration": 2823,
    "start_time": "2023-10-10T08:41:07.434Z"
   },
   {
    "duration": 1768,
    "start_time": "2023-10-10T08:42:45.114Z"
   },
   {
    "duration": 1542,
    "start_time": "2023-10-10T08:42:58.607Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
